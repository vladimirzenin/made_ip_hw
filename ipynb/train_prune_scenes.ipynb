{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.misc import imread, imresize\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from random import shuffle\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_progress(sequence, every=None, size=None, name='Items'):\n",
    "    from ipywidgets import IntProgress, HTML, VBox\n",
    "    from IPython.display import display\n",
    "\n",
    "    is_iterator = False\n",
    "    if size is None:\n",
    "        try:\n",
    "            size = len(sequence)\n",
    "        except TypeError:\n",
    "            is_iterator = True\n",
    "    if size is not None:\n",
    "        if every is None:\n",
    "            if size <= 200:\n",
    "                every = 1\n",
    "            else:\n",
    "                every = int(size / 200)     # every 0.5%\n",
    "    else:\n",
    "        assert every is not None, 'sequence is iterator, set every'\n",
    "\n",
    "    if is_iterator:\n",
    "        progress = IntProgress(min=0, max=1, value=1)\n",
    "        progress.bar_style = 'info'\n",
    "    else:\n",
    "        progress = IntProgress(min=0, max=size, value=0)\n",
    "    label = HTML()\n",
    "    box = VBox(children=[label, progress])\n",
    "    display(box)\n",
    "\n",
    "    index = 0\n",
    "    try:\n",
    "        for index, record in enumerate(sequence, 1):\n",
    "            if index == 1 or index % every == 0:\n",
    "                if is_iterator:\n",
    "                    label.value = '{name}: {index} / ?'.format(\n",
    "                        name=name,\n",
    "                        index=index\n",
    "                    )\n",
    "                else:\n",
    "                    progress.value = index\n",
    "                    label.value = u'{name}: {index} / {size}'.format(\n",
    "                        name=name,\n",
    "                        index=index,\n",
    "                        size=size\n",
    "                    )\n",
    "            yield record\n",
    "    except:\n",
    "        progress.bar_style = 'danger'\n",
    "        raise\n",
    "    else:\n",
    "        progress.bar_style = 'success'\n",
    "        progress.value = index\n",
    "        label.value = \"{name}: {index}\".format(\n",
    "            name=name,\n",
    "            index=str(index or '?')\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if False:\n",
    "    INPUT_SIZE = (224, 224)\n",
    "    ALL_DATA_DIR = '/home/datasets/places/all_scenes_224/'\n",
    "else:\n",
    "    INPUT_SIZE = (299, 299)\n",
    "    ALL_DATA_DIR = '/home/datasets/places/all_scenes/'\n",
    "\n",
    "TRAIN_DATA_DIR = ALL_DATA_DIR+'train'\n",
    "VAL_DATA_DIR = ALL_DATA_DIR+'val'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PLACES_DIR = '/home/datasets/places/'\n",
    "PLACES_CATEGORIES_FILE=PLACES_DIR+'categories_places365.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCategories(filename):\n",
    "    places_to_categories={}\n",
    "    with open(filename,'r') as input_file:\n",
    "        for ind,line in enumerate(input_file):\n",
    "            row=line.rstrip().split(' ')\n",
    "            places_to_categories[row[0]]=row[1]\n",
    "\n",
    "    #print(places_to_categories['/r/river'])\n",
    "    categories_to_places={places_to_categories[place]:place for place in places_to_categories}\n",
    "    categories_to_dirs={places_to_categories[place]:place[3:].replace('/','_') for place in places_to_categories}\n",
    "    return categories_to_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories_to_dirs=getCategories(PLACES_CATEGORIES_FILE)\n",
    "#print(categories_to_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_links(filename, input_dir,dir_to_save,categories_to_dirs):\n",
    "    with open(filename,'r') as input_file:\n",
    "        for ind,line in enumerate(input_file):\n",
    "            row=line.rstrip().split(' ')\n",
    "            outdir_path=os.path.join(dir_to_save,categories_to_dirs[row[1]])\n",
    "            if not os.path.exists(outdir_path):\n",
    "                os.makedirs(outdir_path)\n",
    "            src_file_path=input_dir+row[0]\n",
    "            dst_file_path=os.path.join(outdir_path,os.path.basename(src_file_path))\n",
    "            #print(src_file_path,dst_file_path)\n",
    "            os.symlink(src_file_path,dst_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation\n",
    "PLACES_VAL_DATA_DIR = PLACES_DIR+'val_large/'\n",
    "PLACES_VAL_DESCR_FILE=PLACES_DIR+'places365_val.txt'\n",
    "save_links(PLACES_VAL_DESCR_FILE, PLACES_VAL_DATA_DIR,VAL_DATA_DIR,categories_to_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "PLACES_TRAIN_DATA_DIR = PLACES_DIR+'data_large/'\n",
    "PLACES_TRAIN_DESCR_FILE=PLACES_DIR+'places365_train_challenge.txt'\n",
    "save_links(PLACES_TRAIN_DESCR_FILE, PLACES_TRAIN_DATA_DIR,TRAIN_DATA_DIR,categories_to_dirs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Places extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'43': 'hot_tub_indoor', '5': 'dining_car', '51': 'kennel_indoor', '15': 'warehouse_indoor', '50': 'funeral_home', '65': 'fitting_room_interior', '17': 'music_store', '40': 'anechoic_chamber', '55': 'forest_needleleaf', '47': 'rest_area', '3': 'lido_deck_outdoor', '22': 'tennis_court_indoor', '20': 'tennis_court_outdoor', '24': 'subway_interior', '28': 'basketball_court_outdoor', '16': 'volleyball_court_indoor', '61': 'brewery_indoor', '41': 'batters_box', '1': 'baggage_claim', '29': 'squash_court', '19': 'wine_cellar_barrel_storage', '13': 'ranch_house', '57': 'liquor_store_outdoor', '30': 'hat_shop', '46': 'dinette_vehicle', '59': 'poolroom_home', '60': 'driving_range_outdoor', '63': 'podium_indoor', '4': 'hot_tub_outdoor', '23': 'casino_indoor', '54': 'oil_refinery_outdoor', '0': 'toll_plaza', '8': 'courtroom', '45': 'observatory_outdoor', '62': 'outhouse_outdoor', '34': 'electrical_substation', '7': 'cheese_factory', '26': 'badminton_court_indoor', '6': 'videostore', '33': 'loft', '36': 'factory_indoor', '18': 'limousine_interior', '35': 'thriftshop', '67': 'podium_outdoor', '64': 'theater_indoor_seats', '25': 'wine_cellar_bottle_storage', '9': 'elevator_interior', '14': 'promenade_deck', '52': 'power_plant_outdoor', '48': 'portrait_studio', '53': 'walk_in_freezer', '2': 'dentists_office', '11': 'teashop', '10': 'great_hall', '44': 'editing_room', '39': 'nuclear_power_plant_outdoor', '31': 'athletic_field_indoor', '27': 'optician', '49': 'covered_bridge_exterior', '38': 'bow_window_outdoor', '21': 'firing_range_indoor', '32': 'cybercafe', '12': 'labyrinth_outdoor', '42': 'chicken_coop_outdoor', '56': 'florist_shop_outdoor', '58': 'jail_indoor', '66': 'aquatic_theater', '37': 'shower_room', '68': 'synagogue_indoor'}\n"
     ]
    }
   ],
   "source": [
    "EXTRA_CATEGORIES_FILE=PLACES_DIR+'categories_extra69.txt'\n",
    "categories_to_dirs_extra=getCategories(EXTRA_CATEGORIES_FILE)\n",
    "print(categories_to_dirs_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation\n",
    "EXTRA_VAL_DATA_DIR = PLACES_DIR+'data_large_extra'\n",
    "EXTRA_VAL_DESCR_FILE=PLACES_DIR+'imglist_test.txt'\n",
    "save_links(EXTRA_VAL_DESCR_FILE, EXTRA_VAL_DATA_DIR,VAL_DATA_DIR,categories_to_dirs_extra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train\n",
    "EXTRA_TRAIN_DATA_DIR = PLACES_DIR+'data_large_extra'\n",
    "EXTRA_TRAIN_DESCR_FILE=PLACES_DIR+'imglist_train.txt'\n",
    "save_links(EXTRA_TRAIN_DESCR_FILE, EXTRA_TRAIN_DATA_DIR,TRAIN_DATA_DIR,categories_to_dirs_extra)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model,load_model,model_from_json\n",
    "from keras.applications import mobilenet,mobilenet_v2,densenet, xception, inception_resnet_v2,inception_v3,resnet, resnet_v2\n",
    "from keras.utils.generic_utils import CustomObjectScope\n",
    "from keras.layers import Flatten, Dense, Dropout,GlobalAveragePooling2D,Activation, Conv2D, Reshape,DepthwiseConv2D,Input\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint, TensorBoard, Callback, CSVLogger, EarlyStopping\n",
    "from keras.metrics import top_k_categorical_accuracy\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#from keras.preprocessing.image import ImageDataGenerator\n",
    "from myimage import ImageDataGenerator\n",
    "\n",
    "#net_model=mobilenet_v2\n",
    "#net_description='mobilenet2_alpha=1.0'\n",
    "#net_model=densenet\n",
    "#net_description='densenet121'\n",
    "#net_model=mobilenet\n",
    "#net_description='mobilenet_augm'\n",
    "#net_model=inception_resnet_v2\n",
    "#net_description='inception_resnet_v2'\n",
    "#net_model=inception_v3\n",
    "#net_description='inception_v3'\n",
    "#net_model=resnet_v2\n",
    "#net_description='resnet2_50'\n",
    "net_model=resnet\n",
    "net_description='resnet_101'\n",
    "\n",
    "net_description='places_'+net_description\n",
    "\n",
    "BATCH_SIZE=40 #512 #64 #32 #64\n",
    "\n",
    "def save_model(model,filename):\n",
    "    model.save_weights('weights.h5')\n",
    "    model_json = model.to_json()\n",
    "    with open(\"model.json\", \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "\n",
    "    json_file = open('model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    loaded_model.load_weights('weights.h5')\n",
    "    loaded_model.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "380\n"
     ]
    }
   ],
   "source": [
    "USE_EFFICENT_NET=True\n",
    "\n",
    "if USE_EFFICENT_NET:\n",
    "    import efficientnet.keras as enet\n",
    "\n",
    "    base_model = enet.EfficientNetB3(weights='imagenet')\n",
    "    #base_model.load_weights('/home/avsavchenko/distr/efficientnet/efficientnet-b3-weights.h5')\n",
    "\n",
    "    INPUT_SIZE = base_model.input_shape[1]\n",
    "    print(INPUT_SIZE)\n",
    "    INPUT_SIZE=(INPUT_SIZE,INPUT_SIZE)\n",
    "    target_size=INPUT_SIZE\n",
    "    preprocessing_function=enet.preprocess_input\n",
    "    net_description='enet3'\n",
    "else:\n",
    "    def random_crop(x, random_crop_size, sync_seed=None, **kwargs):\n",
    "        np.random.seed(sync_seed)\n",
    "        w, h = x.shape[1], x.shape[2]\n",
    "        rangew = (w - random_crop_size[0]) // 2\n",
    "        rangeh = (h - random_crop_size[1]) // 2\n",
    "        offsetw = 0 if rangew == 0 else np.random.randint(rangew)\n",
    "        offseth = 0 if rangeh == 0 else np.random.randint(rangeh)\n",
    "        return x[:, offsetw:offsetw+random_crop_size[0], offseth:offseth+random_crop_size[1]]\n",
    "\n",
    "    preprocessing_function=net_model.preprocess_input\n",
    "    target_size=INPUT_SIZE\n",
    "    #preprocessing_function,target_size=my_preprocessing,(256,256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MixupImageDataGenerator():\n",
    "    def __init__(self, generator, directory, batch_size, img_height, img_width, alpha=0.2, subset=None):\n",
    "        \"\"\"Constructor for mixup image data generator.\n",
    "\n",
    "        Arguments:\n",
    "            generator {object} -- An instance of Keras ImageDataGenerator.\n",
    "            directory {str} -- Image directory.\n",
    "            batch_size {int} -- Batch size.\n",
    "            img_height {int} -- Image height in pixels.\n",
    "            img_width {int} -- Image width in pixels.\n",
    "\n",
    "        Keyword Arguments:\n",
    "            alpha {float} -- Mixup beta distribution alpha parameter. (default: {0.2})\n",
    "            subset {str} -- 'training' or 'validation' if validation_split is specified in\n",
    "            `generator` (ImageDataGenerator).(default: {None})\n",
    "        \"\"\"\n",
    "\n",
    "        self.batch_index = 0\n",
    "        self.batch_size = batch_size\n",
    "        self.alpha = alpha\n",
    "\n",
    "        # First iterator yielding tuples of (x, y)\n",
    "        self.generator1 = generator.flow_from_directory(directory,\n",
    "                                                        #target_size=(img_height, img_width),\n",
    "                                                        target_size=img_height,\n",
    "                                                        class_mode=\"categorical\",\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        subset=subset,follow_links=True)\n",
    "\n",
    "        # Second iterator yielding tuples of (x, y)\n",
    "        self.generator2 = generator.flow_from_directory(directory,\n",
    "                                                        #target_size=(img_height, img_width),\n",
    "                                                        target_size=img_height,\n",
    "                                                        class_mode=\"categorical\",\n",
    "                                                        batch_size=batch_size,\n",
    "                                                        shuffle=True,\n",
    "                                                        subset=subset,follow_links=True)\n",
    "\n",
    "        # Number of images across all classes in image directory.\n",
    "        self.samples = self.generator1.samples\n",
    "        self.classes = self.generator1.classes\n",
    "\n",
    "    def reset_index(self):\n",
    "        \"\"\"Reset the generator indexes array.\n",
    "        \"\"\"\n",
    "\n",
    "        self.generator1._set_index_array()\n",
    "        self.generator2._set_index_array()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.reset_index()\n",
    "\n",
    "    def reset(self):\n",
    "        self.batch_index = 0\n",
    "\n",
    "    def __len__(self):\n",
    "        # round up\n",
    "        return (self.samples + self.batch_size - 1) // self.batch_size\n",
    "\n",
    "    def get_steps_per_epoch(self):\n",
    "        \"\"\"Get number of steps per epoch based on batch size and\n",
    "        number of images.\n",
    "\n",
    "        Returns:\n",
    "            int -- steps per epoch.\n",
    "        \"\"\"\n",
    "\n",
    "        return self.samples // self.batch_size\n",
    "\n",
    "    def __next__(self):\n",
    "        \"\"\"Get next batch input/output pair.\n",
    "\n",
    "        Returns:\n",
    "            tuple -- batch of input/output pair, (inputs, outputs).\n",
    "        \"\"\"\n",
    "\n",
    "        if self.batch_index == 0:\n",
    "            self.reset_index()\n",
    "\n",
    "        current_index = (self.batch_index * self.batch_size) % self.samples\n",
    "        if self.samples > current_index + self.batch_size:\n",
    "            self.batch_index += 1\n",
    "        else:\n",
    "            self.batch_index = 0\n",
    "\n",
    "        # Get a pair of inputs and outputs from two iterators.\n",
    "        X1, y1 = self.generator1.next()\n",
    "        X2, y2 = self.generator2.next()\n",
    "\n",
    "        \n",
    "        current_size=y1.shape[0] #self.batch_size\n",
    "        # random sample the lambda value from beta distribution.\n",
    "        l = np.random.beta(self.alpha, self.alpha, current_size)\n",
    "\n",
    "        X_l = l.reshape(current_size, 1, 1, 1)\n",
    "        y_l = l.reshape(current_size, 1)\n",
    "\n",
    "        # Perform the mixup.\n",
    "        X = X1 * X_l + X2 * (1 - X_l)\n",
    "        y = y1 * y_l + y2 * (1 - y_l)\n",
    "        return X, y\n",
    "\n",
    "    def __iter__(self):\n",
    "        while True:\n",
    "            yield next(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(featurewise_center=False, samplewise_center=False, featurewise_std_normalization=False, \n",
    "                                   samplewise_std_normalization=False, zca_whitening=False, zca_epsilon=1e-06,\n",
    "                                   rotation_range=0.1, width_shift_range=-0.1, height_shift_range=-0.1, brightness_range=None, shear_range=0.0, \n",
    "                                   zoom_range=0.1, channel_shift_range=1.05, fill_mode='nearest', horizontal_flip=True, vertical_flip=False,\n",
    "                                   preprocessing_function=preprocessing_function)\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocessing_function)\n",
    "\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocessing_function)\n",
    "\n",
    "mc = ModelCheckpoint(net_description+'_augm.h5', monitor='val_acc', verbose=1, save_best_only=True)\n",
    "tb = TensorBoard('logdir', write_graph=True, write_grads=True, write_images=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "del val_generator\n",
    "del train_generator\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43100 images belonging to 431 classes.\n",
      "enet4 /home/datasets/places/all_scenes/train\n",
      "Found 8125174 images belonging to 431 classes.\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE=8\n",
    "val_generator = test_datagen.flow_from_directory(\n",
    "    VAL_DATA_DIR, target_size=target_size,\n",
    "    batch_size=BATCH_SIZE, class_mode='categorical',follow_links=True)\n",
    "\n",
    "if True:\n",
    "    print(net_description,TRAIN_DATA_DIR)\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        TRAIN_DATA_DIR, target_size=target_size,\n",
    "        batch_size=BATCH_SIZE, class_mode='categorical',follow_links=True)\n",
    "else:\n",
    "    train_generator = MixupImageDataGenerator(generator=train_datagen,\n",
    "                                          directory=TRAIN_DATA_DIR,\n",
    "                                          batch_size=BATCH_SIZE,\n",
    "                                          img_height=INPUT_SIZE,\n",
    "                                          img_width=INPUT_SIZE,\n",
    "                                          alpha=0.2,\n",
    "                                          subset='training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431 8125174 43100\n",
      "{0: 'airfield', 1: 'airplane_cabin', 2: 'airport_terminal', 3: 'alcove', 4: 'alley', 5: 'amphitheater', 6: 'amusement_arcade', 7: 'amusement_park', 8: 'anechoic_chamber', 9: 'apartment_building_outdoor', 10: 'aquarium', 11: 'aqueduct', 12: 'arcade', 13: 'arch', 14: 'archaelogical_excavation', 15: 'archive', 16: 'arena_hockey', 17: 'arena_performance', 18: 'arena_rodeo', 19: 'army_base', 20: 'art_gallery', 21: 'art_school', 22: 'art_studio', 23: 'artists_loft', 24: 'assembly_line', 25: 'athletic_field_indoor', 26: 'athletic_field_outdoor', 27: 'atrium_public', 28: 'attic', 29: 'auditorium', 30: 'auto_factory', 31: 'auto_showroom', 32: 'badlands', 33: 'badminton_court_indoor', 34: 'baggage_claim', 35: 'bakery_shop', 36: 'balcony_exterior', 37: 'balcony_interior', 38: 'ball_pit', 39: 'ballroom', 40: 'bamboo_forest', 41: 'bank_vault', 42: 'banquet_hall', 43: 'bar', 44: 'barn', 45: 'barndoor', 46: 'baseball_field', 47: 'basement', 48: 'basketball_court_indoor', 49: 'basketball_court_outdoor', 50: 'bathroom', 51: 'batters_box', 52: 'bazaar_indoor', 53: 'bazaar_outdoor', 54: 'beach', 55: 'beach_house', 56: 'beauty_salon', 57: 'bedchamber', 58: 'bedroom', 59: 'beer_garden', 60: 'beer_hall', 61: 'berth', 62: 'biology_laboratory', 63: 'boardwalk', 64: 'boat_deck', 65: 'boathouse', 66: 'bookstore', 67: 'booth_indoor', 68: 'botanical_garden', 69: 'bow_window_indoor', 70: 'bow_window_outdoor', 71: 'bowling_alley', 72: 'boxing_ring', 73: 'brewery_indoor', 74: 'bridge', 75: 'building_facade', 76: 'bullring', 77: 'burial_chamber', 78: 'bus_interior', 79: 'bus_station_indoor', 80: 'butchers_shop', 81: 'butte', 82: 'cabin_outdoor', 83: 'cafeteria', 84: 'campsite', 85: 'campus', 86: 'canal_natural', 87: 'canal_urban', 88: 'candy_store', 89: 'canyon', 90: 'car_interior', 91: 'carrousel', 92: 'casino_indoor', 93: 'castle', 94: 'catacomb', 95: 'cemetery', 96: 'chalet', 97: 'cheese_factory', 98: 'chemistry_lab', 99: 'chicken_coop_outdoor', 100: 'childs_room', 101: 'church_indoor', 102: 'church_outdoor', 103: 'classroom', 104: 'clean_room', 105: 'cliff', 106: 'closet', 107: 'clothing_store', 108: 'coast', 109: 'cockpit', 110: 'coffee_shop', 111: 'computer_room', 112: 'conference_center', 113: 'conference_room', 114: 'construction_site', 115: 'corn_field', 116: 'corral', 117: 'corridor', 118: 'cottage', 119: 'courthouse', 120: 'courtroom', 121: 'courtyard', 122: 'covered_bridge_exterior', 123: 'creek', 124: 'crevasse', 125: 'crosswalk', 126: 'cybercafe', 127: 'dam', 128: 'delicatessen', 129: 'dentists_office', 130: 'department_store', 131: 'desert_road', 132: 'desert_sand', 133: 'desert_vegetation', 134: 'diner_outdoor', 135: 'dinette_vehicle', 136: 'dining_car', 137: 'dining_hall', 138: 'dining_room', 139: 'discotheque', 140: 'doorway_outdoor', 141: 'dorm_room', 142: 'downtown', 143: 'dressing_room', 144: 'driveway', 145: 'driving_range_outdoor', 146: 'drugstore', 147: 'editing_room', 148: 'electrical_substation', 149: 'elevator_door', 150: 'elevator_interior', 151: 'elevator_lobby', 152: 'elevator_shaft', 153: 'embassy', 154: 'engine_room', 155: 'entrance_hall', 156: 'escalator_indoor', 157: 'excavation', 158: 'fabric_store', 159: 'factory_indoor', 160: 'farm', 161: 'fastfood_restaurant', 162: 'field_cultivated', 163: 'field_road', 164: 'field_wild', 165: 'fire_escape', 166: 'fire_station', 167: 'firing_range_indoor', 168: 'fishpond', 169: 'fitting_room_interior', 170: 'flea_market_indoor', 171: 'florist_shop_indoor', 172: 'florist_shop_outdoor', 173: 'food_court', 174: 'football_field', 175: 'forest_broadleaf', 176: 'forest_needleleaf', 177: 'forest_path', 178: 'forest_road', 179: 'formal_garden', 180: 'fountain', 181: 'funeral_home', 182: 'galley', 183: 'garage_indoor', 184: 'garage_outdoor', 185: 'gas_station', 186: 'gazebo_exterior', 187: 'general_store_indoor', 188: 'general_store_outdoor', 189: 'gift_shop', 190: 'glacier', 191: 'golf_course', 192: 'great_hall', 193: 'greenhouse_indoor', 194: 'greenhouse_outdoor', 195: 'grotto', 196: 'gymnasium_indoor', 197: 'hangar_indoor', 198: 'hangar_outdoor', 199: 'harbor', 200: 'hardware_store', 201: 'hat_shop', 202: 'hayfield', 203: 'heliport', 204: 'highway', 205: 'home_office', 206: 'home_theater', 207: 'hospital', 208: 'hospital_room', 209: 'hot_spring', 210: 'hot_tub_indoor', 211: 'hot_tub_outdoor', 212: 'hotel_outdoor', 213: 'hotel_room', 214: 'house', 215: 'hunting_lodge_outdoor', 216: 'ice_cream_parlor', 217: 'ice_floe', 218: 'ice_shelf', 219: 'ice_skating_rink_indoor', 220: 'ice_skating_rink_outdoor', 221: 'iceberg', 222: 'igloo', 223: 'industrial_area', 224: 'inn_outdoor', 225: 'islet', 226: 'jacuzzi_indoor', 227: 'jail_cell', 228: 'jail_indoor', 229: 'japanese_garden', 230: 'jewelry_shop', 231: 'junkyard', 232: 'kasbah', 233: 'kennel_indoor', 234: 'kennel_outdoor', 235: 'kindergarden_classroom', 236: 'kitchen', 237: 'labyrinth_outdoor', 238: 'lagoon', 239: 'lake_natural', 240: 'landfill', 241: 'landing_deck', 242: 'laundromat', 243: 'lawn', 244: 'lecture_room', 245: 'legislative_chamber', 246: 'library_indoor', 247: 'library_outdoor', 248: 'lido_deck_outdoor', 249: 'lighthouse', 250: 'limousine_interior', 251: 'liquor_store_outdoor', 252: 'living_room', 253: 'loading_dock', 254: 'lobby', 255: 'lock_chamber', 256: 'locker_room', 257: 'loft', 258: 'mansion', 259: 'manufactured_home', 260: 'market_indoor', 261: 'market_outdoor', 262: 'marsh', 263: 'martial_arts_gym', 264: 'mausoleum', 265: 'medina', 266: 'mezzanine', 267: 'moat_water', 268: 'mosque_outdoor', 269: 'motel', 270: 'mountain', 271: 'mountain_path', 272: 'mountain_snowy', 273: 'movie_theater_indoor', 274: 'museum_indoor', 275: 'museum_outdoor', 276: 'music_store', 277: 'music_studio', 278: 'natural_history_museum', 279: 'nuclear_power_plant_outdoor', 280: 'nursery', 281: 'nursing_home', 282: 'oast_house', 283: 'observatory_outdoor', 284: 'ocean', 285: 'office', 286: 'office_building', 287: 'office_cubicles', 288: 'oil_refinery_outdoor', 289: 'oilrig', 290: 'operating_room', 291: 'optician', 292: 'orchard', 293: 'orchestra_pit', 294: 'outhouse_outdoor', 295: 'pagoda', 296: 'palace', 297: 'pantry', 298: 'park', 299: 'parking_garage_indoor', 300: 'parking_garage_outdoor', 301: 'parking_lot', 302: 'pasture', 303: 'patio', 304: 'pavilion', 305: 'pet_shop', 306: 'pharmacy', 307: 'phone_booth', 308: 'physics_laboratory', 309: 'picnic_area', 310: 'pier', 311: 'pizzeria', 312: 'playground', 313: 'playroom', 314: 'plaza', 315: 'podium_indoor', 316: 'pond', 317: 'poolroom_home', 318: 'porch', 319: 'portrait_studio', 320: 'power_plant_outdoor', 321: 'promenade', 322: 'promenade_deck', 323: 'pub_indoor', 324: 'racecourse', 325: 'raceway', 326: 'raft', 327: 'railroad_track', 328: 'rainforest', 329: 'ranch_house', 330: 'reception', 331: 'recreation_room', 332: 'repair_shop', 333: 'residential_neighborhood', 334: 'rest_area', 335: 'restaurant', 336: 'restaurant_kitchen', 337: 'restaurant_patio', 338: 'rice_paddy', 339: 'river', 340: 'rock_arch', 341: 'roof_garden', 342: 'rope_bridge', 343: 'ruin', 344: 'runway', 345: 'sandbox', 346: 'sauna', 347: 'schoolhouse', 348: 'science_museum', 349: 'server_room', 350: 'shed', 351: 'shoe_shop', 352: 'shopfront', 353: 'shopping_mall_indoor', 354: 'shower', 355: 'shower_room', 356: 'ski_resort', 357: 'ski_slope', 358: 'sky', 359: 'skyscraper', 360: 'slum', 361: 'snowfield', 362: 'soccer_field', 363: 'squash_court', 364: 'stable', 365: 'stadium_baseball', 366: 'stadium_football', 367: 'stadium_soccer', 368: 'stage_indoor', 369: 'stage_outdoor', 370: 'staircase', 371: 'storage_room', 372: 'street', 373: 'subway_interior', 374: 'subway_station_platform', 375: 'supermarket', 376: 'sushi_bar', 377: 'swamp', 378: 'swimming_hole', 379: 'swimming_pool_indoor', 380: 'swimming_pool_outdoor', 381: 'synagogue_outdoor', 382: 'teashop', 383: 'television_room', 384: 'television_studio', 385: 'temple_asia', 386: 'tennis_court_indoor', 387: 'tennis_court_outdoor', 388: 'theater_indoor_seats', 389: 'thriftshop', 390: 'throne_room', 391: 'ticket_booth', 392: 'toll_plaza', 393: 'topiary_garden', 394: 'tower', 395: 'toyshop', 396: 'train_interior', 397: 'train_station_platform', 398: 'tree_farm', 399: 'tree_house', 400: 'trench', 401: 'tundra', 402: 'underwater_ocean_deep', 403: 'utility_room', 404: 'valley', 405: 'vegetable_garden', 406: 'veterinarians_office', 407: 'viaduct', 408: 'videostore', 409: 'village', 410: 'vineyard', 411: 'volcano', 412: 'volleyball_court_indoor', 413: 'volleyball_court_outdoor', 414: 'waiting_room', 415: 'walk_in_freezer', 416: 'warehouse_indoor', 417: 'water_park', 418: 'water_tower', 419: 'waterfall', 420: 'watering_hole', 421: 'wave', 422: 'wet_bar', 423: 'wheat_field', 424: 'wind_farm', 425: 'windmill', 426: 'wine_cellar_barrel_storage', 427: 'wine_cellar_bottle_storage', 428: 'yard', 429: 'youth_hostel', 430: 'zen_garden'}\n"
     ]
    }
   ],
   "source": [
    "N_CLASS=val_generator.num_classes\n",
    "nb_train_samples=train_generator.samples\n",
    "nb_validation_samples=val_generator.samples\n",
    "print(N_CLASS,nb_train_samples,nb_validation_samples)\n",
    "\n",
    "class_to_idx=val_generator.class_indices\n",
    "idx_to_class={class_to_idx[cls]:cls for cls in class_to_idx}\n",
    "print(idx_to_class)\n",
    "\n",
    "#np.save('idx_to_class.npy',np.array(idx_to_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "               'balanced',\n",
    "                np.unique(train_generator.classes), \n",
    "                train_generator.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net():\n",
    "    if USE_EFFICENT_NET:\n",
    "        global base_model\n",
    "        x=base_model.layers[-2].output\n",
    "    else:\n",
    "        input_shape=(INPUT_SIZE[0],INPUT_SIZE[1],3)\n",
    "        #base_model = mobilenet.MobileNet(input_shape=input_shape, include_top=False, weights='imagenet', pooling='avg')\n",
    "        #base_model = mobilenetv2.MobileNetV2(alpha=1.0, input_shape=input_shape, include_top=False, weights='imagenet', pooling='avg')\n",
    "        #base_model = densenet.DenseNet121(input_shape=input_shape, include_top=False, weights='imagenet', pooling='avg')\n",
    "        #base_model = inception_resnet_v2.InceptionResNetV2(input_shape=input_shape, include_top=False, weights='imagenet', pooling='avg')\n",
    "        base_model = inception_v3.InceptionV3(input_shape=input_shape, include_top=False, weights='imagenet', pooling='avg')\n",
    "        #base_model = resnet_v2.ResNet50V2(input_shape=input_shape, include_top=False, weights='imagenet', pooling='avg')\n",
    "        #base_model = resnet.ResNet101(input_shape=input_shape, include_top=False, weights='imagenet', pooling='avg')\n",
    "    \n",
    "        x=base_model.output\n",
    "        \n",
    "    #x = Dropout(0.5)(x)\n",
    "    #N_CLASS=431\n",
    "    x = Dense(N_CLASS, activation='softmax', use_bias=True)(x)\n",
    "    model=Model(base_model.inputs, x)\n",
    "    return model,base_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model,base_model=net()\n",
    "\n",
    "start_epoch=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 300, 300, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 150, 150, 40) 1080        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 150, 150, 40) 160         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 150, 150, 40) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 150, 150, 40) 360         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 150, 150, 40) 160         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 150, 150, 40) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 40)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 40)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 10)     410         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 40)     440         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 150, 150, 40) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 150, 150, 24) 960         block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 150, 150, 24) 96          block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_dwconv (DepthwiseConv2D (None, 150, 150, 24) 216         block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_bn (BatchNormalization) (None, 150, 150, 24) 96          block1b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1b_activation (Activation) (None, 150, 150, 24) 0           block1b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_squeeze (GlobalAvera (None, 24)           0           block1b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reshape (Reshape)    (None, 1, 1, 24)     0           block1b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reduce (Conv2D)      (None, 1, 1, 6)      150         block1b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_expand (Conv2D)      (None, 1, 1, 24)     168         block1b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_excite (Multiply)    (None, 150, 150, 24) 0           block1b_activation[0][0]         \n",
      "                                                                 block1b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_conv (Conv2D)   (None, 150, 150, 24) 576         block1b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_bn (BatchNormal (None, 150, 150, 24) 96          block1b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_drop (FixedDropout)     (None, 150, 150, 24) 0           block1b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_add (Add)               (None, 150, 150, 24) 0           block1b_drop[0][0]               \n",
      "                                                                 block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 150, 150, 144 3456        block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 150, 150, 144 576         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 150, 150, 144 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 75, 75, 144)  1296        block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 75, 75, 144)  576         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 75, 75, 144)  0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 144)          0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 75, 75, 144)  0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 75, 75, 32)   4608        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 75, 75, 32)   128         block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 75, 75, 192)  6144        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 75, 75, 192)  768         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 75, 75, 192)  0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 75, 75, 192)  1728        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 75, 75, 192)  768         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 75, 75, 192)  0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 192)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 75, 75, 192)  0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 75, 75, 32)   6144        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 75, 75, 32)   128         block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (FixedDropout)     (None, 75, 75, 32)   0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 75, 75, 32)   0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_conv (Conv2D)    (None, 75, 75, 192)  6144        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_bn (BatchNormali (None, 75, 75, 192)  768         block2c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_activation (Acti (None, 75, 75, 192)  0           block2c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_dwconv (DepthwiseConv2D (None, 75, 75, 192)  1728        block2c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2c_bn (BatchNormalization) (None, 75, 75, 192)  768         block2c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2c_activation (Activation) (None, 75, 75, 192)  0           block2c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_squeeze (GlobalAvera (None, 192)          0           block2c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_excite (Multiply)    (None, 75, 75, 192)  0           block2c_activation[0][0]         \n",
      "                                                                 block2c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_conv (Conv2D)   (None, 75, 75, 32)   6144        block2c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_bn (BatchNormal (None, 75, 75, 32)   128         block2c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2c_drop (FixedDropout)     (None, 75, 75, 32)   0           block2c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_add (Add)               (None, 75, 75, 32)   0           block2c_drop[0][0]               \n",
      "                                                                 block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 75, 75, 192)  6144        block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 75, 75, 192)  768         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 75, 75, 192)  0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 38, 38, 192)  4800        block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 38, 38, 192)  768         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 38, 38, 192)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 192)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 192)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 38, 38, 192)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 38, 38, 48)   9216        block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 38, 38, 48)   192         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 38, 38, 288)  13824       block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 38, 38, 288)  1152        block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 38, 38, 288)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 38, 38, 288)  7200        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 38, 38, 288)  1152        block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 38, 38, 288)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 288)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 288)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 38, 38, 288)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 38, 38, 48)   13824       block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 38, 38, 48)   192         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (FixedDropout)     (None, 38, 38, 48)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 38, 38, 48)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_conv (Conv2D)    (None, 38, 38, 288)  13824       block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_bn (BatchNormali (None, 38, 38, 288)  1152        block3c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_activation (Acti (None, 38, 38, 288)  0           block3c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_dwconv (DepthwiseConv2D (None, 38, 38, 288)  7200        block3c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3c_bn (BatchNormalization) (None, 38, 38, 288)  1152        block3c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3c_activation (Activation) (None, 38, 38, 288)  0           block3c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_squeeze (GlobalAvera (None, 288)          0           block3c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reshape (Reshape)    (None, 1, 1, 288)    0           block3c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block3c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block3c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_excite (Multiply)    (None, 38, 38, 288)  0           block3c_activation[0][0]         \n",
      "                                                                 block3c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_conv (Conv2D)   (None, 38, 38, 48)   13824       block3c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_bn (BatchNormal (None, 38, 38, 48)   192         block3c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3c_drop (FixedDropout)     (None, 38, 38, 48)   0           block3c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_add (Add)               (None, 38, 38, 48)   0           block3c_drop[0][0]               \n",
      "                                                                 block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 38, 38, 288)  13824       block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 38, 38, 288)  1152        block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 38, 38, 288)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 19, 19, 288)  2592        block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 19, 19, 288)  1152        block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 19, 19, 288)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 288)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 288)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 12)     3468        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 288)    3744        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 19, 19, 288)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 19, 19, 96)   27648       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 19, 19, 96)   384         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 19, 19, 576)  55296       block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 19, 19, 576)  2304        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 19, 19, 576)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 19, 19, 576)  5184        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 19, 19, 576)  2304        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 19, 19, 576)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 576)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 576)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 19, 19, 576)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 19, 19, 96)   55296       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 19, 19, 96)   384         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (FixedDropout)     (None, 19, 19, 96)   0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 19, 19, 96)   0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 19, 19, 576)  55296       block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 19, 19, 576)  2304        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 19, 19, 576)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 19, 19, 576)  5184        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 19, 19, 576)  2304        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 19, 19, 576)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 576)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 576)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 19, 19, 576)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 19, 19, 96)   55296       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 19, 19, 96)   384         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (FixedDropout)     (None, 19, 19, 96)   0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 19, 19, 96)   0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_conv (Conv2D)    (None, 19, 19, 576)  55296       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_bn (BatchNormali (None, 19, 19, 576)  2304        block4d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_activation (Acti (None, 19, 19, 576)  0           block4d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_dwconv (DepthwiseConv2D (None, 19, 19, 576)  5184        block4d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4d_bn (BatchNormalization) (None, 19, 19, 576)  2304        block4d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4d_activation (Activation) (None, 19, 19, 576)  0           block4d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_squeeze (GlobalAvera (None, 576)          0           block4d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reshape (Reshape)    (None, 1, 1, 576)    0           block4d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block4d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block4d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_excite (Multiply)    (None, 19, 19, 576)  0           block4d_activation[0][0]         \n",
      "                                                                 block4d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_conv (Conv2D)   (None, 19, 19, 96)   55296       block4d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_bn (BatchNormal (None, 19, 19, 96)   384         block4d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4d_drop (FixedDropout)     (None, 19, 19, 96)   0           block4d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_add (Add)               (None, 19, 19, 96)   0           block4d_drop[0][0]               \n",
      "                                                                 block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_conv (Conv2D)    (None, 19, 19, 576)  55296       block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_bn (BatchNormali (None, 19, 19, 576)  2304        block4e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_activation (Acti (None, 19, 19, 576)  0           block4e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_dwconv (DepthwiseConv2D (None, 19, 19, 576)  5184        block4e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4e_bn (BatchNormalization) (None, 19, 19, 576)  2304        block4e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4e_activation (Activation) (None, 19, 19, 576)  0           block4e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_squeeze (GlobalAvera (None, 576)          0           block4e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reshape (Reshape)    (None, 1, 1, 576)    0           block4e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block4e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block4e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_excite (Multiply)    (None, 19, 19, 576)  0           block4e_activation[0][0]         \n",
      "                                                                 block4e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_conv (Conv2D)   (None, 19, 19, 96)   55296       block4e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_bn (BatchNormal (None, 19, 19, 96)   384         block4e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4e_drop (FixedDropout)     (None, 19, 19, 96)   0           block4e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_add (Add)               (None, 19, 19, 96)   0           block4e_drop[0][0]               \n",
      "                                                                 block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 19, 19, 576)  55296       block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 19, 19, 576)  2304        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 19, 19, 576)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 19, 19, 576)  14400       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 19, 19, 576)  2304        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 19, 19, 576)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 576)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 576)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 24)     13848       block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 576)    14400       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 19, 19, 576)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 19, 19, 136)  78336       block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 19, 19, 136)  544         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 19, 19, 816)  110976      block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 19, 19, 816)  3264        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 19, 19, 816)  0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 19, 19, 816)  20400       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 19, 19, 816)  3264        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 19, 19, 816)  0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 816)          0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 816)    0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 19, 19, 816)  0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 19, 19, 136)  110976      block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 19, 19, 136)  544         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (FixedDropout)     (None, 19, 19, 136)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 19, 19, 136)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 19, 19, 816)  110976      block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 19, 19, 816)  3264        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 19, 19, 816)  0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 19, 19, 816)  20400       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 19, 19, 816)  3264        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 19, 19, 816)  0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 816)          0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 816)    0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 19, 19, 816)  0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 19, 19, 136)  110976      block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 19, 19, 136)  544         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (FixedDropout)     (None, 19, 19, 136)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 19, 19, 136)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_conv (Conv2D)    (None, 19, 19, 816)  110976      block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_bn (BatchNormali (None, 19, 19, 816)  3264        block5d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_activation (Acti (None, 19, 19, 816)  0           block5d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_dwconv (DepthwiseConv2D (None, 19, 19, 816)  20400       block5d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5d_bn (BatchNormalization) (None, 19, 19, 816)  3264        block5d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5d_activation (Activation) (None, 19, 19, 816)  0           block5d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_squeeze (GlobalAvera (None, 816)          0           block5d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reshape (Reshape)    (None, 1, 1, 816)    0           block5d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block5d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block5d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_excite (Multiply)    (None, 19, 19, 816)  0           block5d_activation[0][0]         \n",
      "                                                                 block5d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_conv (Conv2D)   (None, 19, 19, 136)  110976      block5d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_bn (BatchNormal (None, 19, 19, 136)  544         block5d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5d_drop (FixedDropout)     (None, 19, 19, 136)  0           block5d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_add (Add)               (None, 19, 19, 136)  0           block5d_drop[0][0]               \n",
      "                                                                 block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_conv (Conv2D)    (None, 19, 19, 816)  110976      block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_bn (BatchNormali (None, 19, 19, 816)  3264        block5e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_activation (Acti (None, 19, 19, 816)  0           block5e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_dwconv (DepthwiseConv2D (None, 19, 19, 816)  20400       block5e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5e_bn (BatchNormalization) (None, 19, 19, 816)  3264        block5e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5e_activation (Activation) (None, 19, 19, 816)  0           block5e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_squeeze (GlobalAvera (None, 816)          0           block5e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reshape (Reshape)    (None, 1, 1, 816)    0           block5e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block5e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block5e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_excite (Multiply)    (None, 19, 19, 816)  0           block5e_activation[0][0]         \n",
      "                                                                 block5e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_conv (Conv2D)   (None, 19, 19, 136)  110976      block5e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_bn (BatchNormal (None, 19, 19, 136)  544         block5e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5e_drop (FixedDropout)     (None, 19, 19, 136)  0           block5e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_add (Add)               (None, 19, 19, 136)  0           block5e_drop[0][0]               \n",
      "                                                                 block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 19, 19, 816)  110976      block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 19, 19, 816)  3264        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 19, 19, 816)  0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 10, 10, 816)  20400       block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 10, 10, 816)  3264        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 10, 10, 816)  0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 816)          0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 816)    0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 34)     27778       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 816)    28560       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 10, 10, 816)  0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 10, 10, 232)  189312      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 10, 10, 232)  928         block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 10, 10, 1392) 322944      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 10, 10, 1392) 5568        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 10, 10, 1392) 0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 10, 10, 1392) 34800       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 10, 10, 1392) 5568        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 10, 10, 1392) 0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 1392)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 10, 10, 1392) 0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 10, 10, 232)  322944      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 10, 10, 232)  928         block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (FixedDropout)     (None, 10, 10, 232)  0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 10, 10, 232)  0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 10, 10, 1392) 322944      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 10, 10, 1392) 5568        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 10, 10, 1392) 0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 10, 10, 1392) 34800       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 10, 10, 1392) 5568        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 10, 10, 1392) 0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1392)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 10, 10, 1392) 0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 10, 10, 232)  322944      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 10, 10, 232)  928         block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (FixedDropout)     (None, 10, 10, 232)  0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 10, 10, 232)  0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 10, 10, 1392) 322944      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 10, 10, 1392) 5568        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 10, 10, 1392) 0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 10, 10, 1392) 34800       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 10, 10, 1392) 5568        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 10, 10, 1392) 0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1392)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 10, 10, 1392) 0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 10, 10, 232)  322944      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 10, 10, 232)  928         block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (FixedDropout)     (None, 10, 10, 232)  0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 10, 10, 232)  0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_conv (Conv2D)    (None, 10, 10, 1392) 322944      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_bn (BatchNormali (None, 10, 10, 1392) 5568        block6e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_activation (Acti (None, 10, 10, 1392) 0           block6e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_dwconv (DepthwiseConv2D (None, 10, 10, 1392) 34800       block6e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6e_bn (BatchNormalization) (None, 10, 10, 1392) 5568        block6e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6e_activation (Activation) (None, 10, 10, 1392) 0           block6e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_squeeze (GlobalAvera (None, 1392)         0           block6e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_excite (Multiply)    (None, 10, 10, 1392) 0           block6e_activation[0][0]         \n",
      "                                                                 block6e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_conv (Conv2D)   (None, 10, 10, 232)  322944      block6e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_bn (BatchNormal (None, 10, 10, 232)  928         block6e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6e_drop (FixedDropout)     (None, 10, 10, 232)  0           block6e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_add (Add)               (None, 10, 10, 232)  0           block6e_drop[0][0]               \n",
      "                                                                 block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_conv (Conv2D)    (None, 10, 10, 1392) 322944      block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_bn (BatchNormali (None, 10, 10, 1392) 5568        block6f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_activation (Acti (None, 10, 10, 1392) 0           block6f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_dwconv (DepthwiseConv2D (None, 10, 10, 1392) 34800       block6f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6f_bn (BatchNormalization) (None, 10, 10, 1392) 5568        block6f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6f_activation (Activation) (None, 10, 10, 1392) 0           block6f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_squeeze (GlobalAvera (None, 1392)         0           block6f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block6f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block6f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block6f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_excite (Multiply)    (None, 10, 10, 1392) 0           block6f_activation[0][0]         \n",
      "                                                                 block6f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_conv (Conv2D)   (None, 10, 10, 232)  322944      block6f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_bn (BatchNormal (None, 10, 10, 232)  928         block6f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6f_drop (FixedDropout)     (None, 10, 10, 232)  0           block6f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_add (Add)               (None, 10, 10, 232)  0           block6f_drop[0][0]               \n",
      "                                                                 block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 10, 10, 1392) 322944      block6f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 10, 10, 1392) 5568        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 10, 10, 1392) 0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 10, 10, 1392) 12528       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 10, 10, 1392) 5568        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 10, 10, 1392) 0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 1392)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 1392)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 58)     80794       block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 1392)   82128       block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 10, 10, 1392) 0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 10, 10, 384)  534528      block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 10, 10, 384)  1536        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_conv (Conv2D)    (None, 10, 10, 2304) 884736      block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_bn (BatchNormali (None, 10, 10, 2304) 9216        block7b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_activation (Acti (None, 10, 10, 2304) 0           block7b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_dwconv (DepthwiseConv2D (None, 10, 10, 2304) 20736       block7b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7b_bn (BatchNormalization) (None, 10, 10, 2304) 9216        block7b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7b_activation (Activation) (None, 10, 10, 2304) 0           block7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_squeeze (GlobalAvera (None, 2304)         0           block7b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reshape (Reshape)    (None, 1, 1, 2304)   0           block7b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reduce (Conv2D)      (None, 1, 1, 96)     221280      block7b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_expand (Conv2D)      (None, 1, 1, 2304)   223488      block7b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_excite (Multiply)    (None, 10, 10, 2304) 0           block7b_activation[0][0]         \n",
      "                                                                 block7b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_conv (Conv2D)   (None, 10, 10, 384)  884736      block7b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_bn (BatchNormal (None, 10, 10, 384)  1536        block7b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_drop (FixedDropout)     (None, 10, 10, 384)  0           block7b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_add (Add)               (None, 10, 10, 384)  0           block7b_drop[0][0]               \n",
      "                                                                 block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 10, 10, 1536) 589824      block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 10, 10, 1536) 6144        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 10, 10, 1536) 0           top_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1536)         0           top_activation[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "top_dropout (Dropout)           (None, 1536)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 431)          662447      top_dropout[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 11,445,975\n",
      "Trainable params: 662,447\n",
      "Non-trainable params: 10,783,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      " 31471/203129 [===>..........................] - ETA: 71:36:14 - loss: 2.9920 - acc: 0.3197 - top_k_categorical_accuracy: 0.6120"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-50807f05653f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mFIRST_EPOCHS\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m hist1=model.fit_generator(train_generator, steps_per_epoch=nb_train_samples//BATCH_SIZE, epochs=FIRST_EPOCHS, verbose=1, \n\u001b[0;32m---> 12\u001b[0;31m                     initial_epoch=0, callbacks=[tb, mc, es], validation_data=val_generator, validation_steps=nb_validation_samples // BATCH_SIZE,class_weight=class_weights)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for l in base_model.layers:\n",
    "    l.trainable=False\n",
    "model.compile('adam', 'categorical_crossentropy', metrics=['accuracy',top_k_categorical_accuracy])\n",
    "model.summary()\n",
    "\n",
    "mc = ModelCheckpoint(net_description+'_augm.h5', monitor='val_acc', verbose=1, save_best_only=True)\n",
    "\n",
    "es=EarlyStopping(monitor='val_acc',patience=2)\n",
    "FIRST_EPOCHS=1\n",
    "hist1=model.fit_generator(train_generator, steps_per_epoch=nb_train_samples//BATCH_SIZE, epochs=FIRST_EPOCHS, verbose=1, \n",
    "                    initial_epoch=0, callbacks=[tb, mc, es], validation_data=val_generator, validation_steps=nb_validation_samples // BATCH_SIZE,class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_epoch=len(hist1.history['loss'])\n",
    "model.load_weights(net_description+'_augm.h5')\n",
    "for l in base_model.layers:\n",
    "    l.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 380, 380, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 190, 190, 48) 1296        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 190, 190, 48) 192         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 190, 190, 48) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 190, 190, 48) 432         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 190, 190, 48) 192         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 190, 190, 48) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 48)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 48)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 12)     588         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 48)     624         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 190, 190, 48) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 190, 190, 24) 1152        block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 190, 190, 24) 96          block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_dwconv (DepthwiseConv2D (None, 190, 190, 24) 216         block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_bn (BatchNormalization) (None, 190, 190, 24) 96          block1b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1b_activation (Activation) (None, 190, 190, 24) 0           block1b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_squeeze (GlobalAvera (None, 24)           0           block1b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reshape (Reshape)    (None, 1, 1, 24)     0           block1b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reduce (Conv2D)      (None, 1, 1, 6)      150         block1b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_expand (Conv2D)      (None, 1, 1, 24)     168         block1b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_excite (Multiply)    (None, 190, 190, 24) 0           block1b_activation[0][0]         \n",
      "                                                                 block1b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_conv (Conv2D)   (None, 190, 190, 24) 576         block1b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_bn (BatchNormal (None, 190, 190, 24) 96          block1b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_drop (FixedDropout)     (None, 190, 190, 24) 0           block1b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_add (Add)               (None, 190, 190, 24) 0           block1b_drop[0][0]               \n",
      "                                                                 block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 190, 190, 144 3456        block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 190, 190, 144 576         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 190, 190, 144 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 95, 95, 144)  1296        block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 95, 95, 144)  576         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 95, 95, 144)  0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 144)          0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 95, 95, 144)  0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 95, 95, 32)   4608        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 95, 95, 32)   128         block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 95, 95, 192)  6144        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 95, 95, 192)  768         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 95, 95, 192)  0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 95, 95, 192)  1728        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 95, 95, 192)  768         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 95, 95, 192)  0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 192)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 95, 95, 192)  0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 95, 95, 32)   6144        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 95, 95, 32)   128         block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (FixedDropout)     (None, 95, 95, 32)   0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 95, 95, 32)   0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_conv (Conv2D)    (None, 95, 95, 192)  6144        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_bn (BatchNormali (None, 95, 95, 192)  768         block2c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_activation (Acti (None, 95, 95, 192)  0           block2c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_dwconv (DepthwiseConv2D (None, 95, 95, 192)  1728        block2c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2c_bn (BatchNormalization) (None, 95, 95, 192)  768         block2c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2c_activation (Activation) (None, 95, 95, 192)  0           block2c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_squeeze (GlobalAvera (None, 192)          0           block2c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_excite (Multiply)    (None, 95, 95, 192)  0           block2c_activation[0][0]         \n",
      "                                                                 block2c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_conv (Conv2D)   (None, 95, 95, 32)   6144        block2c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_bn (BatchNormal (None, 95, 95, 32)   128         block2c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2c_drop (FixedDropout)     (None, 95, 95, 32)   0           block2c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_add (Add)               (None, 95, 95, 32)   0           block2c_drop[0][0]               \n",
      "                                                                 block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_conv (Conv2D)    (None, 95, 95, 192)  6144        block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_bn (BatchNormali (None, 95, 95, 192)  768         block2d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_activation (Acti (None, 95, 95, 192)  0           block2d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_dwconv (DepthwiseConv2D (None, 95, 95, 192)  1728        block2d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2d_bn (BatchNormalization) (None, 95, 95, 192)  768         block2d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2d_activation (Activation) (None, 95, 95, 192)  0           block2d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_squeeze (GlobalAvera (None, 192)          0           block2d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_excite (Multiply)    (None, 95, 95, 192)  0           block2d_activation[0][0]         \n",
      "                                                                 block2d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_project_conv (Conv2D)   (None, 95, 95, 32)   6144        block2d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_project_bn (BatchNormal (None, 95, 95, 32)   128         block2d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2d_drop (FixedDropout)     (None, 95, 95, 32)   0           block2d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_add (Add)               (None, 95, 95, 32)   0           block2d_drop[0][0]               \n",
      "                                                                 block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 95, 95, 192)  6144        block2d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 95, 95, 192)  768         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 95, 95, 192)  0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 48, 48, 192)  4800        block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 48, 48, 192)  768         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 48, 48, 192)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 192)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 192)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 48, 48, 192)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 48, 48, 56)   10752       block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 48, 48, 56)   224         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 48, 48, 336)  18816       block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 48, 48, 336)  1344        block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 48, 48, 336)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 48, 48, 336)  8400        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 48, 48, 336)  1344        block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 48, 48, 336)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 336)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 336)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 14)     4718        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 336)    5040        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 48, 48, 336)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 48, 48, 56)   18816       block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 48, 48, 56)   224         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (FixedDropout)     (None, 48, 48, 56)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 48, 48, 56)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_conv (Conv2D)    (None, 48, 48, 336)  18816       block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_bn (BatchNormali (None, 48, 48, 336)  1344        block3c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_activation (Acti (None, 48, 48, 336)  0           block3c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_dwconv (DepthwiseConv2D (None, 48, 48, 336)  8400        block3c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3c_bn (BatchNormalization) (None, 48, 48, 336)  1344        block3c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3c_activation (Activation) (None, 48, 48, 336)  0           block3c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_squeeze (GlobalAvera (None, 336)          0           block3c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reshape (Reshape)    (None, 1, 1, 336)    0           block3c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reduce (Conv2D)      (None, 1, 1, 14)     4718        block3c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_expand (Conv2D)      (None, 1, 1, 336)    5040        block3c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_excite (Multiply)    (None, 48, 48, 336)  0           block3c_activation[0][0]         \n",
      "                                                                 block3c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_conv (Conv2D)   (None, 48, 48, 56)   18816       block3c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_bn (BatchNormal (None, 48, 48, 56)   224         block3c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3c_drop (FixedDropout)     (None, 48, 48, 56)   0           block3c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_add (Add)               (None, 48, 48, 56)   0           block3c_drop[0][0]               \n",
      "                                                                 block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_conv (Conv2D)    (None, 48, 48, 336)  18816       block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_bn (BatchNormali (None, 48, 48, 336)  1344        block3d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_activation (Acti (None, 48, 48, 336)  0           block3d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_dwconv (DepthwiseConv2D (None, 48, 48, 336)  8400        block3d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3d_bn (BatchNormalization) (None, 48, 48, 336)  1344        block3d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3d_activation (Activation) (None, 48, 48, 336)  0           block3d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_squeeze (GlobalAvera (None, 336)          0           block3d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_reshape (Reshape)    (None, 1, 1, 336)    0           block3d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_reduce (Conv2D)      (None, 1, 1, 14)     4718        block3d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_expand (Conv2D)      (None, 1, 1, 336)    5040        block3d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_excite (Multiply)    (None, 48, 48, 336)  0           block3d_activation[0][0]         \n",
      "                                                                 block3d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_project_conv (Conv2D)   (None, 48, 48, 56)   18816       block3d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_project_bn (BatchNormal (None, 48, 48, 56)   224         block3d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3d_drop (FixedDropout)     (None, 48, 48, 56)   0           block3d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_add (Add)               (None, 48, 48, 56)   0           block3d_drop[0][0]               \n",
      "                                                                 block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 48, 48, 336)  18816       block3d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 48, 48, 336)  1344        block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 48, 48, 336)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 24, 24, 336)  3024        block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 24, 24, 336)  1344        block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 24, 24, 336)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 336)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 336)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 14)     4718        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 336)    5040        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 24, 24, 336)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 24, 24, 112)  37632       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 24, 24, 112)  448         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 24, 24, 672)  75264       block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 24, 24, 672)  2688        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 24, 24, 672)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 24, 24, 672)  6048        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 24, 24, 672)  2688        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 24, 24, 672)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 672)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 672)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 24, 24, 672)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 24, 24, 112)  75264       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 24, 24, 112)  448         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (FixedDropout)     (None, 24, 24, 112)  0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 24, 24, 112)  0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 24, 24, 672)  75264       block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 24, 24, 672)  2688        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 24, 24, 672)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 24, 24, 672)  6048        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 24, 24, 672)  2688        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 24, 24, 672)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 672)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 672)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 24, 24, 672)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 24, 24, 112)  75264       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 24, 24, 112)  448         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (FixedDropout)     (None, 24, 24, 112)  0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 24, 24, 112)  0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_conv (Conv2D)    (None, 24, 24, 672)  75264       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_bn (BatchNormali (None, 24, 24, 672)  2688        block4d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_activation (Acti (None, 24, 24, 672)  0           block4d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_dwconv (DepthwiseConv2D (None, 24, 24, 672)  6048        block4d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4d_bn (BatchNormalization) (None, 24, 24, 672)  2688        block4d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4d_activation (Activation) (None, 24, 24, 672)  0           block4d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_squeeze (GlobalAvera (None, 672)          0           block4d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reshape (Reshape)    (None, 1, 1, 672)    0           block4d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block4d_se_reshape[0][0]         \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "block4d_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block4d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_excite (Multiply)    (None, 24, 24, 672)  0           block4d_activation[0][0]         \n",
      "                                                                 block4d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_conv (Conv2D)   (None, 24, 24, 112)  75264       block4d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_bn (BatchNormal (None, 24, 24, 112)  448         block4d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4d_drop (FixedDropout)     (None, 24, 24, 112)  0           block4d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_add (Add)               (None, 24, 24, 112)  0           block4d_drop[0][0]               \n",
      "                                                                 block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_conv (Conv2D)    (None, 24, 24, 672)  75264       block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_bn (BatchNormali (None, 24, 24, 672)  2688        block4e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_activation (Acti (None, 24, 24, 672)  0           block4e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_dwconv (DepthwiseConv2D (None, 24, 24, 672)  6048        block4e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4e_bn (BatchNormalization) (None, 24, 24, 672)  2688        block4e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4e_activation (Activation) (None, 24, 24, 672)  0           block4e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_squeeze (GlobalAvera (None, 672)          0           block4e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reshape (Reshape)    (None, 1, 1, 672)    0           block4e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block4e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block4e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_excite (Multiply)    (None, 24, 24, 672)  0           block4e_activation[0][0]         \n",
      "                                                                 block4e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_conv (Conv2D)   (None, 24, 24, 112)  75264       block4e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_bn (BatchNormal (None, 24, 24, 112)  448         block4e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4e_drop (FixedDropout)     (None, 24, 24, 112)  0           block4e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_add (Add)               (None, 24, 24, 112)  0           block4e_drop[0][0]               \n",
      "                                                                 block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_conv (Conv2D)    (None, 24, 24, 672)  75264       block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_bn (BatchNormali (None, 24, 24, 672)  2688        block4f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_activation (Acti (None, 24, 24, 672)  0           block4f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_dwconv (DepthwiseConv2D (None, 24, 24, 672)  6048        block4f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4f_bn (BatchNormalization) (None, 24, 24, 672)  2688        block4f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4f_activation (Activation) (None, 24, 24, 672)  0           block4f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_squeeze (GlobalAvera (None, 672)          0           block4f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_reshape (Reshape)    (None, 1, 1, 672)    0           block4f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block4f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block4f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_excite (Multiply)    (None, 24, 24, 672)  0           block4f_activation[0][0]         \n",
      "                                                                 block4f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_project_conv (Conv2D)   (None, 24, 24, 112)  75264       block4f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_project_bn (BatchNormal (None, 24, 24, 112)  448         block4f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4f_drop (FixedDropout)     (None, 24, 24, 112)  0           block4f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_add (Add)               (None, 24, 24, 112)  0           block4f_drop[0][0]               \n",
      "                                                                 block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 24, 24, 672)  75264       block4f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 24, 24, 672)  2688        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 24, 24, 672)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 24, 24, 672)  16800       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 24, 24, 672)  2688        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 24, 24, 672)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 672)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 24, 24, 672)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 24, 24, 160)  107520      block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 24, 24, 160)  640         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 24, 24, 960)  153600      block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 24, 24, 960)  3840        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 24, 24, 960)  0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 24, 24, 960)  24000       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 24, 24, 960)  3840        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 24, 24, 960)  0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 960)          0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 960)    0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 24, 24, 960)  0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 24, 24, 160)  153600      block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 24, 24, 160)  640         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (FixedDropout)     (None, 24, 24, 160)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 24, 24, 160)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 24, 24, 960)  153600      block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 24, 24, 960)  3840        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 24, 24, 960)  0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 24, 24, 960)  24000       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 24, 24, 960)  3840        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 24, 24, 960)  0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 960)          0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 960)    0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 24, 24, 960)  0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 24, 24, 160)  153600      block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 24, 24, 160)  640         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (FixedDropout)     (None, 24, 24, 160)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 24, 24, 160)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_conv (Conv2D)    (None, 24, 24, 960)  153600      block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_bn (BatchNormali (None, 24, 24, 960)  3840        block5d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_activation (Acti (None, 24, 24, 960)  0           block5d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_dwconv (DepthwiseConv2D (None, 24, 24, 960)  24000       block5d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5d_bn (BatchNormalization) (None, 24, 24, 960)  3840        block5d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5d_activation (Activation) (None, 24, 24, 960)  0           block5d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_squeeze (GlobalAvera (None, 960)          0           block5d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reshape (Reshape)    (None, 1, 1, 960)    0           block5d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block5d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block5d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_excite (Multiply)    (None, 24, 24, 960)  0           block5d_activation[0][0]         \n",
      "                                                                 block5d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_conv (Conv2D)   (None, 24, 24, 160)  153600      block5d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_bn (BatchNormal (None, 24, 24, 160)  640         block5d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5d_drop (FixedDropout)     (None, 24, 24, 160)  0           block5d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_add (Add)               (None, 24, 24, 160)  0           block5d_drop[0][0]               \n",
      "                                                                 block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_conv (Conv2D)    (None, 24, 24, 960)  153600      block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_bn (BatchNormali (None, 24, 24, 960)  3840        block5e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_activation (Acti (None, 24, 24, 960)  0           block5e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_dwconv (DepthwiseConv2D (None, 24, 24, 960)  24000       block5e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5e_bn (BatchNormalization) (None, 24, 24, 960)  3840        block5e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5e_activation (Activation) (None, 24, 24, 960)  0           block5e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_squeeze (GlobalAvera (None, 960)          0           block5e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reshape (Reshape)    (None, 1, 1, 960)    0           block5e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block5e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block5e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_excite (Multiply)    (None, 24, 24, 960)  0           block5e_activation[0][0]         \n",
      "                                                                 block5e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_conv (Conv2D)   (None, 24, 24, 160)  153600      block5e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_bn (BatchNormal (None, 24, 24, 160)  640         block5e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5e_drop (FixedDropout)     (None, 24, 24, 160)  0           block5e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_add (Add)               (None, 24, 24, 160)  0           block5e_drop[0][0]               \n",
      "                                                                 block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_conv (Conv2D)    (None, 24, 24, 960)  153600      block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_bn (BatchNormali (None, 24, 24, 960)  3840        block5f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_activation (Acti (None, 24, 24, 960)  0           block5f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_dwconv (DepthwiseConv2D (None, 24, 24, 960)  24000       block5f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5f_bn (BatchNormalization) (None, 24, 24, 960)  3840        block5f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5f_activation (Activation) (None, 24, 24, 960)  0           block5f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_squeeze (GlobalAvera (None, 960)          0           block5f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_reshape (Reshape)    (None, 1, 1, 960)    0           block5f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block5f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block5f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_excite (Multiply)    (None, 24, 24, 960)  0           block5f_activation[0][0]         \n",
      "                                                                 block5f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_project_conv (Conv2D)   (None, 24, 24, 160)  153600      block5f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_project_bn (BatchNormal (None, 24, 24, 160)  640         block5f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5f_drop (FixedDropout)     (None, 24, 24, 160)  0           block5f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_add (Add)               (None, 24, 24, 160)  0           block5f_drop[0][0]               \n",
      "                                                                 block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 24, 24, 960)  153600      block5f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 24, 24, 960)  3840        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 24, 24, 960)  0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 12, 12, 960)  24000       block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 12, 12, 960)  3840        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 12, 12, 960)  0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 960)          0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 960)    0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 12, 12, 960)  0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 12, 12, 272)  261120      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 12, 12, 272)  1088        block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 12, 12, 1632) 443904      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 12, 12, 1632) 6528        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 12, 12, 1632) 0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 12, 12, 1632) 40800       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 12, 12, 1632) 6528        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 12, 12, 1632) 0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 1632)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 1632)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 68)     111044      block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 1632)   112608      block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 12, 12, 1632) 0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 12, 12, 272)  443904      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 12, 12, 272)  1088        block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (FixedDropout)     (None, 12, 12, 272)  0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 12, 12, 272)  0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 12, 12, 1632) 443904      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 12, 12, 1632) 6528        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 12, 12, 1632) 0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 12, 12, 1632) 40800       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 12, 12, 1632) 6528        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 12, 12, 1632) 0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1632)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1632)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 68)     111044      block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1632)   112608      block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 12, 12, 1632) 0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 12, 12, 272)  443904      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 12, 12, 272)  1088        block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (FixedDropout)     (None, 12, 12, 272)  0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 12, 12, 272)  0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 12, 12, 1632) 443904      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 12, 12, 1632) 6528        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 12, 12, 1632) 0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 12, 12, 1632) 40800       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 12, 12, 1632) 6528        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 12, 12, 1632) 0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1632)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1632)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 68)     111044      block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1632)   112608      block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 12, 12, 1632) 0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 12, 12, 272)  443904      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 12, 12, 272)  1088        block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (FixedDropout)     (None, 12, 12, 272)  0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 12, 12, 272)  0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_conv (Conv2D)    (None, 12, 12, 1632) 443904      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_bn (BatchNormali (None, 12, 12, 1632) 6528        block6e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_activation (Acti (None, 12, 12, 1632) 0           block6e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_dwconv (DepthwiseConv2D (None, 12, 12, 1632) 40800       block6e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6e_bn (BatchNormalization) (None, 12, 12, 1632) 6528        block6e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6e_activation (Activation) (None, 12, 12, 1632) 0           block6e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_squeeze (GlobalAvera (None, 1632)         0           block6e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reshape (Reshape)    (None, 1, 1, 1632)   0           block6e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reduce (Conv2D)      (None, 1, 1, 68)     111044      block6e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_expand (Conv2D)      (None, 1, 1, 1632)   112608      block6e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_excite (Multiply)    (None, 12, 12, 1632) 0           block6e_activation[0][0]         \n",
      "                                                                 block6e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_conv (Conv2D)   (None, 12, 12, 272)  443904      block6e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_bn (BatchNormal (None, 12, 12, 272)  1088        block6e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6e_drop (FixedDropout)     (None, 12, 12, 272)  0           block6e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_add (Add)               (None, 12, 12, 272)  0           block6e_drop[0][0]               \n",
      "                                                                 block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_conv (Conv2D)    (None, 12, 12, 1632) 443904      block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_bn (BatchNormali (None, 12, 12, 1632) 6528        block6f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_activation (Acti (None, 12, 12, 1632) 0           block6f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_dwconv (DepthwiseConv2D (None, 12, 12, 1632) 40800       block6f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6f_bn (BatchNormalization) (None, 12, 12, 1632) 6528        block6f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6f_activation (Activation) (None, 12, 12, 1632) 0           block6f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_squeeze (GlobalAvera (None, 1632)         0           block6f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reshape (Reshape)    (None, 1, 1, 1632)   0           block6f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reduce (Conv2D)      (None, 1, 1, 68)     111044      block6f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_expand (Conv2D)      (None, 1, 1, 1632)   112608      block6f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_excite (Multiply)    (None, 12, 12, 1632) 0           block6f_activation[0][0]         \n",
      "                                                                 block6f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_conv (Conv2D)   (None, 12, 12, 272)  443904      block6f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_bn (BatchNormal (None, 12, 12, 272)  1088        block6f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6f_drop (FixedDropout)     (None, 12, 12, 272)  0           block6f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_add (Add)               (None, 12, 12, 272)  0           block6f_drop[0][0]               \n",
      "                                                                 block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_conv (Conv2D)    (None, 12, 12, 1632) 443904      block6f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_bn (BatchNormali (None, 12, 12, 1632) 6528        block6g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_activation (Acti (None, 12, 12, 1632) 0           block6g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_dwconv (DepthwiseConv2D (None, 12, 12, 1632) 40800       block6g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6g_bn (BatchNormalization) (None, 12, 12, 1632) 6528        block6g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6g_activation (Activation) (None, 12, 12, 1632) 0           block6g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_squeeze (GlobalAvera (None, 1632)         0           block6g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_reshape (Reshape)    (None, 1, 1, 1632)   0           block6g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_reduce (Conv2D)      (None, 1, 1, 68)     111044      block6g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_expand (Conv2D)      (None, 1, 1, 1632)   112608      block6g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_excite (Multiply)    (None, 12, 12, 1632) 0           block6g_activation[0][0]         \n",
      "                                                                 block6g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_project_conv (Conv2D)   (None, 12, 12, 272)  443904      block6g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_project_bn (BatchNormal (None, 12, 12, 272)  1088        block6g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6g_drop (FixedDropout)     (None, 12, 12, 272)  0           block6g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_add (Add)               (None, 12, 12, 272)  0           block6g_drop[0][0]               \n",
      "                                                                 block6f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_conv (Conv2D)    (None, 12, 12, 1632) 443904      block6g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_bn (BatchNormali (None, 12, 12, 1632) 6528        block6h_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_activation (Acti (None, 12, 12, 1632) 0           block6h_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_dwconv (DepthwiseConv2D (None, 12, 12, 1632) 40800       block6h_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6h_bn (BatchNormalization) (None, 12, 12, 1632) 6528        block6h_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6h_activation (Activation) (None, 12, 12, 1632) 0           block6h_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_squeeze (GlobalAvera (None, 1632)         0           block6h_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_reshape (Reshape)    (None, 1, 1, 1632)   0           block6h_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_reduce (Conv2D)      (None, 1, 1, 68)     111044      block6h_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_expand (Conv2D)      (None, 1, 1, 1632)   112608      block6h_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_excite (Multiply)    (None, 12, 12, 1632) 0           block6h_activation[0][0]         \n",
      "                                                                 block6h_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_project_conv (Conv2D)   (None, 12, 12, 272)  443904      block6h_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_project_bn (BatchNormal (None, 12, 12, 272)  1088        block6h_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6h_drop (FixedDropout)     (None, 12, 12, 272)  0           block6h_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_add (Add)               (None, 12, 12, 272)  0           block6h_drop[0][0]               \n",
      "                                                                 block6g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 12, 12, 1632) 443904      block6h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 12, 12, 1632) 6528        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 12, 12, 1632) 0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 12, 12, 1632) 14688       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 12, 12, 1632) 6528        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 12, 12, 1632) 0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 1632)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 1632)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 68)     111044      block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 1632)   112608      block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 12, 12, 1632) 0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 12, 12, 448)  731136      block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 12, 12, 448)  1792        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_conv (Conv2D)    (None, 12, 12, 2688) 1204224     block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_bn (BatchNormali (None, 12, 12, 2688) 10752       block7b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_activation (Acti (None, 12, 12, 2688) 0           block7b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_dwconv (DepthwiseConv2D (None, 12, 12, 2688) 24192       block7b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7b_bn (BatchNormalization) (None, 12, 12, 2688) 10752       block7b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7b_activation (Activation) (None, 12, 12, 2688) 0           block7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_squeeze (GlobalAvera (None, 2688)         0           block7b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reshape (Reshape)    (None, 1, 1, 2688)   0           block7b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reduce (Conv2D)      (None, 1, 1, 112)    301168      block7b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_expand (Conv2D)      (None, 1, 1, 2688)   303744      block7b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_excite (Multiply)    (None, 12, 12, 2688) 0           block7b_activation[0][0]         \n",
      "                                                                 block7b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_conv (Conv2D)   (None, 12, 12, 448)  1204224     block7b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_bn (BatchNormal (None, 12, 12, 448)  1792        block7b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_drop (FixedDropout)     (None, 12, 12, 448)  0           block7b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_add (Add)               (None, 12, 12, 448)  0           block7b_drop[0][0]               \n",
      "                                                                 block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 12, 12, 1792) 802816      block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 12, 12, 1792) 7168        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 12, 12, 1792) 0           top_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1792)         0           top_activation[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "top_dropout (Dropout)           (None, 1792)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 431)          772783      top_dropout[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 18,446,599\n",
      "Trainable params: 18,321,399\n",
      "Non-trainable params: 125,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      " 455277/1015646 [============>.................] - ETA: 71:37:08 - loss: 3.0277 - acc: 0.2973 - top_k_categorical_accuracy: 0.5881"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 466299/1015646 [============>.................] - ETA: 70:11:49 - loss: 3.0128 - acc: 0.2998 - top_k_categorical_accuracy: 0.5913"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 476850/1015646 [=============>................] - ETA: 68:50:13 - loss: 2.9992 - acc: 0.3020 - top_k_categorical_accuracy: 0.5942"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 487700/1015646 [=============>................] - ETA: 67:28:23 - loss: 2.9854 - acc: 0.3041 - top_k_categorical_accuracy: 0.5971"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 497976/1015646 [=============>................] - ETA: 66:08:55 - loss: 2.9729 - acc: 0.3061 - top_k_categorical_accuracy: 0.5998"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 508932/1015646 [==============>...............] - ETA: 64:44:15 - loss: 2.9598 - acc: 0.3083 - top_k_categorical_accuracy: 0.6026"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 519170/1015646 [==============>...............] - ETA: 63:25:08 - loss: 2.9478 - acc: 0.3103 - top_k_categorical_accuracy: 0.6051"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 529940/1015646 [==============>...............] - ETA: 62:01:59 - loss: 2.9357 - acc: 0.3123 - top_k_categorical_accuracy: 0.6077"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 879243/1015646 [========================>.....] - ETA: 17:23:04 - loss: 2.6559 - acc: 0.3599 - top_k_categorical_accuracy: 0.6662"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1015646/1015646 [==============================] - 466590s 459ms/step - loss: 2.5849 - acc: 0.3723 - top_k_categorical_accuracy: 0.6809 - val_loss: 2.9374 - val_acc: 0.4233 - val_top_k_categorical_accuracy: 0.7207\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.42331, saving model to enet4_augm_ft.h5\n",
      "Epoch 2/4\n",
      "1015646/1015646 [==============================] - 462000s 455ms/step - loss: 1.9903 - acc: 0.4806 - top_k_categorical_accuracy: 0.8008 - val_loss: 2.7198 - val_acc: 0.4606 - val_top_k_categorical_accuracy: 0.7557\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.42331 to 0.46062, saving model to enet4_augm_ft.h5\n",
      "Epoch 3/4\n",
      "   6226/1015646 [..............................] - ETA: 126:59:24 - loss: 1.8842 - acc: 0.5024 - top_k_categorical_accuracy: 0.8182"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1015646/1015646 [==============================] - 462793s 456ms/step - loss: 1.8619 - acc: 0.5075 - top_k_categorical_accuracy: 0.8239 - val_loss: 2.6357 - val_acc: 0.4761 - val_top_k_categorical_accuracy: 0.7682\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.46062 to 0.47614, saving model to enet4_augm_ft.h5\n",
      "Epoch 4/4\n",
      "1015646/1015646 [==============================] - 486071s 479ms/step - loss: 1.7925 - acc: 0.5224 - top_k_categorical_accuracy: 0.8360 - val_loss: 2.5585 - val_acc: 0.4875 - val_top_k_categorical_accuracy: 0.7768\n",
      "\n",
      "Epoch 00004: val_acc improved from 0.47614 to 0.48754, saving model to enet4_augm_ft.h5\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(lr=1e-4,decay=1e-6), loss='categorical_crossentropy', metrics=['accuracy',top_k_categorical_accuracy])\n",
    "model.summary()\n",
    "mc = ModelCheckpoint(net_description+'_augm_ft.h5', monitor='val_acc', verbose=1, save_best_only=True)\n",
    "es=EarlyStopping(monitor='val_acc',patience=2 )\n",
    "SECOND_EPOCHS=4\n",
    "\n",
    "hist2=model.fit_generator(train_generator, steps_per_epoch=nb_train_samples//BATCH_SIZE, epochs=SECOND_EPOCHS, verbose=1, \n",
    "                    initial_epoch=start_epoch, callbacks=[mc], validation_data=val_generator, validation_steps=nb_validation_samples // BATCH_SIZE,class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 380, 380, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "stem_conv (Conv2D)              (None, 190, 190, 48) 1296        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "stem_bn (BatchNormalization)    (None, 190, 190, 48) 192         stem_conv[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "stem_activation (Activation)    (None, 190, 190, 48) 0           stem_bn[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1a_dwconv (DepthwiseConv2D (None, 190, 190, 48) 432         stem_activation[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1a_bn (BatchNormalization) (None, 190, 190, 48) 192         block1a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1a_activation (Activation) (None, 190, 190, 48) 0           block1a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_squeeze (GlobalAvera (None, 48)           0           block1a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reshape (Reshape)    (None, 1, 1, 48)     0           block1a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_reduce (Conv2D)      (None, 1, 1, 12)     588         block1a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_expand (Conv2D)      (None, 1, 1, 48)     624         block1a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_se_excite (Multiply)    (None, 190, 190, 48) 0           block1a_activation[0][0]         \n",
      "                                                                 block1a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_conv (Conv2D)   (None, 190, 190, 24) 1152        block1a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1a_project_bn (BatchNormal (None, 190, 190, 24) 96          block1a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_dwconv (DepthwiseConv2D (None, 190, 190, 24) 216         block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_bn (BatchNormalization) (None, 190, 190, 24) 96          block1b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block1b_activation (Activation) (None, 190, 190, 24) 0           block1b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_squeeze (GlobalAvera (None, 24)           0           block1b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reshape (Reshape)    (None, 1, 1, 24)     0           block1b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_reduce (Conv2D)      (None, 1, 1, 6)      150         block1b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_expand (Conv2D)      (None, 1, 1, 24)     168         block1b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_se_excite (Multiply)    (None, 190, 190, 24) 0           block1b_activation[0][0]         \n",
      "                                                                 block1b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_conv (Conv2D)   (None, 190, 190, 24) 576         block1b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1b_project_bn (BatchNormal (None, 190, 190, 24) 96          block1b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1b_drop (FixedDropout)     (None, 190, 190, 24) 0           block1b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block1b_add (Add)               (None, 190, 190, 24) 0           block1b_drop[0][0]               \n",
      "                                                                 block1a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_conv (Conv2D)    (None, 190, 190, 144 3456        block1b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_bn (BatchNormali (None, 190, 190, 144 576         block2a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2a_expand_activation (Acti (None, 190, 190, 144 0           block2a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_dwconv (DepthwiseConv2D (None, 95, 95, 144)  1296        block2a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2a_bn (BatchNormalization) (None, 95, 95, 144)  576         block2a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2a_activation (Activation) (None, 95, 95, 144)  0           block2a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_squeeze (GlobalAvera (None, 144)          0           block2a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reshape (Reshape)    (None, 1, 1, 144)    0           block2a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_reduce (Conv2D)      (None, 1, 1, 6)      870         block2a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_expand (Conv2D)      (None, 1, 1, 144)    1008        block2a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_se_excite (Multiply)    (None, 95, 95, 144)  0           block2a_activation[0][0]         \n",
      "                                                                 block2a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_conv (Conv2D)   (None, 95, 95, 32)   4608        block2a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2a_project_bn (BatchNormal (None, 95, 95, 32)   128         block2a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_conv (Conv2D)    (None, 95, 95, 192)  6144        block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_bn (BatchNormali (None, 95, 95, 192)  768         block2b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2b_expand_activation (Acti (None, 95, 95, 192)  0           block2b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_dwconv (DepthwiseConv2D (None, 95, 95, 192)  1728        block2b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2b_bn (BatchNormalization) (None, 95, 95, 192)  768         block2b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2b_activation (Activation) (None, 95, 95, 192)  0           block2b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_squeeze (GlobalAvera (None, 192)          0           block2b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_se_excite (Multiply)    (None, 95, 95, 192)  0           block2b_activation[0][0]         \n",
      "                                                                 block2b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_conv (Conv2D)   (None, 95, 95, 32)   6144        block2b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2b_project_bn (BatchNormal (None, 95, 95, 32)   128         block2b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2b_drop (FixedDropout)     (None, 95, 95, 32)   0           block2b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2b_add (Add)               (None, 95, 95, 32)   0           block2b_drop[0][0]               \n",
      "                                                                 block2a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_conv (Conv2D)    (None, 95, 95, 192)  6144        block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_bn (BatchNormali (None, 95, 95, 192)  768         block2c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2c_expand_activation (Acti (None, 95, 95, 192)  0           block2c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_dwconv (DepthwiseConv2D (None, 95, 95, 192)  1728        block2c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2c_bn (BatchNormalization) (None, 95, 95, 192)  768         block2c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2c_activation (Activation) (None, 95, 95, 192)  0           block2c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_squeeze (GlobalAvera (None, 192)          0           block2c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_se_excite (Multiply)    (None, 95, 95, 192)  0           block2c_activation[0][0]         \n",
      "                                                                 block2c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_conv (Conv2D)   (None, 95, 95, 32)   6144        block2c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2c_project_bn (BatchNormal (None, 95, 95, 32)   128         block2c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2c_drop (FixedDropout)     (None, 95, 95, 32)   0           block2c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2c_add (Add)               (None, 95, 95, 32)   0           block2c_drop[0][0]               \n",
      "                                                                 block2b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_conv (Conv2D)    (None, 95, 95, 192)  6144        block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_bn (BatchNormali (None, 95, 95, 192)  768         block2d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2d_expand_activation (Acti (None, 95, 95, 192)  0           block2d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_dwconv (DepthwiseConv2D (None, 95, 95, 192)  1728        block2d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block2d_bn (BatchNormalization) (None, 95, 95, 192)  768         block2d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block2d_activation (Activation) (None, 95, 95, 192)  0           block2d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_squeeze (GlobalAvera (None, 192)          0           block2d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_reshape (Reshape)    (None, 1, 1, 192)    0           block2d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block2d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block2d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_se_excite (Multiply)    (None, 95, 95, 192)  0           block2d_activation[0][0]         \n",
      "                                                                 block2d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_project_conv (Conv2D)   (None, 95, 95, 32)   6144        block2d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block2d_project_bn (BatchNormal (None, 95, 95, 32)   128         block2d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block2d_drop (FixedDropout)     (None, 95, 95, 32)   0           block2d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2d_add (Add)               (None, 95, 95, 32)   0           block2d_drop[0][0]               \n",
      "                                                                 block2c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_conv (Conv2D)    (None, 95, 95, 192)  6144        block2d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_bn (BatchNormali (None, 95, 95, 192)  768         block3a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3a_expand_activation (Acti (None, 95, 95, 192)  0           block3a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_dwconv (DepthwiseConv2D (None, 48, 48, 192)  4800        block3a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3a_bn (BatchNormalization) (None, 48, 48, 192)  768         block3a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3a_activation (Activation) (None, 48, 48, 192)  0           block3a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_squeeze (GlobalAvera (None, 192)          0           block3a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reshape (Reshape)    (None, 1, 1, 192)    0           block3a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_reduce (Conv2D)      (None, 1, 1, 8)      1544        block3a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_expand (Conv2D)      (None, 1, 1, 192)    1728        block3a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_se_excite (Multiply)    (None, 48, 48, 192)  0           block3a_activation[0][0]         \n",
      "                                                                 block3a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_conv (Conv2D)   (None, 48, 48, 56)   10752       block3a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3a_project_bn (BatchNormal (None, 48, 48, 56)   224         block3a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_conv (Conv2D)    (None, 48, 48, 336)  18816       block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_bn (BatchNormali (None, 48, 48, 336)  1344        block3b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3b_expand_activation (Acti (None, 48, 48, 336)  0           block3b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_dwconv (DepthwiseConv2D (None, 48, 48, 336)  8400        block3b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3b_bn (BatchNormalization) (None, 48, 48, 336)  1344        block3b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3b_activation (Activation) (None, 48, 48, 336)  0           block3b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_squeeze (GlobalAvera (None, 336)          0           block3b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reshape (Reshape)    (None, 1, 1, 336)    0           block3b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_reduce (Conv2D)      (None, 1, 1, 14)     4718        block3b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_expand (Conv2D)      (None, 1, 1, 336)    5040        block3b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_se_excite (Multiply)    (None, 48, 48, 336)  0           block3b_activation[0][0]         \n",
      "                                                                 block3b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_conv (Conv2D)   (None, 48, 48, 56)   18816       block3b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3b_project_bn (BatchNormal (None, 48, 48, 56)   224         block3b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3b_drop (FixedDropout)     (None, 48, 48, 56)   0           block3b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3b_add (Add)               (None, 48, 48, 56)   0           block3b_drop[0][0]               \n",
      "                                                                 block3a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_conv (Conv2D)    (None, 48, 48, 336)  18816       block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_bn (BatchNormali (None, 48, 48, 336)  1344        block3c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3c_expand_activation (Acti (None, 48, 48, 336)  0           block3c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_dwconv (DepthwiseConv2D (None, 48, 48, 336)  8400        block3c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3c_bn (BatchNormalization) (None, 48, 48, 336)  1344        block3c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3c_activation (Activation) (None, 48, 48, 336)  0           block3c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_squeeze (GlobalAvera (None, 336)          0           block3c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reshape (Reshape)    (None, 1, 1, 336)    0           block3c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_reduce (Conv2D)      (None, 1, 1, 14)     4718        block3c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_expand (Conv2D)      (None, 1, 1, 336)    5040        block3c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_se_excite (Multiply)    (None, 48, 48, 336)  0           block3c_activation[0][0]         \n",
      "                                                                 block3c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_conv (Conv2D)   (None, 48, 48, 56)   18816       block3c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3c_project_bn (BatchNormal (None, 48, 48, 56)   224         block3c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3c_drop (FixedDropout)     (None, 48, 48, 56)   0           block3c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3c_add (Add)               (None, 48, 48, 56)   0           block3c_drop[0][0]               \n",
      "                                                                 block3b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_conv (Conv2D)    (None, 48, 48, 336)  18816       block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_bn (BatchNormali (None, 48, 48, 336)  1344        block3d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3d_expand_activation (Acti (None, 48, 48, 336)  0           block3d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_dwconv (DepthwiseConv2D (None, 48, 48, 336)  8400        block3d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block3d_bn (BatchNormalization) (None, 48, 48, 336)  1344        block3d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block3d_activation (Activation) (None, 48, 48, 336)  0           block3d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_squeeze (GlobalAvera (None, 336)          0           block3d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_reshape (Reshape)    (None, 1, 1, 336)    0           block3d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_reduce (Conv2D)      (None, 1, 1, 14)     4718        block3d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_expand (Conv2D)      (None, 1, 1, 336)    5040        block3d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_se_excite (Multiply)    (None, 48, 48, 336)  0           block3d_activation[0][0]         \n",
      "                                                                 block3d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_project_conv (Conv2D)   (None, 48, 48, 56)   18816       block3d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block3d_project_bn (BatchNormal (None, 48, 48, 56)   224         block3d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block3d_drop (FixedDropout)     (None, 48, 48, 56)   0           block3d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3d_add (Add)               (None, 48, 48, 56)   0           block3d_drop[0][0]               \n",
      "                                                                 block3c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_conv (Conv2D)    (None, 48, 48, 336)  18816       block3d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_bn (BatchNormali (None, 48, 48, 336)  1344        block4a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4a_expand_activation (Acti (None, 48, 48, 336)  0           block4a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_dwconv (DepthwiseConv2D (None, 24, 24, 336)  3024        block4a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4a_bn (BatchNormalization) (None, 24, 24, 336)  1344        block4a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4a_activation (Activation) (None, 24, 24, 336)  0           block4a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_squeeze (GlobalAvera (None, 336)          0           block4a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reshape (Reshape)    (None, 1, 1, 336)    0           block4a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_reduce (Conv2D)      (None, 1, 1, 14)     4718        block4a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_expand (Conv2D)      (None, 1, 1, 336)    5040        block4a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_se_excite (Multiply)    (None, 24, 24, 336)  0           block4a_activation[0][0]         \n",
      "                                                                 block4a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_conv (Conv2D)   (None, 24, 24, 112)  37632       block4a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4a_project_bn (BatchNormal (None, 24, 24, 112)  448         block4a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_conv (Conv2D)    (None, 24, 24, 672)  75264       block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_bn (BatchNormali (None, 24, 24, 672)  2688        block4b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4b_expand_activation (Acti (None, 24, 24, 672)  0           block4b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_dwconv (DepthwiseConv2D (None, 24, 24, 672)  6048        block4b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4b_bn (BatchNormalization) (None, 24, 24, 672)  2688        block4b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4b_activation (Activation) (None, 24, 24, 672)  0           block4b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_squeeze (GlobalAvera (None, 672)          0           block4b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reshape (Reshape)    (None, 1, 1, 672)    0           block4b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block4b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block4b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_se_excite (Multiply)    (None, 24, 24, 672)  0           block4b_activation[0][0]         \n",
      "                                                                 block4b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_conv (Conv2D)   (None, 24, 24, 112)  75264       block4b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4b_project_bn (BatchNormal (None, 24, 24, 112)  448         block4b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4b_drop (FixedDropout)     (None, 24, 24, 112)  0           block4b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4b_add (Add)               (None, 24, 24, 112)  0           block4b_drop[0][0]               \n",
      "                                                                 block4a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_conv (Conv2D)    (None, 24, 24, 672)  75264       block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_bn (BatchNormali (None, 24, 24, 672)  2688        block4c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4c_expand_activation (Acti (None, 24, 24, 672)  0           block4c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_dwconv (DepthwiseConv2D (None, 24, 24, 672)  6048        block4c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4c_bn (BatchNormalization) (None, 24, 24, 672)  2688        block4c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4c_activation (Activation) (None, 24, 24, 672)  0           block4c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_squeeze (GlobalAvera (None, 672)          0           block4c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reshape (Reshape)    (None, 1, 1, 672)    0           block4c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block4c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block4c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_se_excite (Multiply)    (None, 24, 24, 672)  0           block4c_activation[0][0]         \n",
      "                                                                 block4c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_conv (Conv2D)   (None, 24, 24, 112)  75264       block4c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4c_project_bn (BatchNormal (None, 24, 24, 112)  448         block4c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4c_drop (FixedDropout)     (None, 24, 24, 112)  0           block4c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4c_add (Add)               (None, 24, 24, 112)  0           block4c_drop[0][0]               \n",
      "                                                                 block4b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_conv (Conv2D)    (None, 24, 24, 672)  75264       block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_bn (BatchNormali (None, 24, 24, 672)  2688        block4d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4d_expand_activation (Acti (None, 24, 24, 672)  0           block4d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_dwconv (DepthwiseConv2D (None, 24, 24, 672)  6048        block4d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4d_bn (BatchNormalization) (None, 24, 24, 672)  2688        block4d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4d_activation (Activation) (None, 24, 24, 672)  0           block4d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_squeeze (GlobalAvera (None, 672)          0           block4d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reshape (Reshape)    (None, 1, 1, 672)    0           block4d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block4d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block4d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_se_excite (Multiply)    (None, 24, 24, 672)  0           block4d_activation[0][0]         \n",
      "                                                                 block4d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_conv (Conv2D)   (None, 24, 24, 112)  75264       block4d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4d_project_bn (BatchNormal (None, 24, 24, 112)  448         block4d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4d_drop (FixedDropout)     (None, 24, 24, 112)  0           block4d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4d_add (Add)               (None, 24, 24, 112)  0           block4d_drop[0][0]               \n",
      "                                                                 block4c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_conv (Conv2D)    (None, 24, 24, 672)  75264       block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_bn (BatchNormali (None, 24, 24, 672)  2688        block4e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4e_expand_activation (Acti (None, 24, 24, 672)  0           block4e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_dwconv (DepthwiseConv2D (None, 24, 24, 672)  6048        block4e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4e_bn (BatchNormalization) (None, 24, 24, 672)  2688        block4e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4e_activation (Activation) (None, 24, 24, 672)  0           block4e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_squeeze (GlobalAvera (None, 672)          0           block4e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reshape (Reshape)    (None, 1, 1, 672)    0           block4e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block4e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block4e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_se_excite (Multiply)    (None, 24, 24, 672)  0           block4e_activation[0][0]         \n",
      "                                                                 block4e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_conv (Conv2D)   (None, 24, 24, 112)  75264       block4e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4e_project_bn (BatchNormal (None, 24, 24, 112)  448         block4e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4e_drop (FixedDropout)     (None, 24, 24, 112)  0           block4e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4e_add (Add)               (None, 24, 24, 112)  0           block4e_drop[0][0]               \n",
      "                                                                 block4d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_conv (Conv2D)    (None, 24, 24, 672)  75264       block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_bn (BatchNormali (None, 24, 24, 672)  2688        block4f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4f_expand_activation (Acti (None, 24, 24, 672)  0           block4f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_dwconv (DepthwiseConv2D (None, 24, 24, 672)  6048        block4f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block4f_bn (BatchNormalization) (None, 24, 24, 672)  2688        block4f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block4f_activation (Activation) (None, 24, 24, 672)  0           block4f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_squeeze (GlobalAvera (None, 672)          0           block4f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_reshape (Reshape)    (None, 1, 1, 672)    0           block4f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block4f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block4f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_se_excite (Multiply)    (None, 24, 24, 672)  0           block4f_activation[0][0]         \n",
      "                                                                 block4f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_project_conv (Conv2D)   (None, 24, 24, 112)  75264       block4f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block4f_project_bn (BatchNormal (None, 24, 24, 112)  448         block4f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block4f_drop (FixedDropout)     (None, 24, 24, 112)  0           block4f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4f_add (Add)               (None, 24, 24, 112)  0           block4f_drop[0][0]               \n",
      "                                                                 block4e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_conv (Conv2D)    (None, 24, 24, 672)  75264       block4f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_bn (BatchNormali (None, 24, 24, 672)  2688        block5a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5a_expand_activation (Acti (None, 24, 24, 672)  0           block5a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_dwconv (DepthwiseConv2D (None, 24, 24, 672)  16800       block5a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5a_bn (BatchNormalization) (None, 24, 24, 672)  2688        block5a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5a_activation (Activation) (None, 24, 24, 672)  0           block5a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_squeeze (GlobalAvera (None, 672)          0           block5a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reshape (Reshape)    (None, 1, 1, 672)    0           block5a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_reduce (Conv2D)      (None, 1, 1, 28)     18844       block5a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_expand (Conv2D)      (None, 1, 1, 672)    19488       block5a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_se_excite (Multiply)    (None, 24, 24, 672)  0           block5a_activation[0][0]         \n",
      "                                                                 block5a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_conv (Conv2D)   (None, 24, 24, 160)  107520      block5a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5a_project_bn (BatchNormal (None, 24, 24, 160)  640         block5a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_conv (Conv2D)    (None, 24, 24, 960)  153600      block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_bn (BatchNormali (None, 24, 24, 960)  3840        block5b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5b_expand_activation (Acti (None, 24, 24, 960)  0           block5b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_dwconv (DepthwiseConv2D (None, 24, 24, 960)  24000       block5b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5b_bn (BatchNormalization) (None, 24, 24, 960)  3840        block5b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5b_activation (Activation) (None, 24, 24, 960)  0           block5b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_squeeze (GlobalAvera (None, 960)          0           block5b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reshape (Reshape)    (None, 1, 1, 960)    0           block5b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block5b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block5b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_se_excite (Multiply)    (None, 24, 24, 960)  0           block5b_activation[0][0]         \n",
      "                                                                 block5b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_conv (Conv2D)   (None, 24, 24, 160)  153600      block5b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5b_project_bn (BatchNormal (None, 24, 24, 160)  640         block5b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5b_drop (FixedDropout)     (None, 24, 24, 160)  0           block5b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5b_add (Add)               (None, 24, 24, 160)  0           block5b_drop[0][0]               \n",
      "                                                                 block5a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_conv (Conv2D)    (None, 24, 24, 960)  153600      block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_bn (BatchNormali (None, 24, 24, 960)  3840        block5c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5c_expand_activation (Acti (None, 24, 24, 960)  0           block5c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_dwconv (DepthwiseConv2D (None, 24, 24, 960)  24000       block5c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5c_bn (BatchNormalization) (None, 24, 24, 960)  3840        block5c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5c_activation (Activation) (None, 24, 24, 960)  0           block5c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_squeeze (GlobalAvera (None, 960)          0           block5c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reshape (Reshape)    (None, 1, 1, 960)    0           block5c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block5c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block5c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_se_excite (Multiply)    (None, 24, 24, 960)  0           block5c_activation[0][0]         \n",
      "                                                                 block5c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_conv (Conv2D)   (None, 24, 24, 160)  153600      block5c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5c_project_bn (BatchNormal (None, 24, 24, 160)  640         block5c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5c_drop (FixedDropout)     (None, 24, 24, 160)  0           block5c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5c_add (Add)               (None, 24, 24, 160)  0           block5c_drop[0][0]               \n",
      "                                                                 block5b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_conv (Conv2D)    (None, 24, 24, 960)  153600      block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_bn (BatchNormali (None, 24, 24, 960)  3840        block5d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5d_expand_activation (Acti (None, 24, 24, 960)  0           block5d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_dwconv (DepthwiseConv2D (None, 24, 24, 960)  24000       block5d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5d_bn (BatchNormalization) (None, 24, 24, 960)  3840        block5d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5d_activation (Activation) (None, 24, 24, 960)  0           block5d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_squeeze (GlobalAvera (None, 960)          0           block5d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reshape (Reshape)    (None, 1, 1, 960)    0           block5d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block5d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block5d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_se_excite (Multiply)    (None, 24, 24, 960)  0           block5d_activation[0][0]         \n",
      "                                                                 block5d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_conv (Conv2D)   (None, 24, 24, 160)  153600      block5d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5d_project_bn (BatchNormal (None, 24, 24, 160)  640         block5d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5d_drop (FixedDropout)     (None, 24, 24, 160)  0           block5d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5d_add (Add)               (None, 24, 24, 160)  0           block5d_drop[0][0]               \n",
      "                                                                 block5c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_conv (Conv2D)    (None, 24, 24, 960)  153600      block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_bn (BatchNormali (None, 24, 24, 960)  3840        block5e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5e_expand_activation (Acti (None, 24, 24, 960)  0           block5e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_dwconv (DepthwiseConv2D (None, 24, 24, 960)  24000       block5e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5e_bn (BatchNormalization) (None, 24, 24, 960)  3840        block5e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5e_activation (Activation) (None, 24, 24, 960)  0           block5e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_squeeze (GlobalAvera (None, 960)          0           block5e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reshape (Reshape)    (None, 1, 1, 960)    0           block5e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block5e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block5e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_se_excite (Multiply)    (None, 24, 24, 960)  0           block5e_activation[0][0]         \n",
      "                                                                 block5e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_conv (Conv2D)   (None, 24, 24, 160)  153600      block5e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5e_project_bn (BatchNormal (None, 24, 24, 160)  640         block5e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5e_drop (FixedDropout)     (None, 24, 24, 160)  0           block5e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5e_add (Add)               (None, 24, 24, 160)  0           block5e_drop[0][0]               \n",
      "                                                                 block5d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_conv (Conv2D)    (None, 24, 24, 960)  153600      block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_bn (BatchNormali (None, 24, 24, 960)  3840        block5f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5f_expand_activation (Acti (None, 24, 24, 960)  0           block5f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_dwconv (DepthwiseConv2D (None, 24, 24, 960)  24000       block5f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block5f_bn (BatchNormalization) (None, 24, 24, 960)  3840        block5f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block5f_activation (Activation) (None, 24, 24, 960)  0           block5f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_squeeze (GlobalAvera (None, 960)          0           block5f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_reshape (Reshape)    (None, 1, 1, 960)    0           block5f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block5f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block5f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_se_excite (Multiply)    (None, 24, 24, 960)  0           block5f_activation[0][0]         \n",
      "                                                                 block5f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_project_conv (Conv2D)   (None, 24, 24, 160)  153600      block5f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block5f_project_bn (BatchNormal (None, 24, 24, 160)  640         block5f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block5f_drop (FixedDropout)     (None, 24, 24, 160)  0           block5f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5f_add (Add)               (None, 24, 24, 160)  0           block5f_drop[0][0]               \n",
      "                                                                 block5e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_conv (Conv2D)    (None, 24, 24, 960)  153600      block5f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_bn (BatchNormali (None, 24, 24, 960)  3840        block6a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6a_expand_activation (Acti (None, 24, 24, 960)  0           block6a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_dwconv (DepthwiseConv2D (None, 12, 12, 960)  24000       block6a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6a_bn (BatchNormalization) (None, 12, 12, 960)  3840        block6a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6a_activation (Activation) (None, 12, 12, 960)  0           block6a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_squeeze (GlobalAvera (None, 960)          0           block6a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reshape (Reshape)    (None, 1, 1, 960)    0           block6a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_reduce (Conv2D)      (None, 1, 1, 40)     38440       block6a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_expand (Conv2D)      (None, 1, 1, 960)    39360       block6a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_se_excite (Multiply)    (None, 12, 12, 960)  0           block6a_activation[0][0]         \n",
      "                                                                 block6a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_conv (Conv2D)   (None, 12, 12, 272)  261120      block6a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6a_project_bn (BatchNormal (None, 12, 12, 272)  1088        block6a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_conv (Conv2D)    (None, 12, 12, 1632) 443904      block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_bn (BatchNormali (None, 12, 12, 1632) 6528        block6b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6b_expand_activation (Acti (None, 12, 12, 1632) 0           block6b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_dwconv (DepthwiseConv2D (None, 12, 12, 1632) 40800       block6b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6b_bn (BatchNormalization) (None, 12, 12, 1632) 6528        block6b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6b_activation (Activation) (None, 12, 12, 1632) 0           block6b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_squeeze (GlobalAvera (None, 1632)         0           block6b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reshape (Reshape)    (None, 1, 1, 1632)   0           block6b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_reduce (Conv2D)      (None, 1, 1, 68)     111044      block6b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_expand (Conv2D)      (None, 1, 1, 1632)   112608      block6b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_se_excite (Multiply)    (None, 12, 12, 1632) 0           block6b_activation[0][0]         \n",
      "                                                                 block6b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_conv (Conv2D)   (None, 12, 12, 272)  443904      block6b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6b_project_bn (BatchNormal (None, 12, 12, 272)  1088        block6b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6b_drop (FixedDropout)     (None, 12, 12, 272)  0           block6b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6b_add (Add)               (None, 12, 12, 272)  0           block6b_drop[0][0]               \n",
      "                                                                 block6a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_conv (Conv2D)    (None, 12, 12, 1632) 443904      block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_bn (BatchNormali (None, 12, 12, 1632) 6528        block6c_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6c_expand_activation (Acti (None, 12, 12, 1632) 0           block6c_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_dwconv (DepthwiseConv2D (None, 12, 12, 1632) 40800       block6c_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6c_bn (BatchNormalization) (None, 12, 12, 1632) 6528        block6c_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6c_activation (Activation) (None, 12, 12, 1632) 0           block6c_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_squeeze (GlobalAvera (None, 1632)         0           block6c_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reshape (Reshape)    (None, 1, 1, 1632)   0           block6c_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_reduce (Conv2D)      (None, 1, 1, 68)     111044      block6c_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_expand (Conv2D)      (None, 1, 1, 1632)   112608      block6c_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_se_excite (Multiply)    (None, 12, 12, 1632) 0           block6c_activation[0][0]         \n",
      "                                                                 block6c_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_conv (Conv2D)   (None, 12, 12, 272)  443904      block6c_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6c_project_bn (BatchNormal (None, 12, 12, 272)  1088        block6c_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6c_drop (FixedDropout)     (None, 12, 12, 272)  0           block6c_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6c_add (Add)               (None, 12, 12, 272)  0           block6c_drop[0][0]               \n",
      "                                                                 block6b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_conv (Conv2D)    (None, 12, 12, 1632) 443904      block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_bn (BatchNormali (None, 12, 12, 1632) 6528        block6d_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6d_expand_activation (Acti (None, 12, 12, 1632) 0           block6d_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_dwconv (DepthwiseConv2D (None, 12, 12, 1632) 40800       block6d_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6d_bn (BatchNormalization) (None, 12, 12, 1632) 6528        block6d_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6d_activation (Activation) (None, 12, 12, 1632) 0           block6d_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_squeeze (GlobalAvera (None, 1632)         0           block6d_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reshape (Reshape)    (None, 1, 1, 1632)   0           block6d_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_reduce (Conv2D)      (None, 1, 1, 68)     111044      block6d_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_expand (Conv2D)      (None, 1, 1, 1632)   112608      block6d_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_se_excite (Multiply)    (None, 12, 12, 1632) 0           block6d_activation[0][0]         \n",
      "                                                                 block6d_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_conv (Conv2D)   (None, 12, 12, 272)  443904      block6d_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6d_project_bn (BatchNormal (None, 12, 12, 272)  1088        block6d_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6d_drop (FixedDropout)     (None, 12, 12, 272)  0           block6d_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6d_add (Add)               (None, 12, 12, 272)  0           block6d_drop[0][0]               \n",
      "                                                                 block6c_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_conv (Conv2D)    (None, 12, 12, 1632) 443904      block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_bn (BatchNormali (None, 12, 12, 1632) 6528        block6e_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6e_expand_activation (Acti (None, 12, 12, 1632) 0           block6e_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_dwconv (DepthwiseConv2D (None, 12, 12, 1632) 40800       block6e_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6e_bn (BatchNormalization) (None, 12, 12, 1632) 6528        block6e_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6e_activation (Activation) (None, 12, 12, 1632) 0           block6e_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_squeeze (GlobalAvera (None, 1632)         0           block6e_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reshape (Reshape)    (None, 1, 1, 1632)   0           block6e_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_reduce (Conv2D)      (None, 1, 1, 68)     111044      block6e_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_expand (Conv2D)      (None, 1, 1, 1632)   112608      block6e_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_se_excite (Multiply)    (None, 12, 12, 1632) 0           block6e_activation[0][0]         \n",
      "                                                                 block6e_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_conv (Conv2D)   (None, 12, 12, 272)  443904      block6e_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6e_project_bn (BatchNormal (None, 12, 12, 272)  1088        block6e_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6e_drop (FixedDropout)     (None, 12, 12, 272)  0           block6e_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6e_add (Add)               (None, 12, 12, 272)  0           block6e_drop[0][0]               \n",
      "                                                                 block6d_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_conv (Conv2D)    (None, 12, 12, 1632) 443904      block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_bn (BatchNormali (None, 12, 12, 1632) 6528        block6f_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6f_expand_activation (Acti (None, 12, 12, 1632) 0           block6f_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_dwconv (DepthwiseConv2D (None, 12, 12, 1632) 40800       block6f_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6f_bn (BatchNormalization) (None, 12, 12, 1632) 6528        block6f_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6f_activation (Activation) (None, 12, 12, 1632) 0           block6f_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_squeeze (GlobalAvera (None, 1632)         0           block6f_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reshape (Reshape)    (None, 1, 1, 1632)   0           block6f_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_reduce (Conv2D)      (None, 1, 1, 68)     111044      block6f_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_expand (Conv2D)      (None, 1, 1, 1632)   112608      block6f_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_se_excite (Multiply)    (None, 12, 12, 1632) 0           block6f_activation[0][0]         \n",
      "                                                                 block6f_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_conv (Conv2D)   (None, 12, 12, 272)  443904      block6f_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6f_project_bn (BatchNormal (None, 12, 12, 272)  1088        block6f_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6f_drop (FixedDropout)     (None, 12, 12, 272)  0           block6f_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6f_add (Add)               (None, 12, 12, 272)  0           block6f_drop[0][0]               \n",
      "                                                                 block6e_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_conv (Conv2D)    (None, 12, 12, 1632) 443904      block6f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_bn (BatchNormali (None, 12, 12, 1632) 6528        block6g_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6g_expand_activation (Acti (None, 12, 12, 1632) 0           block6g_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_dwconv (DepthwiseConv2D (None, 12, 12, 1632) 40800       block6g_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6g_bn (BatchNormalization) (None, 12, 12, 1632) 6528        block6g_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6g_activation (Activation) (None, 12, 12, 1632) 0           block6g_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_squeeze (GlobalAvera (None, 1632)         0           block6g_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_reshape (Reshape)    (None, 1, 1, 1632)   0           block6g_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_reduce (Conv2D)      (None, 1, 1, 68)     111044      block6g_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_expand (Conv2D)      (None, 1, 1, 1632)   112608      block6g_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_se_excite (Multiply)    (None, 12, 12, 1632) 0           block6g_activation[0][0]         \n",
      "                                                                 block6g_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_project_conv (Conv2D)   (None, 12, 12, 272)  443904      block6g_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6g_project_bn (BatchNormal (None, 12, 12, 272)  1088        block6g_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6g_drop (FixedDropout)     (None, 12, 12, 272)  0           block6g_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6g_add (Add)               (None, 12, 12, 272)  0           block6g_drop[0][0]               \n",
      "                                                                 block6f_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_conv (Conv2D)    (None, 12, 12, 1632) 443904      block6g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_bn (BatchNormali (None, 12, 12, 1632) 6528        block6h_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6h_expand_activation (Acti (None, 12, 12, 1632) 0           block6h_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_dwconv (DepthwiseConv2D (None, 12, 12, 1632) 40800       block6h_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block6h_bn (BatchNormalization) (None, 12, 12, 1632) 6528        block6h_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block6h_activation (Activation) (None, 12, 12, 1632) 0           block6h_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_squeeze (GlobalAvera (None, 1632)         0           block6h_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_reshape (Reshape)    (None, 1, 1, 1632)   0           block6h_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_reduce (Conv2D)      (None, 1, 1, 68)     111044      block6h_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_expand (Conv2D)      (None, 1, 1, 1632)   112608      block6h_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_se_excite (Multiply)    (None, 12, 12, 1632) 0           block6h_activation[0][0]         \n",
      "                                                                 block6h_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_project_conv (Conv2D)   (None, 12, 12, 272)  443904      block6h_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block6h_project_bn (BatchNormal (None, 12, 12, 272)  1088        block6h_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block6h_drop (FixedDropout)     (None, 12, 12, 272)  0           block6h_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6h_add (Add)               (None, 12, 12, 272)  0           block6h_drop[0][0]               \n",
      "                                                                 block6g_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_conv (Conv2D)    (None, 12, 12, 1632) 443904      block6h_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_bn (BatchNormali (None, 12, 12, 1632) 6528        block7a_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7a_expand_activation (Acti (None, 12, 12, 1632) 0           block7a_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_dwconv (DepthwiseConv2D (None, 12, 12, 1632) 14688       block7a_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7a_bn (BatchNormalization) (None, 12, 12, 1632) 6528        block7a_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7a_activation (Activation) (None, 12, 12, 1632) 0           block7a_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_squeeze (GlobalAvera (None, 1632)         0           block7a_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reshape (Reshape)    (None, 1, 1, 1632)   0           block7a_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_reduce (Conv2D)      (None, 1, 1, 68)     111044      block7a_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_expand (Conv2D)      (None, 1, 1, 1632)   112608      block7a_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_se_excite (Multiply)    (None, 12, 12, 1632) 0           block7a_activation[0][0]         \n",
      "                                                                 block7a_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_conv (Conv2D)   (None, 12, 12, 448)  731136      block7a_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7a_project_bn (BatchNormal (None, 12, 12, 448)  1792        block7a_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_conv (Conv2D)    (None, 12, 12, 2688) 1204224     block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_bn (BatchNormali (None, 12, 12, 2688) 10752       block7b_expand_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7b_expand_activation (Acti (None, 12, 12, 2688) 0           block7b_expand_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_dwconv (DepthwiseConv2D (None, 12, 12, 2688) 24192       block7b_expand_activation[0][0]  \n",
      "__________________________________________________________________________________________________\n",
      "block7b_bn (BatchNormalization) (None, 12, 12, 2688) 10752       block7b_dwconv[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block7b_activation (Activation) (None, 12, 12, 2688) 0           block7b_bn[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_squeeze (GlobalAvera (None, 2688)         0           block7b_activation[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reshape (Reshape)    (None, 1, 1, 2688)   0           block7b_se_squeeze[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_reduce (Conv2D)      (None, 1, 1, 112)    301168      block7b_se_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_expand (Conv2D)      (None, 1, 1, 2688)   303744      block7b_se_reduce[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_se_excite (Multiply)    (None, 12, 12, 2688) 0           block7b_activation[0][0]         \n",
      "                                                                 block7b_se_expand[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_conv (Conv2D)   (None, 12, 12, 448)  1204224     block7b_se_excite[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block7b_project_bn (BatchNormal (None, 12, 12, 448)  1792        block7b_project_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block7b_drop (FixedDropout)     (None, 12, 12, 448)  0           block7b_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7b_add (Add)               (None, 12, 12, 448)  0           block7b_drop[0][0]               \n",
      "                                                                 block7a_project_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "top_conv (Conv2D)               (None, 12, 12, 1792) 802816      block7b_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "top_bn (BatchNormalization)     (None, 12, 12, 1792) 7168        top_conv[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "top_activation (Activation)     (None, 12, 12, 1792) 0           top_bn[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 1792)         0           top_activation[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "top_dropout (Dropout)           (None, 1792)         0           avg_pool[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 431)          772783      top_dropout[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 18,446,599\n",
      "Trainable params: 18,321,399\n",
      "Non-trainable params: 125,200\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5\n",
      "  53769/1015646 [>.............................] - ETA: 122:17:20 - loss: 1.7214 - acc: 0.5389 - top_k_categorical_accuracy: 0.8471"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-dc55b83446fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#gc.collect()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m hist3=model.fit_generator(train_generator, steps_per_epoch=nb_train_samples//BATCH_SIZE, epochs=THIRD_EPOCHS, verbose=1, \n\u001b[0;32m---> 13\u001b[0;31m                     initial_epoch=second_epoch, callbacks=[mc], validation_data=val_generator, validation_steps=nb_validation_samples // BATCH_SIZE,class_weight=class_weights)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    214\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1447\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1448\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1449\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1450\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.load_weights(net_description+'_augm_ft.h5')\n",
    "model.compile(optimizer=SGD(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy',top_k_categorical_accuracy])\n",
    "model.summary()\n",
    "mc = ModelCheckpoint(net_description+'_augm_ft_sgd.h5', monitor='val_acc', verbose=1, save_best_only=True)\n",
    "es=EarlyStopping(monitor='val_acc',patience=2)\n",
    "second_epoch=start_epoch+len(hist2.history['loss'])\n",
    "THIRD_EPOCHS=second_epoch+1 #2 #3\n",
    "\n",
    "#import gc\n",
    "#gc.collect()\n",
    "hist3=model.fit_generator(train_generator, steps_per_epoch=nb_train_samples//BATCH_SIZE, epochs=THIRD_EPOCHS, verbose=1, \n",
    "                    initial_epoch=second_epoch, callbacks=[mc], validation_data=val_generator, validation_steps=nb_validation_samples // BATCH_SIZE,class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.0810632379445453, 0.531934645376903, 0.8260536576308949]\n"
     ]
    }
   ],
   "source": [
    "#model.load_weights(net_description+'_augm_ft_sgd.h5')\n",
    "print(model.evaluate_generator(val_generator, nb_validation_samples // BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc1 = hist1.history['acc']\n",
    "val_acc1 = hist1.history['val_acc']\n",
    "\n",
    "acc2 = hist2.history['acc']\n",
    "val_acc2 = hist2.history['val_acc']\n",
    "\n",
    "acc3 = hist3.history['acc']\n",
    "val_acc3 = hist3.history['val_acc']\n",
    "\n",
    "acc=np.concatenate((acc1,acc2,acc3),axis=0)\n",
    "val_acc=np.concatenate((val_acc1,val_acc2,val_acc3),axis=0)\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss1 = hist1.history['loss']\n",
    "val_loss1 = hist1.history['val_loss']\n",
    "\n",
    "loss2 = hist2.history['loss']\n",
    "val_loss2 = hist2.history['val_loss']\n",
    "\n",
    "loss3 = hist3.history['loss']\n",
    "val_loss3 = hist3.history['val_loss']\n",
    "\n",
    "loss=np.concatenate((loss1,loss2,loss3),axis=0)\n",
    "val_loss=np.concatenate((val_loss1,val_loss2,val_loss3),axis=0)\n",
    "epochs = range(1, len(loss) + 1)\n",
    "\n",
    "plt.clf()\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_dirs = sorted(os.listdir(VAL_DATA_DIR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "enet3_augm_ft_sgd.h5\n"
     ]
    }
   ],
   "source": [
    "net_file=net_description+'_augm_ft_sgd.h5'\n",
    "if False:\n",
    "    new_model=model\n",
    "    new_model.load_weights(net_file)\n",
    "else:\n",
    "    new_model = load_model(net_file)\n",
    "print(net_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py:310: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "save_model(model,net_description + '_model_augm_ft_sgd.h5')\n",
    "new_model = load_model(net_description + '_model_augm_ft_sgd.h5')\n",
    "new_model.compile(optimizer=SGD(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy',top_k_categorical_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airfield 100 0.97\n",
      "airplane_cabin 100 0.96\n",
      "airport_terminal 100 0.91\n",
      "alcove 100 0.86\n",
      "alley 100 0.94\n",
      "amphitheater 100 0.84\n",
      "amusement_arcade 100 0.88\n",
      "amusement_park 100 0.89\n",
      "anechoic_chamber 100 0.87\n",
      "apartment_building_outdoor 100 0.77\n",
      "aquarium 100 0.94\n",
      "aqueduct 100 0.84\n",
      "arcade 100 0.9\n",
      "arch 100 0.87\n",
      "archaelogical_excavation 100 0.96\n",
      "archive 100 0.78\n",
      "arena_hockey 100 0.98\n",
      "arena_performance 100 0.94\n",
      "arena_rodeo 100 0.99\n",
      "army_base 100 0.95\n",
      "art_gallery 100 0.9\n",
      "art_school 100 0.86\n",
      "art_studio 100 0.81\n",
      "artists_loft 100 0.79\n",
      "assembly_line 100 0.63\n",
      "athletic_field_indoor 100 0.6\n",
      "athletic_field_outdoor 100 0.96\n",
      "atrium_public 100 0.91\n",
      "attic 100 0.96\n",
      "auditorium 100 0.92\n",
      "auto_factory 100 0.87\n",
      "auto_showroom 100 0.97\n",
      "badlands 100 0.81\n",
      "badminton_court_indoor 100 0.89\n",
      "baggage_claim 100 0.92\n",
      "bakery_shop 100 0.86\n",
      "balcony_exterior 100 0.78\n",
      "balcony_interior 100 0.88\n",
      "ball_pit 100 0.96\n",
      "ballroom 100 0.89\n",
      "bamboo_forest 100 0.99\n",
      "bank_vault 100 0.74\n",
      "banquet_hall 100 0.95\n",
      "bar 100 0.77\n",
      "barn 100 0.87\n",
      "barndoor 100 0.9\n",
      "baseball_field 100 0.99\n",
      "basement 100 0.85\n",
      "basketball_court_indoor 100 0.98\n",
      "basketball_court_outdoor 100 0.8\n",
      "bathroom 100 0.99\n",
      "batters_box 100 0.91\n",
      "bazaar_indoor 100 0.68\n",
      "bazaar_outdoor 100 0.89\n",
      "beach 100 0.91\n",
      "beach_house 100 0.86\n",
      "beauty_salon 100 0.79\n",
      "bedchamber 100 0.84\n",
      "bedroom 100 0.97\n",
      "beer_garden 100 0.87\n",
      "beer_hall 100 0.92\n",
      "berth 100 0.86\n",
      "biology_laboratory 100 0.76\n",
      "boardwalk 100 0.82\n",
      "boat_deck 100 0.9\n",
      "boathouse 100 0.85\n",
      "bookstore 100 0.9\n",
      "booth_indoor 100 0.92\n",
      "botanical_garden 100 0.79\n",
      "bow_window_indoor 100 0.91\n",
      "bow_window_outdoor 100 0.14\n",
      "bowling_alley 100 0.96\n",
      "boxing_ring 100 0.99\n",
      "brewery_indoor 100 0.0\n",
      "bridge 100 0.84\n",
      "building_facade 100 0.52\n",
      "bullring 100 0.9\n",
      "burial_chamber 100 0.93\n",
      "bus_interior 100 0.99\n",
      "bus_station_indoor 100 0.91\n",
      "butchers_shop 100 0.78\n",
      "butte 100 0.78\n",
      "cabin_outdoor 100 0.93\n",
      "cafeteria 100 0.36\n",
      "campsite 100 0.96\n",
      "campus 100 0.69\n",
      "canal_natural 100 0.91\n",
      "canal_urban 100 0.86\n",
      "candy_store 100 0.76\n",
      "canyon 100 0.88\n",
      "car_interior 100 0.98\n",
      "carrousel 100 0.93\n",
      "casino_indoor 100 0.74\n",
      "castle 100 0.9\n",
      "catacomb 100 0.96\n",
      "cemetery 100 0.96\n",
      "chalet 100 0.8\n",
      "cheese_factory 100 0.72\n",
      "chemistry_lab 100 0.75\n",
      "chicken_coop_outdoor 100 0.58\n",
      "childs_room 100 0.96\n",
      "church_indoor 100 0.94\n",
      "church_outdoor 100 0.82\n",
      "classroom 100 0.91\n",
      "clean_room 100 0.74\n",
      "cliff 100 0.74\n",
      "closet 100 0.95\n",
      "clothing_store 100 0.89\n",
      "coast 100 0.84\n",
      "cockpit 100 1.0\n",
      "coffee_shop 100 0.76\n",
      "computer_room 100 0.83\n",
      "conference_center 100 0.94\n",
      "conference_room 100 0.9\n",
      "construction_site 100 0.83\n",
      "corn_field 100 0.94\n",
      "corral 100 0.96\n",
      "corridor 100 0.97\n",
      "cottage 100 0.77\n",
      "courthouse 100 0.83\n",
      "courtroom 100 0.81\n",
      "courtyard 100 0.76\n",
      "covered_bridge_exterior 100 0.67\n",
      "creek 100 0.92\n",
      "crevasse 100 0.85\n",
      "crosswalk 100 0.9\n",
      "cybercafe 100 0.46\n",
      "dam 100 0.88\n",
      "delicatessen 100 0.77\n",
      "dentists_office 100 0.86\n",
      "department_store 100 0.84\n",
      "desert_road 100 0.94\n",
      "desert_sand 100 0.91\n",
      "desert_vegetation 100 0.98\n",
      "diner_outdoor 100 0.83\n",
      "dinette_vehicle 100 0.55\n",
      "dining_car 100 0.77\n",
      "dining_hall 100 0.84\n",
      "dining_room 100 0.9\n",
      "discotheque 100 0.96\n",
      "doorway_outdoor 100 0.87\n",
      "dorm_room 100 0.89\n",
      "downtown 100 0.89\n",
      "dressing_room 100 0.77\n",
      "driveway 100 0.88\n",
      "driving_range_outdoor 100 0.0\n",
      "drugstore 100 0.73\n",
      "editing_room 100 0.64\n",
      "electrical_substation 100 0.9\n",
      "elevator_door 100 0.78\n",
      "elevator_interior 100 0.89\n",
      "elevator_lobby 100 0.8\n",
      "elevator_shaft 100 0.83\n",
      "embassy 100 0.85\n",
      "engine_room 100 0.93\n",
      "entrance_hall 100 0.9\n",
      "escalator_indoor 100 0.92\n",
      "excavation 100 0.94\n",
      "fabric_store 100 0.82\n",
      "factory_indoor 100 0.12\n",
      "farm 100 0.82\n",
      "fastfood_restaurant 100 0.82\n",
      "field_cultivated 100 0.82\n",
      "field_road 100 0.89\n",
      "field_wild 100 0.82\n",
      "fire_escape 100 0.93\n",
      "fire_station 100 0.85\n",
      "firing_range_indoor 100 0.64\n",
      "fishpond 100 0.86\n",
      "fitting_room_interior 100 0.0\n",
      "flea_market_indoor 100 0.75\n",
      "florist_shop_indoor 100 0.96\n",
      "florist_shop_outdoor 100 0.62\n",
      "food_court 100 0.74\n",
      "football_field 100 0.98\n",
      "forest_broadleaf 100 0.82\n",
      "forest_needleleaf 100 0.0\n",
      "forest_path 100 0.91\n",
      "forest_road 100 0.93\n",
      "formal_garden 100 0.77\n",
      "fountain 100 0.95\n",
      "funeral_home 100 0.22\n",
      "galley 100 0.85\n",
      "garage_indoor 100 0.82\n",
      "garage_outdoor 100 0.95\n",
      "gas_station 100 0.91\n",
      "gazebo_exterior 100 0.83\n",
      "general_store_indoor 100 0.62\n",
      "general_store_outdoor 100 0.86\n",
      "gift_shop 100 0.65\n",
      "glacier 100 0.94\n",
      "golf_course 100 0.95\n",
      "great_hall 100 0.39\n",
      "greenhouse_indoor 100 0.86\n",
      "greenhouse_outdoor 100 0.9\n",
      "grotto 100 0.92\n",
      "gymnasium_indoor 100 0.89\n",
      "hangar_indoor 100 0.96\n",
      "hangar_outdoor 100 0.83\n",
      "harbor 100 0.88\n",
      "hardware_store 100 0.6\n",
      "hat_shop 100 0.77\n",
      "hayfield 100 0.81\n",
      "heliport 100 0.95\n",
      "highway 100 0.9\n",
      "home_office 100 0.89\n",
      "home_theater 100 0.85\n",
      "hospital 100 0.6\n",
      "hospital_room 100 0.87\n",
      "hot_spring 100 0.83\n",
      "hot_tub_indoor 100 0.75\n",
      "hot_tub_outdoor 100 0.86\n",
      "hotel_outdoor 100 0.78\n",
      "hotel_room 100 0.97\n",
      "house 100 0.83\n",
      "hunting_lodge_outdoor 100 0.85\n",
      "ice_cream_parlor 100 0.69\n",
      "ice_floe 100 0.86\n",
      "ice_shelf 100 0.69\n",
      "ice_skating_rink_indoor 100 0.97\n",
      "ice_skating_rink_outdoor 100 0.92\n",
      "iceberg 100 0.99\n",
      "igloo 100 0.92\n",
      "industrial_area 100 0.86\n",
      "inn_outdoor 100 0.77\n",
      "islet 100 0.83\n",
      "jacuzzi_indoor 100 0.9\n",
      "jail_cell 100 0.92\n",
      "jail_indoor 100 0.17\n",
      "japanese_garden 100 0.81\n",
      "jewelry_shop 100 0.78\n",
      "junkyard 100 0.94\n",
      "kasbah 100 0.85\n",
      "kennel_indoor 100 0.67\n",
      "kennel_outdoor 100 0.82\n",
      "kindergarden_classroom 100 0.97\n",
      "kitchen 100 0.98\n",
      "labyrinth_outdoor 100 0.68\n",
      "lagoon 100 0.86\n",
      "lake_natural 100 0.83\n",
      "landfill 100 0.93\n",
      "landing_deck 100 0.97\n",
      "laundromat 100 0.95\n",
      "lawn 100 0.87\n",
      "lecture_room 100 0.94\n",
      "legislative_chamber 100 0.93\n",
      "library_indoor 100 0.94\n",
      "library_outdoor 100 0.76\n",
      "lido_deck_outdoor 100 0.8\n",
      "lighthouse 100 0.96\n",
      "limousine_interior 100 0.96\n",
      "liquor_store_outdoor 100 0.0\n",
      "living_room 100 0.9\n",
      "loading_dock 100 0.89\n",
      "lobby 100 0.9\n",
      "lock_chamber 100 0.79\n",
      "locker_room 100 0.91\n",
      "loft 100 0.55\n",
      "mansion 100 0.72\n",
      "manufactured_home 100 0.93\n",
      "market_indoor 100 0.59\n",
      "market_outdoor 100 0.86\n",
      "marsh 100 0.8\n",
      "martial_arts_gym 100 0.96\n",
      "mausoleum 100 0.85\n",
      "medina 100 0.82\n",
      "mezzanine 100 0.81\n",
      "moat_water 100 0.78\n",
      "mosque_outdoor 100 0.9\n",
      "motel 100 0.79\n",
      "mountain 100 0.84\n",
      "mountain_path 100 0.75\n",
      "mountain_snowy 100 0.96\n",
      "movie_theater_indoor 100 0.89\n",
      "museum_indoor 100 0.81\n",
      "museum_outdoor 100 0.65\n",
      "music_store 100 0.9\n",
      "music_studio 100 0.98\n",
      "natural_history_museum 100 0.92\n",
      "nuclear_power_plant_outdoor 100 0.86\n",
      "nursery 100 0.9\n",
      "nursing_home 100 0.85\n",
      "oast_house 100 0.83\n",
      "observatory_outdoor 100 0.69\n",
      "ocean 100 0.85\n",
      "office 100 0.83\n",
      "office_building 100 0.84\n",
      "office_cubicles 100 0.84\n",
      "oil_refinery_outdoor 100 0.69\n",
      "oilrig 100 0.92\n",
      "operating_room 100 0.97\n",
      "optician 100 0.83\n",
      "orchard 100 0.82\n",
      "orchestra_pit 100 0.96\n",
      "outhouse_outdoor 100 0.0\n",
      "pagoda 100 0.95\n",
      "palace 100 0.8\n",
      "pantry 100 0.92\n",
      "park 100 0.67\n",
      "parking_garage_indoor 100 0.87\n",
      "parking_garage_outdoor 100 0.79\n",
      "parking_lot 100 0.91\n",
      "pasture 100 0.81\n",
      "patio 100 0.88\n",
      "pavilion 100 0.85\n",
      "pet_shop 100 0.72\n",
      "pharmacy 100 0.71\n",
      "phone_booth 100 0.96\n",
      "physics_laboratory 100 0.84\n",
      "picnic_area 100 0.91\n",
      "pier 100 0.89\n",
      "pizzeria 100 0.81\n",
      "playground 100 0.98\n",
      "playroom 100 0.92\n",
      "plaza 100 0.7\n",
      "podium_indoor 100 0.0\n",
      "pond 100 0.8\n",
      "poolroom_home 100 0.9\n",
      "porch 100 0.88\n",
      "portrait_studio 100 0.69\n",
      "power_plant_outdoor 100 0.5\n",
      "promenade 100 0.84\n",
      "promenade_deck 100 0.76\n",
      "pub_indoor 100 0.94\n",
      "racecourse 100 0.91\n",
      "raceway 100 0.98\n",
      "raft 100 0.97\n",
      "railroad_track 100 0.93\n",
      "rainforest 100 0.88\n",
      "ranch_house 100 0.31\n",
      "reception 100 0.86\n",
      "recreation_room 100 0.59\n",
      "repair_shop 100 0.78\n",
      "residential_neighborhood 100 0.82\n",
      "rest_area 100 0.02\n",
      "restaurant 100 0.86\n",
      "restaurant_kitchen 100 0.95\n",
      "restaurant_patio 100 0.86\n",
      "rice_paddy 100 0.95\n",
      "river 100 0.69\n",
      "rock_arch 100 0.97\n",
      "roof_garden 100 0.9\n",
      "rope_bridge 100 0.85\n",
      "ruin 100 0.88\n",
      "runway 100 0.97\n",
      "sandbox 100 0.91\n",
      "sauna 100 0.84\n",
      "schoolhouse 100 0.77\n",
      "science_museum 100 0.75\n",
      "server_room 100 0.8\n",
      "shed 100 0.87\n",
      "shoe_shop 100 0.9\n",
      "shopfront 100 0.86\n",
      "shopping_mall_indoor 100 0.72\n",
      "shower 100 0.94\n",
      "shower_room 100 0.68\n",
      "ski_resort 100 0.89\n",
      "ski_slope 100 0.93\n",
      "sky 100 0.84\n",
      "skyscraper 100 0.9\n",
      "slum 100 0.86\n",
      "snowfield 100 0.95\n",
      "soccer_field 100 0.95\n",
      "squash_court 100 0.9\n",
      "stable 100 0.85\n",
      "stadium_baseball 100 0.99\n",
      "stadium_football 100 0.99\n",
      "stadium_soccer 100 0.95\n",
      "stage_indoor 100 0.9\n",
      "stage_outdoor 100 0.94\n",
      "staircase 100 0.96\n",
      "storage_room 100 0.8\n",
      "street 100 0.88\n",
      "subway_interior 100 0.92\n",
      "subway_station_platform 100 0.89\n",
      "supermarket 100 0.89\n",
      "sushi_bar 100 0.65\n",
      "swamp 100 0.9\n",
      "swimming_hole 100 0.91\n",
      "swimming_pool_indoor 100 0.95\n",
      "swimming_pool_outdoor 100 0.99\n",
      "synagogue_outdoor 100 0.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teashop 100 0.51\n",
      "television_room 100 0.94\n",
      "television_studio 100 0.81\n",
      "temple_asia 100 0.92\n",
      "tennis_court_indoor 100 0.93\n",
      "tennis_court_outdoor 100 0.95\n",
      "theater_indoor_seats 100 0.0\n",
      "thriftshop 100 0.22\n",
      "throne_room 100 0.83\n",
      "ticket_booth 100 0.7\n",
      "toll_plaza 100 0.83\n",
      "topiary_garden 100 0.81\n",
      "tower 100 0.87\n",
      "toyshop 100 0.8\n",
      "train_interior 100 0.96\n",
      "train_station_platform 100 0.97\n",
      "tree_farm 100 0.74\n",
      "tree_house 100 0.82\n",
      "trench 100 0.91\n",
      "tundra 100 0.87\n",
      "underwater_ocean_deep 100 0.98\n",
      "utility_room 100 0.86\n",
      "valley 100 0.75\n",
      "vegetable_garden 100 0.87\n",
      "veterinarians_office 100 0.9\n",
      "viaduct 100 0.87\n",
      "videostore 100 0.84\n",
      "village 100 0.85\n",
      "vineyard 100 0.9\n",
      "volcano 100 0.93\n",
      "volleyball_court_indoor 100 0.94\n",
      "volleyball_court_outdoor 100 0.93\n",
      "waiting_room 100 0.87\n",
      "walk_in_freezer 100 0.13\n",
      "warehouse_indoor 100 0.72\n",
      "water_park 100 0.92\n",
      "water_tower 100 0.89\n",
      "waterfall 100 0.98\n",
      "watering_hole 100 0.83\n",
      "wave 100 0.93\n",
      "wet_bar 100 0.89\n",
      "wheat_field 100 0.94\n",
      "wind_farm 100 1.0\n",
      "windmill 100 0.99\n",
      "wine_cellar_barrel_storage 100 0.88\n",
      "wine_cellar_bottle_storage 100 0.87\n",
      "yard 100 0.63\n",
      "youth_hostel 100 0.87\n",
      "zen_garden 100 0.75\n",
      "avg topK accuracy: 0.8256380510440835\n"
     ]
    }
   ],
   "source": [
    "all_pred_classes={}\n",
    "all_pred_scores={}\n",
    "avg_topK_accuracy=0\n",
    "val_ind=0\n",
    "for label in img_dirs:\n",
    "    img_dir=os.path.join(VAL_DATA_DIR,label)\n",
    "    img_files = sorted(os.listdir(img_dir))\n",
    "    pred_classes=[]\n",
    "    pred_scores=[]\n",
    "    num_correct_topK=0\n",
    "    for f in img_files:\n",
    "        val_ind+=1\n",
    "        if False:\n",
    "            img=val_images[val_ind]\n",
    "        else:\n",
    "            img=cv2.imread(os.path.join(img_dir,f))\n",
    "            img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "            img=cv2.resize(img,INPUT_SIZE)\n",
    "            img=preprocessing_function(img.astype(np.float32))\n",
    "        inp=np.expand_dims(img, axis=0)\n",
    "        preds=new_model.predict(inp)[0]\n",
    "        indices=preds.argsort()[::-1]\n",
    "        predictions=[idx_to_class[ind] for ind in indices]\n",
    "        if label in predictions[:5]:\n",
    "            num_correct_topK+=1\n",
    "        pred_classes.append(predictions)\n",
    "        pred_scores.append(preds)\n",
    "    topK_accuracy=num_correct_topK/len(img_files)\n",
    "    avg_topK_accuracy+=topK_accuracy\n",
    "    print(label,len(img_files),topK_accuracy)\n",
    "    all_pred_classes[label]=pred_classes\n",
    "    all_pred_scores[label]=pred_scores\n",
    "\n",
    "avg_topK_accuracy/=len(img_dirs)\n",
    "print('avg topK accuracy:',avg_topK_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airfield 0.7\n",
      "airplane_cabin 0.82\n",
      "airport_terminal 0.68\n",
      "alcove 0.33\n",
      "alley 0.73\n",
      "amphitheater 0.58\n",
      "amusement_arcade 0.74\n",
      "amusement_park 0.69\n",
      "anechoic_chamber 0.71\n",
      "apartment_building_outdoor 0.36\n",
      "aquarium 0.89\n",
      "aqueduct 0.54\n",
      "arcade 0.46\n",
      "arch 0.24\n",
      "archaelogical_excavation 0.6\n",
      "archive 0.42\n",
      "arena_hockey 0.98\n",
      "arena_performance 0.61\n",
      "arena_rodeo 0.88\n",
      "army_base 0.86\n",
      "art_gallery 0.64\n",
      "art_school 0.44\n",
      "art_studio 0.36\n",
      "artists_loft 0.2\n",
      "assembly_line 0.15\n",
      "athletic_field_indoor 0.14\n",
      "athletic_field_outdoor 0.58\n",
      "atrium_public 0.53\n",
      "attic 0.82\n",
      "auditorium 0.62\n",
      "auto_factory 0.38\n",
      "auto_showroom 0.91\n",
      "badlands 0.73\n",
      "badminton_court_indoor 0.31\n",
      "baggage_claim 0.78\n",
      "bakery_shop 0.57\n",
      "balcony_exterior 0.54\n",
      "balcony_interior 0.59\n",
      "ball_pit 0.84\n",
      "ballroom 0.75\n",
      "bamboo_forest 0.89\n",
      "bank_vault 0.49\n",
      "banquet_hall 0.78\n",
      "bar 0.41\n",
      "barn 0.62\n",
      "barndoor 0.47\n",
      "baseball_field 0.78\n",
      "basement 0.36\n",
      "basketball_court_indoor 0.89\n",
      "basketball_court_outdoor 0.56\n",
      "bathroom 0.84\n",
      "batters_box 0.0\n",
      "bazaar_indoor 0.23\n",
      "bazaar_outdoor 0.53\n",
      "beach 0.53\n",
      "beach_house 0.5\n",
      "beauty_salon 0.61\n",
      "bedchamber 0.44\n",
      "bedroom 0.61\n",
      "beer_garden 0.46\n",
      "beer_hall 0.47\n",
      "berth 0.55\n",
      "biology_laboratory 0.31\n",
      "boardwalk 0.56\n",
      "boat_deck 0.69\n",
      "boathouse 0.7\n",
      "bookstore 0.62\n",
      "booth_indoor 0.67\n",
      "botanical_garden 0.22\n",
      "bow_window_indoor 0.65\n",
      "bow_window_outdoor 0.02\n",
      "bowling_alley 0.92\n",
      "boxing_ring 0.98\n",
      "brewery_indoor 0.0\n",
      "bridge 0.47\n",
      "building_facade 0.08\n",
      "bullring 0.69\n",
      "burial_chamber 0.48\n",
      "bus_interior 0.75\n",
      "bus_station_indoor 0.79\n",
      "butchers_shop 0.65\n",
      "butte 0.46\n",
      "cabin_outdoor 0.67\n",
      "cafeteria 0.0\n",
      "campsite 0.86\n",
      "campus 0.41\n",
      "canal_natural 0.52\n",
      "canal_urban 0.67\n",
      "candy_store 0.37\n",
      "canyon 0.57\n",
      "car_interior 0.9\n",
      "carrousel 0.89\n",
      "casino_indoor 0.39\n",
      "castle 0.62\n",
      "catacomb 0.67\n",
      "cemetery 0.9\n",
      "chalet 0.38\n",
      "cheese_factory 0.44\n",
      "chemistry_lab 0.33\n",
      "chicken_coop_outdoor 0.29\n",
      "childs_room 0.47\n",
      "church_indoor 0.87\n",
      "church_outdoor 0.46\n",
      "classroom 0.48\n",
      "clean_room 0.44\n",
      "cliff 0.38\n",
      "closet 0.82\n",
      "clothing_store 0.55\n",
      "coast 0.14\n",
      "cockpit 0.95\n",
      "coffee_shop 0.38\n",
      "computer_room 0.45\n",
      "conference_center 0.28\n",
      "conference_room 0.61\n",
      "construction_site 0.5\n",
      "corn_field 0.72\n",
      "corral 0.7\n",
      "corridor 0.74\n",
      "cottage 0.37\n",
      "courthouse 0.6\n",
      "courtroom 0.49\n",
      "courtyard 0.35\n",
      "covered_bridge_exterior 0.45\n",
      "creek 0.63\n",
      "crevasse 0.62\n",
      "crosswalk 0.72\n",
      "cybercafe 0.14\n",
      "dam 0.73\n",
      "delicatessen 0.34\n",
      "dentists_office 0.59\n",
      "department_store 0.36\n",
      "desert_road 0.7\n",
      "desert_sand 0.76\n",
      "desert_vegetation 0.79\n",
      "diner_outdoor 0.4\n",
      "dinette_vehicle 0.13\n",
      "dining_car 0.47\n",
      "dining_hall 0.25\n",
      "dining_room 0.7\n",
      "discotheque 0.72\n",
      "doorway_outdoor 0.69\n",
      "dorm_room 0.34\n",
      "downtown 0.41\n",
      "dressing_room 0.31\n",
      "driveway 0.38\n",
      "driving_range_outdoor 0.0\n",
      "drugstore 0.11\n",
      "editing_room 0.13\n",
      "electrical_substation 0.79\n",
      "elevator_door 0.36\n",
      "elevator_interior 0.64\n",
      "elevator_lobby 0.29\n",
      "elevator_shaft 0.51\n",
      "embassy 0.59\n",
      "engine_room 0.66\n",
      "entrance_hall 0.46\n",
      "escalator_indoor 0.74\n",
      "excavation 0.67\n",
      "fabric_store 0.55\n",
      "factory_indoor 0.0\n",
      "farm 0.14\n",
      "fastfood_restaurant 0.34\n",
      "field_cultivated 0.46\n",
      "field_road 0.58\n",
      "field_wild 0.47\n",
      "fire_escape 0.77\n",
      "fire_station 0.78\n",
      "firing_range_indoor 0.47\n",
      "fishpond 0.6\n",
      "fitting_room_interior 0.0\n",
      "flea_market_indoor 0.27\n",
      "florist_shop_indoor 0.83\n",
      "florist_shop_outdoor 0.3\n",
      "food_court 0.4\n",
      "football_field 0.53\n",
      "forest_broadleaf 0.57\n",
      "forest_needleleaf 0.0\n",
      "forest_path 0.6\n",
      "forest_road 0.64\n",
      "formal_garden 0.5\n",
      "fountain 0.84\n",
      "funeral_home 0.05\n",
      "galley 0.63\n",
      "garage_indoor 0.61\n",
      "garage_outdoor 0.84\n",
      "gas_station 0.83\n",
      "gazebo_exterior 0.6\n",
      "general_store_indoor 0.19\n",
      "general_store_outdoor 0.49\n",
      "gift_shop 0.19\n",
      "glacier 0.62\n",
      "golf_course 0.87\n",
      "great_hall 0.04\n",
      "greenhouse_indoor 0.58\n",
      "greenhouse_outdoor 0.61\n",
      "grotto 0.77\n",
      "gymnasium_indoor 0.81\n",
      "hangar_indoor 0.81\n",
      "hangar_outdoor 0.38\n",
      "harbor 0.48\n",
      "hardware_store 0.23\n",
      "hat_shop 0.65\n",
      "hayfield 0.48\n",
      "heliport 0.61\n",
      "highway 0.67\n",
      "home_office 0.56\n",
      "home_theater 0.54\n",
      "hospital 0.31\n",
      "hospital_room 0.66\n",
      "hot_spring 0.65\n",
      "hot_tub_indoor 0.15\n",
      "hot_tub_outdoor 0.52\n",
      "hotel_outdoor 0.46\n",
      "hotel_room 0.76\n",
      "house 0.25\n",
      "hunting_lodge_outdoor 0.49\n",
      "ice_cream_parlor 0.46\n",
      "ice_floe 0.57\n",
      "ice_shelf 0.12\n",
      "ice_skating_rink_indoor 0.31\n",
      "ice_skating_rink_outdoor 0.63\n",
      "iceberg 0.78\n",
      "igloo 0.74\n",
      "industrial_area 0.42\n",
      "inn_outdoor 0.44\n",
      "islet 0.62\n",
      "jacuzzi_indoor 0.57\n",
      "jail_cell 0.61\n",
      "jail_indoor 0.0\n",
      "japanese_garden 0.58\n",
      "jewelry_shop 0.57\n",
      "junkyard 0.75\n",
      "kasbah 0.65\n",
      "kennel_indoor 0.43\n",
      "kennel_outdoor 0.46\n",
      "kindergarden_classroom 0.77\n",
      "kitchen 0.81\n",
      "labyrinth_outdoor 0.48\n",
      "lagoon 0.48\n",
      "lake_natural 0.26\n",
      "landfill 0.72\n",
      "landing_deck 0.82\n",
      "laundromat 0.86\n",
      "lawn 0.52\n",
      "lecture_room 0.49\n",
      "legislative_chamber 0.54\n",
      "library_indoor 0.71\n",
      "library_outdoor 0.45\n",
      "lido_deck_outdoor 0.56\n",
      "lighthouse 0.88\n",
      "limousine_interior 0.68\n",
      "liquor_store_outdoor 0.0\n",
      "living_room 0.48\n",
      "loading_dock 0.56\n",
      "lobby 0.53\n",
      "lock_chamber 0.44\n",
      "locker_room 0.72\n",
      "loft 0.04\n",
      "mansion 0.31\n",
      "manufactured_home 0.57\n",
      "market_indoor 0.23\n",
      "market_outdoor 0.56\n",
      "marsh 0.46\n",
      "martial_arts_gym 0.79\n",
      "mausoleum 0.51\n",
      "medina 0.53\n",
      "mezzanine 0.21\n",
      "moat_water 0.3\n",
      "mosque_outdoor 0.59\n",
      "motel 0.56\n",
      "mountain 0.15\n",
      "mountain_path 0.39\n",
      "mountain_snowy 0.42\n",
      "movie_theater_indoor 0.31\n",
      "museum_indoor 0.42\n",
      "museum_outdoor 0.16\n",
      "music_store 0.84\n",
      "music_studio 0.71\n",
      "natural_history_museum 0.79\n",
      "nuclear_power_plant_outdoor 0.72\n",
      "nursery 0.78\n",
      "nursing_home 0.57\n",
      "oast_house 0.48\n",
      "observatory_outdoor 0.56\n",
      "ocean 0.24\n",
      "office 0.46\n",
      "office_building 0.19\n",
      "office_cubicles 0.43\n",
      "oil_refinery_outdoor 0.5\n",
      "oilrig 0.61\n",
      "operating_room 0.77\n",
      "optician 0.68\n",
      "orchard 0.57\n",
      "orchestra_pit 0.76\n",
      "outhouse_outdoor 0.0\n",
      "pagoda 0.66\n",
      "palace 0.27\n",
      "pantry 0.68\n",
      "park 0.32\n",
      "parking_garage_indoor 0.64\n",
      "parking_garage_outdoor 0.38\n",
      "parking_lot 0.65\n",
      "pasture 0.44\n",
      "patio 0.44\n",
      "pavilion 0.41\n",
      "pet_shop 0.27\n",
      "pharmacy 0.41\n",
      "phone_booth 0.96\n",
      "physics_laboratory 0.38\n",
      "picnic_area 0.65\n",
      "pier 0.61\n",
      "pizzeria 0.65\n",
      "playground 0.9\n",
      "playroom 0.63\n",
      "plaza 0.24\n",
      "podium_indoor 0.0\n",
      "pond 0.24\n",
      "poolroom_home 0.8\n",
      "porch 0.57\n",
      "portrait_studio 0.53\n",
      "power_plant_outdoor 0.01\n",
      "promenade 0.51\n",
      "promenade_deck 0.49\n",
      "pub_indoor 0.6\n",
      "racecourse 0.82\n",
      "raceway 0.9\n",
      "raft 0.86\n",
      "railroad_track 0.73\n",
      "rainforest 0.54\n",
      "ranch_house 0.03\n",
      "reception 0.62\n",
      "recreation_room 0.13\n",
      "repair_shop 0.32\n",
      "residential_neighborhood 0.54\n",
      "rest_area 0.0\n",
      "restaurant 0.46\n",
      "restaurant_kitchen 0.72\n",
      "restaurant_patio 0.58\n",
      "rice_paddy 0.71\n",
      "river 0.05\n",
      "rock_arch 0.84\n",
      "roof_garden 0.4\n",
      "rope_bridge 0.68\n",
      "ruin 0.52\n",
      "runway 0.71\n",
      "sandbox 0.71\n",
      "sauna 0.62\n",
      "schoolhouse 0.56\n",
      "science_museum 0.34\n",
      "server_room 0.59\n",
      "shed 0.58\n",
      "shoe_shop 0.77\n",
      "shopfront 0.69\n",
      "shopping_mall_indoor 0.3\n",
      "shower 0.59\n",
      "shower_room 0.0\n",
      "ski_resort 0.59\n",
      "ski_slope 0.74\n",
      "sky 0.51\n",
      "skyscraper 0.59\n",
      "slum 0.64\n",
      "snowfield 0.53\n",
      "soccer_field 0.72\n",
      "squash_court 0.81\n",
      "stable 0.64\n",
      "stadium_baseball 0.79\n",
      "stadium_football 0.37\n",
      "stadium_soccer 0.59\n",
      "stage_indoor 0.54\n",
      "stage_outdoor 0.75\n",
      "staircase 0.72\n",
      "storage_room 0.35\n",
      "street 0.57\n",
      "subway_interior 0.44\n",
      "subway_station_platform 0.53\n",
      "supermarket 0.64\n",
      "sushi_bar 0.31\n",
      "swamp 0.49\n",
      "swimming_hole 0.62\n",
      "swimming_pool_indoor 0.68\n",
      "swimming_pool_outdoor 0.82\n",
      "synagogue_outdoor 0.53\n",
      "teashop 0.18\n",
      "television_room 0.63\n",
      "television_studio 0.5\n",
      "temple_asia 0.64\n",
      "tennis_court_indoor 0.79\n",
      "tennis_court_outdoor 0.89\n",
      "theater_indoor_seats 0.0\n",
      "thriftshop 0.0\n",
      "throne_room 0.55\n",
      "ticket_booth 0.38\n",
      "toll_plaza 0.43\n",
      "topiary_garden 0.59\n",
      "tower 0.35\n",
      "toyshop 0.48\n",
      "train_interior 0.58\n",
      "train_station_platform 0.75\n",
      "tree_farm 0.48\n",
      "tree_house 0.5\n",
      "trench 0.59\n",
      "tundra 0.61\n",
      "underwater_ocean_deep 0.79\n",
      "utility_room 0.37\n",
      "valley 0.11\n",
      "vegetable_garden 0.55\n",
      "veterinarians_office 0.79\n",
      "viaduct 0.69\n",
      "videostore 0.62\n",
      "village 0.7\n",
      "vineyard 0.76\n",
      "volcano 0.87\n",
      "volleyball_court_indoor 0.75\n",
      "volleyball_court_outdoor 0.81\n",
      "waiting_room 0.52\n",
      "walk_in_freezer 0.02\n",
      "warehouse_indoor 0.37\n",
      "water_park 0.53\n",
      "water_tower 0.79\n",
      "waterfall 0.89\n",
      "watering_hole 0.59\n",
      "wave 0.71\n",
      "wet_bar 0.36\n",
      "wheat_field 0.65\n",
      "wind_farm 0.94\n",
      "windmill 0.94\n",
      "wine_cellar_barrel_storage 0.79\n",
      "wine_cellar_bottle_storage 0.62\n",
      "yard 0.29\n",
      "youth_hostel 0.43\n",
      "zen_garden 0.46\n",
      "avg topK accuracy: 0.5329466357308587\n"
     ]
    }
   ],
   "source": [
    "avg_topK_accuracy=0\n",
    "class_accuracies={}\n",
    "incorrect_labels={}\n",
    "num_all_images=0\n",
    "\n",
    "K=1\n",
    "for label in img_dirs:\n",
    "    num_correct_topK=0\n",
    "    for predictions in all_pred_classes[label]:\n",
    "        num_all_images+=1\n",
    "        if label in predictions[:K]:\n",
    "            num_correct_topK+=1\n",
    "        else:\n",
    "            for l in predictions[:K]:\n",
    "                if l in incorrect_labels:\n",
    "                    incorrect_labels[l]+=1\n",
    "                else:\n",
    "                    incorrect_labels[l]=1\n",
    "    topK_accuracy=num_correct_topK/len(all_pred_classes[label])\n",
    "    class_accuracies[label]=topK_accuracy\n",
    "    avg_topK_accuracy+=topK_accuracy\n",
    "    print(label,topK_accuracy)\n",
    "\n",
    "avg_topK_accuracy/=len(img_dirs)\n",
    "print('avg topK accuracy:',avg_topK_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "new_sys_dir = os.path.join('..','keras-surgeon','src')\n",
    "if not new_sys_dir in sys.path:\n",
    "    sys.path.append(new_sys_dir)\n",
    "\n",
    "#import importlib\n",
    "#import kerassurgeon\n",
    "#importlib.reload(kerassurgeon)\n",
    "#from kerassurgeon import identify,utils\n",
    "from kerassurgeon.operations import delete_channels\n",
    "#from kerassurgeon import Surgeon\n",
    "\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1 <keras.layers.convolutional.Conv2D object at 0x7f12bed83780>\n",
      "expanded_conv_project <keras.layers.convolutional.Conv2D object at 0x7f12bfa9ad68>\n",
      "block_1_expand <keras.layers.convolutional.Conv2D object at 0x7f12c6fb2278>\n",
      "block_1_project <keras.layers.convolutional.Conv2D object at 0x7f12c6d0c630>\n",
      "block_2_expand <keras.layers.convolutional.Conv2D object at 0x7f12c6cb59e8>\n",
      "block_2_project <keras.layers.convolutional.Conv2D object at 0x7f12c6aa87b8>\n",
      "block_3_expand <keras.layers.convolutional.Conv2D object at 0x7f12c6996b00>\n",
      "block_3_project <keras.layers.convolutional.Conv2D object at 0x7f12bfcdfc88>\n",
      "block_4_expand <keras.layers.convolutional.Conv2D object at 0x7f12bfc24550>\n",
      "block_4_project <keras.layers.convolutional.Conv2D object at 0x7f12bf9d1cf8>\n",
      "block_5_expand <keras.layers.convolutional.Conv2D object at 0x7f12bf8c7748>\n",
      "block_5_project <keras.layers.convolutional.Conv2D object at 0x7f12bf76bda0>\n",
      "block_6_expand <keras.layers.convolutional.Conv2D object at 0x7f12bec84400>\n",
      "block_6_project <keras.layers.convolutional.Conv2D object at 0x7f12beac6978>\n",
      "block_7_expand <keras.layers.convolutional.Conv2D object at 0x7f12bea9f470>\n",
      "block_7_project <keras.layers.convolutional.Conv2D object at 0x7f12be857ac8>\n",
      "block_8_expand <keras.layers.convolutional.Conv2D object at 0x7f12be74ee48>\n",
      "block_8_project <keras.layers.convolutional.Conv2D object at 0x7f12be5997b8>\n",
      "block_9_expand <keras.layers.convolutional.Conv2D object at 0x7f12be485b00>\n",
      "block_9_project <keras.layers.convolutional.Conv2D object at 0x7f12be2cde48>\n",
      "block_10_expand <keras.layers.convolutional.Conv2D object at 0x7f12be23d898>\n",
      "block_10_project <keras.layers.convolutional.Conv2D object at 0x7f12be001b00>\n",
      "block_11_expand <keras.layers.convolutional.Conv2D object at 0x7f12bdfe36d8>\n",
      "block_11_project <keras.layers.convolutional.Conv2D object at 0x7f12bdd9d9e8>\n",
      "block_12_expand <keras.layers.convolutional.Conv2D object at 0x7f12bdcbae80>\n",
      "block_12_project <keras.layers.convolutional.Conv2D object at 0x7f12bdada940>\n",
      "block_13_expand <keras.layers.convolutional.Conv2D object at 0x7f12bd9cbc88>\n",
      "block_13_project <keras.layers.convolutional.Conv2D object at 0x7f12bd813e10>\n",
      "block_14_expand <keras.layers.convolutional.Conv2D object at 0x7f12bd7586d8>\n",
      "block_14_project <keras.layers.convolutional.Conv2D object at 0x7f12bd54a908>\n",
      "block_15_expand <keras.layers.convolutional.Conv2D object at 0x7f12bd4bab00>\n",
      "block_15_project <keras.layers.convolutional.Conv2D object at 0x7f12bd2998d0>\n",
      "block_16_expand <keras.layers.convolutional.Conv2D object at 0x7f12bd18c748>\n",
      "block_16_project <keras.layers.convolutional.Conv2D object at 0x7f12bcfcfe10>\n",
      "Conv_1 <keras.layers.convolutional.Conv2D object at 0x7f12bcf17668>\n",
      "['Conv1', 'expanded_conv_project', 'block_1_expand', 'block_1_project', 'block_2_expand', 'block_2_project', 'block_3_expand', 'block_3_project', 'block_4_expand', 'block_4_project', 'block_5_expand', 'block_5_project', 'block_6_expand', 'block_6_project', 'block_7_expand', 'block_7_project', 'block_8_expand', 'block_8_project', 'block_9_expand', 'block_9_project', 'block_10_expand', 'block_10_project', 'block_11_expand', 'block_11_project', 'block_12_expand', 'block_12_project', 'block_13_expand', 'block_13_project', 'block_14_expand', 'block_14_project', 'block_15_expand', 'block_15_project', 'block_16_expand', 'block_16_project', 'Conv_1']\n"
     ]
    }
   ],
   "source": [
    "#K.clear_session()\n",
    "#tf.reset_default_graph()\n",
    "reduced_model, bm=net()\n",
    "reduced_model.load_weights(net_description+'_augm_ft_sgd.h5')\n",
    "layers=[]\n",
    "for l in bm.layers:\n",
    "    if type(l) is Conv2D:# or type(l) is DepthwiseConv2D:\n",
    "        print(l.name,l)\n",
    "        layers.append(l.name)\n",
    "print(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.layers import Layer\n",
    "from keras.activations import linear\n",
    "\n",
    "\n",
    "def clean_copy(model):\n",
    "    \"\"\"Returns a copy of the model without other model uses of its layers.\"\"\"\n",
    "    weights = model.get_weights()\n",
    "    new_model = model.__class__.from_config(model.get_config())\n",
    "    new_model.set_weights(weights)\n",
    "    return new_model\n",
    "\n",
    "\n",
    "def get_channels_attr(layer):\n",
    "    layer_config = layer.get_config()\n",
    "    if 'units' in layer_config.keys():\n",
    "        channels_attr = 'units'\n",
    "    elif 'filters' in layer_config.keys():\n",
    "        channels_attr = 'filters'\n",
    "    else:\n",
    "        raise ValueError('This layer has not got any channels.')\n",
    "    return channels_attr\n",
    "\n",
    "\n",
    "def get_node_depth(model, node):\n",
    "    \"\"\"Get the depth of a node in a model.\n",
    "    Arguments:\n",
    "        model: Keras Model object\n",
    "        node: Keras Node object\n",
    "    Returns:\n",
    "        The node depth as an integer. The model outputs are at depth 0.\n",
    "    Raises:\n",
    "        KeyError: if the node is not contained in the model.\n",
    "    \"\"\"\n",
    "    for (depth, nodes_at_depth) in get_nodes_by_depth(model).items():\n",
    "        if node in nodes_at_depth:\n",
    "            return depth\n",
    "    raise KeyError('The node is not contained in the model.')\n",
    "\n",
    "\n",
    "def check_for_layer_reuse(model, layers=None):\n",
    "    \"\"\"Returns True if any layers are reused, False if not.\"\"\"\n",
    "    if layers is None:\n",
    "        layers = model.layers\n",
    "    return any([len(get_inbound_nodes(l)) > 1 for l in layers])\n",
    "\n",
    "\n",
    "def find_nodes_in_model(model, layer):\n",
    "    \"\"\"Find the indices of layer's inbound nodes which are in model\"\"\"\n",
    "    model_nodes = get_model_nodes(model)\n",
    "    node_indices = []\n",
    "    for i, node in enumerate(get_inbound_nodes(layer)):\n",
    "        if node in model_nodes:\n",
    "            node_indices.append(i)\n",
    "    return node_indices\n",
    "\n",
    "\n",
    "def check_nodes_in_model(model, nodes):\n",
    "    \"\"\"Check if nodes are in model\"\"\"\n",
    "    model_nodes = get_model_nodes(model)\n",
    "    nodes_in_model = [False] * len(nodes)\n",
    "    for i, node in enumerate(nodes):\n",
    "        if node in model_nodes:\n",
    "            nodes_in_model[i] = True\n",
    "    return nodes_in_model\n",
    "\n",
    "\n",
    "def get_model_nodes(model):\n",
    "    \"\"\"Return all nodes in the model\"\"\"\n",
    "    return [node for v in get_nodes_by_depth(model).values() for node in v]\n",
    "\n",
    "\n",
    "def get_shallower_nodes(node):\n",
    "    possible_nodes = get_outbound_nodes(node.outbound_layer)\n",
    "    next_nodes = []\n",
    "    for n in possible_nodes:\n",
    "        for i, node_index in enumerate(n.node_indices):\n",
    "            if node == get_inbound_nodes(n.inbound_layers[i])[node_index]:\n",
    "                next_nodes.append(n)\n",
    "    return next_nodes\n",
    "\n",
    "\n",
    "def get_node_inbound_nodes(node):\n",
    "    return [get_inbound_nodes(node.inbound_layers[i])[node_index]\n",
    "            for i, node_index in enumerate(node.node_indices)]\n",
    "\n",
    "\n",
    "def get_inbound_nodes(layer):\n",
    "    try:\n",
    "        return getattr(layer, '_inbound_nodes')\n",
    "    except AttributeError:\n",
    "        warnings.warn(\"Please update keras to version 2.1.3 or greater.\"\n",
    "                      \"Support for earlier versions will be dropped in a \"\n",
    "                      \"future release.\")\n",
    "        return layer.inbound_nodes\n",
    "\n",
    "\n",
    "def get_outbound_nodes(layer):\n",
    "    try:\n",
    "        return getattr(layer, '_outbound_nodes')\n",
    "    except AttributeError:\n",
    "        warnings.warn(\"Please update keras to version 2.1.3 or greater.\"\n",
    "                      \"Support for earlier versions will be dropped in a \"\n",
    "                      \"future release.\")\n",
    "        return layer.outbound_nodes\n",
    "\n",
    "\n",
    "def get_nodes_by_depth(model):\n",
    "    try:\n",
    "        return getattr(model, '_nodes_by_depth')\n",
    "    except AttributeError:\n",
    "        warnings.warn(\"Please update keras to version 2.1.3 or greater.\"\n",
    "                      \"Support for earlier versions will be dropped in a \"\n",
    "                      \"future release.\")\n",
    "        return model.nodes_by_depth\n",
    "\n",
    "\n",
    "def get_node_index(node):\n",
    "    for i, n in enumerate(get_inbound_nodes(node.outbound_layer)):\n",
    "        if node == n:\n",
    "            return i\n",
    "\n",
    "\n",
    "def find_activation_layer(layer, node_index):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        layer(Layer):\n",
    "        node_index:\n",
    "    \"\"\"\n",
    "    output_shape = layer.get_output_shape_at(node_index)\n",
    "    maybe_layer = layer\n",
    "    node = get_inbound_nodes(maybe_layer)[node_index]\n",
    "    # Loop will be broken by an error if an output layer is encountered\n",
    "    while True:\n",
    "        # If maybe_layer has a nonlinear activation function return it and its index\n",
    "        activation = getattr(maybe_layer, 'activation', linear)\n",
    "        #print(maybe_layer,activation)\n",
    "        if activation.__name__ != 'linear' or 'ReLU' in maybe_layer.__class__.__name__:\n",
    "            if maybe_layer.get_output_shape_at(node_index) != output_shape:\n",
    "                ValueError('The activation layer ({0}), does not have the same'\n",
    "                           ' output shape as {1}'.format(maybe_layer.name,\n",
    "                                                         layer.name))\n",
    "            return maybe_layer, node_index\n",
    "\n",
    "        # If not, move to the next layer in the datastream\n",
    "        next_nodes = get_shallower_nodes(node)\n",
    "        # test if node is a list of nodes with more than one item\n",
    "        if len(next_nodes) > 1:\n",
    "            ValueError('The model must not branch between the chosen layer'\n",
    "                       ' and the activation layer.')\n",
    "        node = next_nodes[0]\n",
    "        node_index = get_node_index(node)\n",
    "        maybe_layer = node.outbound_layer\n",
    "\n",
    "        # Check if maybe_layer has weights, no activation layer has been found\n",
    "        if maybe_layer.weights and (\n",
    "                not maybe_layer.__class__.__name__.startswith('Global')):\n",
    "            AttributeError('There is no nonlinear activation layer between {0}'\n",
    "                           ' and {1}'.format(layer.name, maybe_layer.name))\n",
    "\n",
    "\n",
    "def sort_x_by_y(x, y):\n",
    "    \"\"\"Sort the iterable x by the order of iterable y\"\"\"\n",
    "    x = [x for (_, x) in sorted(zip(y, x))]\n",
    "    return x\n",
    "\n",
    "\n",
    "def single_element(x):\n",
    "    \"\"\"If x contains a single element, return it; otherwise return x\"\"\"\n",
    "    if len(x) == 1:\n",
    "        x = x[0]\n",
    "    return x\n",
    "\n",
    "\n",
    "def bool_to_index(x):\n",
    "    return [i for i, v in enumerate(x) if v]\n",
    "\n",
    "\n",
    "def all_equal(iterator):\n",
    "    try:\n",
    "        iterator = iter(iterator)\n",
    "        first = next(iterator)\n",
    "        return all(\n",
    "            np.array_equal(first, rest) for rest in iterator)\n",
    "    except StopIteration:\n",
    "        return True\n",
    "\n",
    "\n",
    "class MeanCalculator:\n",
    "    def __init__(self, sum_axis):\n",
    "        self.values = None\n",
    "        self.n = 0\n",
    "        self.sum_axis = sum_axis\n",
    "\n",
    "    def add(self, v):\n",
    "        if self.values is None:\n",
    "            self.values = v.sum(axis=self.sum_axis)\n",
    "        else:\n",
    "            self.values += v.sum(axis=self.sum_axis)\n",
    "        self.n += v.shape[self.sum_axis]\n",
    "\n",
    "    def calculate(self):\n",
    "        return self.values / self.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import numpy as np\n",
    "from keras.engine.topology import Node\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.models import Model\n",
    "\n",
    "from kerassurgeon import utils\n",
    "from kerassurgeon.utils import get_inbound_nodes\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "class Surgeon:\n",
    "    \"\"\"Performs network surgery on a model.\n",
    "\n",
    "    Surgeons can perform multiple network surgeries (jobs) at once.\n",
    "    This is much faster than performing them sequentially.\n",
    "    See `add_jobs` for a list of valid jobs and their required keyword arguments.\n",
    "\n",
    "    Examples:\n",
    "        Delete some channels from layer_1 and layer_2:\n",
    "            surgeon = Surgeon(model)\n",
    "            surgeon.add_job('delete_channels', layer_1, channels_1)\n",
    "            surgeon.add_job('delete_channels', layer_2, channels_2)\n",
    "            new_model = surgeon.operate()\n",
    "\n",
    "    Arguments:\n",
    "        model: The model to be modified\n",
    "        copy: If True, the model will be copied before and after any operations\n",
    "              This keeps the layers in the original model and the new model separate.\n",
    "    \"\"\"\n",
    "    def __init__(self, model, copy=None):\n",
    "        if copy:\n",
    "            self.model = utils.clean_copy(model)\n",
    "        else:\n",
    "            self.model = model\n",
    "        self.nodes = []\n",
    "        self._copy = copy\n",
    "        self._finished_nodes = {}\n",
    "        self._replace_tensors = {}\n",
    "        self._channels_map = {}\n",
    "        self._new_layers_map = {}\n",
    "        self._insert_layers_map = {}\n",
    "        self._replace_layers_map = {}\n",
    "        self._mod_func_map = {}\n",
    "        self._kwargs_map = {}\n",
    "        self.valid_jobs = ('delete_layer',\n",
    "                           'insert_layer',\n",
    "                           'replace_layer',\n",
    "                           'delete_channels')\n",
    "\n",
    "    def add_job(self, job, layer, *,\n",
    "                channels=None, new_layer=None, node_indices=None):\n",
    "        \"\"\"Adds a job for the Surgeon to perform on the model.\n",
    "\n",
    "        Job options are:\n",
    "        'delete_layer': delete `layer` from the model\n",
    "                        required keyword arguments: None\n",
    "        'insert_layer': insert `new_layer` before `layer`\n",
    "                        required keyword arguments: `new_layer`\n",
    "        'replace_layer': replace `layer` with `new_layer`\n",
    "                         required keyword arguments: `new_layer`\n",
    "        'delete_channels': delete `channels` from `layer`\n",
    "                           required keyword arguments: `channels`\n",
    "\n",
    "        Jobs can be added in any order. They will be performed in order of\n",
    "        decreasing network depth.\n",
    "        A maximum of one job can be performed per node.\n",
    "\n",
    "        Args:\n",
    "            job(string): job identifier. One of `Surgeon.valid_jobs`.\n",
    "            layer(Layer): A layer from `model` to be modified.\n",
    "            channels(list[int]): A list of channels used for the job.\n",
    "                                 Used in `delete_channels`.\n",
    "            new_layer(Layer): A new layer used for the job. Used in\n",
    "                              `insert_layer` and `replace_layer`.\n",
    "            node_indices(list[int]): (optional) A list of node indices used to\n",
    "                                    selectively apply the job to a subset of\n",
    "                                    the layer's nodes. Nodes are selected with:\n",
    "                                    node[i] = layer.inbound_nodes[node_indices[i]]\n",
    "        \"\"\"\n",
    "        # If the model has been copied, identify `layer` in the copied model.\n",
    "        if self._copy:\n",
    "            layer = self.model.get_layer(layer.name)\n",
    "        # Check that layer is in the model\n",
    "        if layer not in self.model.layers:\n",
    "            raise ValueError('layer is not a valid Layer in model.')\n",
    "\n",
    "        layer_node_indices = utils.find_nodes_in_model(self.model, layer)\n",
    "        # If no nodes are specified, all of the layer's inbound nodes which are\n",
    "        # in model are selected.\n",
    "        if not node_indices:\n",
    "            node_indices = layer_node_indices\n",
    "        # Check for duplicate node indices\n",
    "        elif len(node_indices) != len(set(node_indices)):\n",
    "            raise ValueError('`node_indices` contains duplicate values.')\n",
    "        # Check that all of the selected nodes are in the layer\n",
    "        elif not set(node_indices).issubset(layer_node_indices):\n",
    "            raise ValueError('One or more nodes specified by `layer` and '\n",
    "                             '`node_indices` are not in `model`.')\n",
    "\n",
    "        # Select the modification function and any keyword arguments.\n",
    "        kwargs = {}\n",
    "        if job == 'delete_channels':\n",
    "            # If not all inbound_nodes are selected, the new layer is renamed\n",
    "            # to avoid duplicate layer names.\n",
    "            if set(node_indices) != set(layer_node_indices):\n",
    "                kwargs['layer_name'] = layer.name + '_' + job\n",
    "            kwargs['channels'] = channels\n",
    "            mod_func = self._delete_channels\n",
    "\n",
    "        elif job == 'delete_layer':\n",
    "            mod_func = self._delete_layer\n",
    "\n",
    "        elif job == 'insert_layer':\n",
    "            kwargs['new_layer'] = new_layer\n",
    "            mod_func = self._insert_layer\n",
    "\n",
    "        elif job == 'replace_layer':\n",
    "            kwargs['new_layer'] = new_layer\n",
    "            mod_func = self._replace_layer\n",
    "\n",
    "        else:\n",
    "            raise ValueError(job + ' is not a recognised job. Valid jobs '\n",
    "                             'are:\\n-', '\\n- '.join(self.valid_jobs))\n",
    "\n",
    "        # Get nodes to be operated on for this job\n",
    "        job_nodes = []\n",
    "        for node_index in node_indices:\n",
    "            job_nodes.append(get_inbound_nodes(layer)[node_index])\n",
    "        # Check that the nodes do not already have jobs assigned to them.\n",
    "        if set(job_nodes).intersection(self.nodes):\n",
    "            raise ValueError('Cannot apply several jobs to the same node.')\n",
    "\n",
    "        # Add the modification function and keyword arguments to the\n",
    "        # self._mod_func_map and _kwargs_map dictionaries for later retrieval.\n",
    "        for node in job_nodes:\n",
    "            self._mod_func_map[node] = mod_func\n",
    "            self._kwargs_map[node] = kwargs\n",
    "        self.nodes.extend(job_nodes)\n",
    "\n",
    "    def operate(self):\n",
    "        \"\"\"Perform all jobs assigned to the surgeon.\n",
    "        \"\"\"\n",
    "        # Operate on each node in self.nodes by order of decreasing depth.\n",
    "        sorted_nodes = sorted(self.nodes, reverse=True,\n",
    "                              key=lambda x: utils.get_node_depth(self.model, x))\n",
    "        for node in sorted_nodes:\n",
    "            # Rebuild submodel up to this node\n",
    "            sub_output_nodes = utils.get_node_inbound_nodes(node)\n",
    "            outputs, output_masks = self._rebuild_graph(self.model.inputs,\n",
    "                                                        sub_output_nodes)\n",
    "\n",
    "            # Perform surgery at this node\n",
    "            kwargs = self._kwargs_map[node]\n",
    "            self._mod_func_map[node](node, outputs, output_masks, **kwargs)\n",
    "\n",
    "        # Finish rebuilding model\n",
    "        output_nodes = []\n",
    "        for output in self.model.outputs:\n",
    "            layer, node_index, tensor_index = output._keras_history\n",
    "            output_nodes.append(get_inbound_nodes(layer)[node_index])\n",
    "        new_outputs, _ = self._rebuild_graph(self.model.inputs, output_nodes)\n",
    "        new_model = Model(self.model.inputs, new_outputs)\n",
    "\n",
    "        if self._copy:\n",
    "            return utils.clean_copy(new_model)\n",
    "        else:\n",
    "            return new_model\n",
    "\n",
    "    def _rebuild_graph(self,\n",
    "                       graph_inputs,\n",
    "                       output_nodes,\n",
    "                       graph_input_masks=None):\n",
    "        \"\"\"Rebuild the graph from graph_inputs to output_nodes.\n",
    "\n",
    "        This does not return a model object, it re-creates the connections\n",
    "        between layers and returns the output tensors and masks of the submodel\n",
    "        This is a building block for the higher level surgery methods.\n",
    "        See `Surgeon.operate` for details of how this method is used.\n",
    "\n",
    "        Arguments:\n",
    "            graph_inputs: List of the submodel's input tensor(s).\n",
    "            output_nodes(list[Node]): List of the submodel's output node(s)\n",
    "            graph_input_masks: Boolean mask for each submodel input.\n",
    "\n",
    "        Returns:\n",
    "            (tuple) containing :\n",
    "                List of the output tensors of the rebuilt submodel\n",
    "                List of the output masks of the rebuilt submodel\n",
    "            tuple[submodel output tensors, output masks]\n",
    "\n",
    "        \"\"\"\n",
    "        if not graph_input_masks:\n",
    "            graph_input_masks = [None] * len(graph_inputs)\n",
    "\n",
    "        def _rebuild_rec(node):\n",
    "            \"\"\"Rebuild the graph up to `node` recursively.\n",
    "\n",
    "            Args:\n",
    "                node(Node): Node to rebuild up to.\n",
    "            Returns:\n",
    "                (tuple) containing :\n",
    "                The output tensor of the rebuilt `node`\n",
    "                The output mask of the rebuilt `node`\n",
    "\n",
    "            \"\"\"\n",
    "            # TODO: What happens if nodes have multiple output tensors?\n",
    "            # Does that ever happen?\n",
    "            layer = node.outbound_layer\n",
    "            logging.debug('getting inputs for: {0}'.format(layer.name))\n",
    "            node_output = utils.single_element(node.output_tensors)\n",
    "            # First check for conditions to bottom out the recursion\n",
    "            # Check for replaced tensors before any other checks:\n",
    "            # these are created by the surgery methods.\n",
    "            if node_output in self._replace_tensors.keys():\n",
    "                logging.debug('bottomed out at replaced output: {0}'.format(\n",
    "                    node_output))\n",
    "                output, output_mask = self._replace_tensors[node_output]\n",
    "                return output, output_mask\n",
    "            # Next check if the current node has already been rebuilt.\n",
    "            elif node in self._finished_nodes.keys():\n",
    "                logging.debug('reached finished node: {0}'.format(node))\n",
    "                return self._finished_nodes[node]\n",
    "            # Next check if one of the graph_inputs has been reached.\n",
    "            elif node_output in graph_inputs:\n",
    "                logging.debug('bottomed out at a model input')\n",
    "                output_mask = graph_input_masks[graph_inputs.index(node_output)]\n",
    "                return node_output, output_mask\n",
    "            # Otherwise recursively call this method on the inbound nodes.\n",
    "            else:\n",
    "                inbound_nodes = utils.get_node_inbound_nodes(node)\n",
    "                logging.debug('inbound_layers: {0}'.format(\n",
    "                    [node.outbound_layer.name for node in inbound_nodes]))\n",
    "                # Recursively rebuild the model up to `node`s inbound nodes to\n",
    "                # obtain its inputs and input masks\n",
    "                inputs, input_masks = zip(\n",
    "                    *[_rebuild_rec(n) for n in inbound_nodes])\n",
    "\n",
    "                if all(i is None for i in inputs):\n",
    "                    output = None\n",
    "                    output_mask = np.zeros(node.output_shapes[0][1:], dtype=bool)\n",
    "                elif any(i is None for i in inputs):\n",
    "                    if node.outbound_layer.__class__.__name__ != 'Concatenate':\n",
    "                        TypeError('Inputs can only be missing for concatenate layers.')\n",
    "                    # remove Nones from inputs list\n",
    "                    inputs = [i for i in inputs if i is not None]\n",
    "                    new_layer, output_mask = self._apply_delete_mask(node, input_masks)\n",
    "                    if len(inputs) == 1:\n",
    "                        output = utils.single_element(list(inputs))\n",
    "                    else:\n",
    "                        output = new_layer(utils.single_element(list(inputs)))\n",
    "                else:\n",
    "                    new_layer, output_mask = self._apply_delete_mask(node, input_masks)\n",
    "                    output = new_layer(utils.single_element(list(inputs)))\n",
    "\n",
    "                # Record that this node has been rebuild\n",
    "                self._finished_nodes[node] = (output, output_mask)\n",
    "                logging.debug('layer complete: {0}'.format(layer.name))\n",
    "                return output, output_mask\n",
    "\n",
    "        # Call the recursive _rebuild_rec method to rebuild the submodel up to\n",
    "        # each output layer\n",
    "        outputs, output_masks = zip(*[_rebuild_rec(n) for n in output_nodes])\n",
    "        return outputs, output_masks\n",
    "\n",
    "    def _delete_layer(self, node, inputs, input_masks):\n",
    "        \"\"\"Skip adding node.outbound_layer when building the graph.\"\"\"\n",
    "        # Skip the deleted layer by replacing its outputs with it inputs\n",
    "        if len(inputs) >= 2:\n",
    "            raise ValueError('Cannot insert new layer at node with multiple '\n",
    "                             'inbound layers.')\n",
    "        inputs = utils.single_element(inputs)\n",
    "        input_masks = utils.single_element(input_masks)\n",
    "        deleted_layer_output = utils.single_element(node.output_tensors)\n",
    "        self._replace_tensors[deleted_layer_output] = (inputs, input_masks)\n",
    "\n",
    "    def _insert_layer(self, node, inputs, input_masks, new_layer=None):\n",
    "        \"\"\"Insert new_layer into the graph before node.outbound_layer.\"\"\"\n",
    "        # This will not work for nodes with multiple inbound layers\n",
    "        if len(inputs) >= 2:\n",
    "            raise ValueError('Cannot insert new layer at node with multiple '\n",
    "                             'inbound layers.')\n",
    "        # Call the new layer on the inbound layer's output\n",
    "        new_output = new_layer(utils.single_element(inputs))\n",
    "        # Replace the inbound layer's output with the new layer's output\n",
    "        old_output = node.input_tensors[0]\n",
    "        input_masks = utils.single_element(input_masks)\n",
    "        self._replace_tensors[old_output] = (new_output, input_masks)\n",
    "\n",
    "    def _replace_layer(self, node, inputs, input_masks, new_layer=None):\n",
    "        \"\"\"Replace node.outbound_layer with new_layer. Add it to the graph.\"\"\"\n",
    "        # Call the new layer on the rebuild submodel's inputs\n",
    "        new_output = new_layer(utils.single_element(inputs))\n",
    "\n",
    "        # Replace the original layer's output with the new layer's output\n",
    "        replaced_layer_output = utils.single_element(node.output_tensors)\n",
    "        input_masks = utils.single_element(input_masks)\n",
    "        self._replace_tensors[replaced_layer_output] = (new_output, input_masks)\n",
    "\n",
    "    def _delete_channels(self, node, inputs, input_masks, channels=None, layer_name=None):\n",
    "        \"\"\"Delete selected channels of node.outbound_layer. Add it to the graph.\n",
    "        \"\"\"\n",
    "        old_layer = node.outbound_layer\n",
    "        old_layer_output = utils.single_element(node.output_tensors)\n",
    "        # Create a mask to propagate the deleted channels to downstream layers\n",
    "        new_delete_mask = self._make_delete_mask(old_layer, channels)\n",
    "\n",
    "        if len(set(channels)) == getattr(old_layer, utils.get_channels_attr(old_layer)):\n",
    "            self._replace_tensors[old_layer_output] = (None, new_delete_mask)\n",
    "            return None\n",
    "\n",
    "        # If this layer has already been operated on, use the cached copy of\n",
    "        # the new layer. Otherwise, apply the inbound delete mask and\n",
    "        # delete channels to obtain the new layer\n",
    "        if old_layer in self._new_layers_map.keys():\n",
    "            new_layer = self._new_layers_map[old_layer]\n",
    "        else:\n",
    "            temp_layer, new_mask = self._apply_delete_mask(node, input_masks)\n",
    "            # This call is needed to initialise input_shape and output_shape\n",
    "            temp_layer(utils.single_element(inputs))\n",
    "            new_layer = self._delete_channel_weights(temp_layer, channels)\n",
    "            if layer_name:\n",
    "                new_layer.name = layer_name\n",
    "            self._new_layers_map[old_layer] = new_layer\n",
    "        new_output = new_layer(utils.single_element(inputs))\n",
    "        # Replace the original layer's output with the modified layer's output\n",
    "        self._replace_tensors[old_layer_output] = (new_output, new_delete_mask)\n",
    "\n",
    "    def _apply_delete_mask(self, node, inbound_masks):\n",
    "        \"\"\"Apply the inbound delete mask and return the outbound delete mask\n",
    "\n",
    "        When specific channels in a layer or layer instance are deleted, the\n",
    "        mask propagates information about which channels are affected to\n",
    "        downstream layers.\n",
    "        If the layer contains weights, those which were previously connected\n",
    "        to the deleted channels are deleted and outbound masks are set to None\n",
    "        since further downstream layers aren't affected.\n",
    "        If the layer does not contain weights, its output mask is calculated to\n",
    "        reflect any transformations performed by the layer to ensure that\n",
    "        information about the deleted channels is propagated downstream.\n",
    "\n",
    "\n",
    "        Arguments:\n",
    "            node(Node): The node where the delete mask is applied.\n",
    "            inbound_masks: Mask(s) from inbound node(s).\n",
    "\n",
    "        Returns:\n",
    "            new_layer: Pass through `layer` if it has no weights, otherwise a\n",
    "                       new `Layer` object with weights corresponding to the\n",
    "                       inbound mask deleted.\n",
    "            outbound_mask: Mask corresponding to `new_layer`.\n",
    "        \"\"\"\n",
    "\n",
    "        # if delete_mask is None or all values are True, it does not affect\n",
    "        # this layer or any layers above/downstream from it\n",
    "        layer = node.outbound_layer\n",
    "        if all(mask is None for mask in inbound_masks):\n",
    "            new_layer = layer\n",
    "            outbound_mask = None\n",
    "            return new_layer, outbound_mask\n",
    "\n",
    "        # If one or more of the masks are None, replace them with ones.\n",
    "        if any(mask is None for mask in inbound_masks):\n",
    "            inbound_masks = [np.ones(shape[1:], dtype=bool)\n",
    "                             if inbound_masks[i] is None else inbound_masks[i]\n",
    "                             for i, shape in enumerate(node.input_shapes)]\n",
    "\n",
    "        # If the layer is shared and has already been affected by this\n",
    "        # operation, use the cached new layer.\n",
    "        if len(get_inbound_nodes(layer)) > 1 \\\n",
    "                and layer in self._replace_layers_map.keys():\n",
    "            return self._replace_layers_map[layer]\n",
    "\n",
    "        output_shape = utils.single_element(node.output_shapes)\n",
    "        input_shape = utils.single_element(node.input_shapes)\n",
    "        data_format = getattr(layer, 'data_format', 'channels_last')\n",
    "        inbound_masks = utils.single_element(inbound_masks)\n",
    "        # otherwise, delete_mask.shape should be: layer.input_shape[1:]\n",
    "        layer_class = layer.__class__.__name__\n",
    "        if layer_class == 'InputLayer':\n",
    "            raise RuntimeError('This should never get here!')\n",
    "\n",
    "        elif layer_class == 'Dense':\n",
    "            if np.all(inbound_masks):\n",
    "                new_layer = layer\n",
    "            else:\n",
    "                weights = layer.get_weights()\n",
    "                weights[0] = weights[0][np.where(inbound_masks)[0], :]\n",
    "                config = layer.get_config()\n",
    "                config['weights'] = weights\n",
    "                new_layer = type(layer).from_config(config)\n",
    "            outbound_mask = None\n",
    "\n",
    "        elif layer_class == 'Flatten':\n",
    "            outbound_mask = np.reshape(inbound_masks, [-1, ])\n",
    "            new_layer = layer\n",
    "\n",
    "        elif layer_class in ('Conv1D', 'Conv2D', 'Conv3D'):\n",
    "            if np.all(inbound_masks):\n",
    "                new_layer = layer\n",
    "            else:\n",
    "                if data_format == 'channels_first':\n",
    "                    inbound_masks = np.swapaxes(inbound_masks, 0, -1)\n",
    "                # Conv layer: trim down inbound_masks to filter shape\n",
    "                k_size = layer.kernel_size\n",
    "                index = [slice(None, 1, None) for _ in k_size]\n",
    "                inbound_masks = inbound_masks[tuple(index + [slice(None)])]\n",
    "                weights = layer.get_weights()\n",
    "                # Delete unused weights to obtain new_weights\n",
    "                # Each deleted channel was connected to all of the channels\n",
    "                # in layer; therefore, the mask must be repeated for each\n",
    "                # channel.\n",
    "                # `delete_mask`'s size: size(weights[0])\n",
    "                delete_mask = np.tile(inbound_masks[..., np.newaxis], list(k_size) + [1, weights[0].shape[-1]])\n",
    "                new_shape = list(weights[0].shape)\n",
    "                new_shape[-2] = -1  # Weights always have channels_last\n",
    "                weights[0] = np.reshape(weights[0][delete_mask], new_shape)\n",
    "                # Instantiate new layer with new_weights\n",
    "                config = layer.get_config()\n",
    "                config['weights'] = weights\n",
    "                new_layer = type(layer).from_config(config)\n",
    "            outbound_mask = None\n",
    "\n",
    "        elif layer_class in ('Cropping1D', 'Cropping2D', 'Cropping3D',\n",
    "                             'MaxPooling1D', 'MaxPooling2D',\n",
    "                             'MaxPooling3D',\n",
    "                             'AveragePooling1D', 'AveragePooling2D',\n",
    "                             'AveragePooling3D'):\n",
    "            index = [slice(None, x, None) for x in output_shape[1:]]\n",
    "            if data_format == 'channels_first':\n",
    "                index[0] = slice(None)\n",
    "            elif data_format == 'channels_last':\n",
    "                index[-1] = slice(None)\n",
    "            else:\n",
    "                raise ValueError('Invalid data format')\n",
    "            outbound_mask = inbound_masks[tuple(index)]\n",
    "            new_layer = layer\n",
    "\n",
    "        elif layer_class in ('UpSampling1D',\n",
    "                             'UpSampling2D',\n",
    "                             'UpSampling3D',\n",
    "                             'ZeroPadding1D',\n",
    "                             'ZeroPadding2D',\n",
    "                             'ZeroPadding3D'):\n",
    "\n",
    "            # Get slice of mask with all singleton dimensions except\n",
    "            # channels dimension\n",
    "            index = [slice(1)] * (len(input_shape) - 1)\n",
    "            tile_shape = list(output_shape[1:])\n",
    "            if data_format == 'channels_first':\n",
    "                index[0] = slice(None)\n",
    "                tile_shape[0] = 1\n",
    "            elif data_format == 'channels_last':\n",
    "                index[-1] = slice(None)\n",
    "                tile_shape[-1] = 1\n",
    "            else:\n",
    "                raise ValueError('Invalid data format')\n",
    "            channels_vector = inbound_masks[tuple(index)]\n",
    "            # Tile this slice to create the outbound mask\n",
    "            outbound_mask = np.tile(channels_vector, tile_shape)\n",
    "            new_layer = layer\n",
    "\n",
    "        elif layer_class in ('GlobalMaxPooling1D',\n",
    "                             'GlobalMaxPooling2D',\n",
    "                             'GlobalAveragePooling1D',\n",
    "                             'GlobalAveragePooling2D'):\n",
    "            # Get slice of mask with all singleton dimensions except\n",
    "            # channels dimension\n",
    "            index = [0] * (len(input_shape) - 1)\n",
    "            if data_format == 'channels_first':\n",
    "                index[0] = slice(None)\n",
    "            elif data_format == 'channels_last':\n",
    "                index[-1] = slice(None)\n",
    "            else:\n",
    "                raise ValueError('Invalid data format')\n",
    "            channels_vector = inbound_masks[tuple(index)]\n",
    "            # Tile this slice to create the outbound mask\n",
    "            outbound_mask = channels_vector\n",
    "            new_layer = layer\n",
    "\n",
    "        elif layer_class in ('Dropout',\n",
    "                             'Activation',\n",
    "                             'SpatialDropout1D',\n",
    "                             'SpatialDropout2D',\n",
    "                             'SpatialDropout3D',\n",
    "                             'ActivityRegularization',\n",
    "                             'Masking',\n",
    "                             'LeakyReLU',\n",
    "                             'ELU',\n",
    "                             'ReLU',\n",
    "                             'ThresholdedReLU',\n",
    "                             'GaussianNoise',\n",
    "                             'GaussianDropout',\n",
    "                             'AlphaDropout'):\n",
    "            # Pass-through layers\n",
    "            outbound_mask = inbound_masks\n",
    "            new_layer = layer\n",
    "\n",
    "        elif layer_class == 'Reshape':\n",
    "            outbound_mask = np.reshape(inbound_masks, layer.target_shape)\n",
    "            new_layer = layer\n",
    "\n",
    "        elif layer_class == 'Permute':\n",
    "            outbound_mask = np.transpose(inbound_masks,\n",
    "                                         [x-1 for x in layer.dims])\n",
    "            new_layer = layer\n",
    "\n",
    "        elif layer_class == 'RepeatVector':\n",
    "            outbound_mask = np.repeat(\n",
    "                np.expand_dims(inbound_masks, 0),\n",
    "                layer.n,\n",
    "                axis=0)\n",
    "            new_layer = layer\n",
    "\n",
    "        elif layer_class == 'Embedding':\n",
    "            # Embedding will always be the first layer so it doesn't need\n",
    "            # to consider the inbound_delete_mask\n",
    "            if inbound_masks is not None:\n",
    "                raise ValueError('Channels cannot be deleted before Embedding '\n",
    "                                 'layers because they change the number of '\n",
    "                                 'channels.')\n",
    "            outbound_mask = None\n",
    "            new_layer = layer\n",
    "\n",
    "        elif layer_class in ('Add', 'Multiply', 'Average', 'Maximum'):\n",
    "            # The inputs must be the same size\n",
    "            if not utils.all_equal(inbound_masks):\n",
    "                ValueError(\n",
    "                    '{0} layers must have the same size inputs. All '\n",
    "                    'inbound nodes must have the same channels deleted'\n",
    "                    .format(layer_class))\n",
    "            outbound_mask = inbound_masks[1]\n",
    "            new_layer = layer\n",
    "\n",
    "        elif layer_class == 'Concatenate':\n",
    "            axis = layer.axis\n",
    "            if layer.axis < 0:\n",
    "                axis = axis % len(layer.input_shape[0])\n",
    "            # Below: axis=axis-1 because the mask excludes the batch dimension\n",
    "            outbound_mask = np.concatenate(inbound_masks, axis=axis-1)\n",
    "            new_layer = layer\n",
    "\n",
    "        elif layer_class in ('SimpleRNN', 'GRU', 'LSTM'):\n",
    "            if np.all(inbound_masks):\n",
    "                new_layer = layer\n",
    "            else:\n",
    "                weights = layer.get_weights()\n",
    "                weights[0] = weights[0][np.where(inbound_masks[0, :])[0], :]\n",
    "                config = layer.get_config()\n",
    "                config['weights'] = weights\n",
    "                new_layer = type(layer).from_config(config)\n",
    "            outbound_mask = None\n",
    "\n",
    "        elif layer_class == 'BatchNormalization':\n",
    "            outbound_mask = inbound_masks\n",
    "            # Get slice of mask with all singleton dimensions except\n",
    "            # channels dimension\n",
    "            index = [0] * (len(input_shape))\n",
    "            index[layer.axis] = slice(None)\n",
    "            index = index[1:]\n",
    "            # TODO: Maybe use channel indices everywhere instead of masks?\n",
    "            channel_indices = np.where(inbound_masks[tuple(index)] == False)[0]\n",
    "            weights = [np.delete(w, channel_indices, axis=-1)\n",
    "                       for w in layer.get_weights()]\n",
    "            new_layer = BatchNormalization.from_config(\n",
    "                layer.get_config())\n",
    "            new_input_shape = list(input_shape)\n",
    "            new_input_shape[new_layer.axis] -= len(channel_indices)\n",
    "            new_layer.build(new_input_shape)\n",
    "            new_layer.set_weights(weights)\n",
    "        elif layer_class=='DepthwiseConv2D':\n",
    "            if np.all(inbound_masks):\n",
    "                new_layer = layer\n",
    "            else:\n",
    "                config = layer.get_config()\n",
    "                if data_format == 'channels_first':\n",
    "                    inbound_masks = np.swapaxes(inbound_masks, 0, -1)\n",
    "                # Conv layer: trim down inbound_masks to filter shape\n",
    "                k_size = layer.kernel_size\n",
    "                index = [slice(None, 1, None) for _ in k_size]\n",
    "                inbound_masks = inbound_masks[tuple(index + [slice(None)])]\n",
    "                weights = layer.get_weights()\n",
    "                # Delete unused weights to obtain new_weights\n",
    "                # Each deleted channel was connected to all of the channels\n",
    "                # in layer; therefore, the mask must be repeated for each\n",
    "                # channel.\n",
    "                # `delete_mask`'s size: size(weights[0])\n",
    "                print(np.array(inbound_masks).shape)\n",
    "                print(weights[0].shape)\n",
    "                delete_mask = np.tile(inbound_masks[..., np.newaxis], list(k_size) + [1, weights[0].shape[-1]])\n",
    "                new_shape = list(weights[0].shape)\n",
    "                new_shape[-2] = -1  # Weights always have channels_last\n",
    "                print(delete_mask.shape,new_shape)\n",
    "                weights[0] = np.reshape(weights[0][delete_mask], new_shape)\n",
    "                print(weights[0].shape)\n",
    "                # Instantiate new layer with new_weights\n",
    "                config = layer.get_config()\n",
    "                config['weights'] = weights\n",
    "                new_layer = type(layer).from_config(config)\n",
    "            outbound_mask = inbound_masks\n",
    "        else:\n",
    "            # Not implemented:\n",
    "            # - Lambda\n",
    "            # - SeparableConv2D\n",
    "            # - Conv2DTranspose\n",
    "            # - LocallyConnected1D\n",
    "            # - LocallyConnected2D\n",
    "            # - TimeDistributed\n",
    "            # - Bidirectional\n",
    "            # - Dot\n",
    "            # - PReLU\n",
    "            # Warning/error needed for Reshape if channels axis is split\n",
    "            raise ValueError('\"{0}\" layers are currently '\n",
    "                             'unsupported.'.format(layer_class))\n",
    "\n",
    "        if len(get_inbound_nodes(layer)) > 1 and new_layer != layer:\n",
    "            self._replace_layers_map[layer] = (new_layer, outbound_mask)\n",
    "\n",
    "        return new_layer, outbound_mask\n",
    "\n",
    "    def _delete_channel_weights(self, layer, channel_indices):\n",
    "        \"\"\"Delete channels from layer and remove the corresponding weights.\n",
    "\n",
    "        Arguments:\n",
    "            layer: A layer whose channels are to be deleted\n",
    "            channel_indices: The indices of the channels to be deleted.\n",
    "\n",
    "        Returns:\n",
    "            A new layer with the channels and corresponding weights deleted.\n",
    "        \"\"\"\n",
    "        layer_config = layer.get_config()\n",
    "        channels_attr = utils.get_channels_attr(layer)\n",
    "        channel_count = layer_config[channels_attr]\n",
    "        # Check inputs\n",
    "        if any([i + 1 > channel_count for i in channel_indices]):\n",
    "            raise ValueError('Channels_index value(s) out of range. '\n",
    "                             'This layer only has {0} channels.'\n",
    "                             .format(channel_count))\n",
    "        print('Deleting {0}/{1} channels from layer: {2}'.format(\n",
    "            len(channel_indices), channel_count, layer.name))\n",
    "        # numpy.delete ignores negative indices in lists: wrap indices\n",
    "        channel_indices = [i % channel_count for i in channel_indices]\n",
    "\n",
    "        # Reduce layer channel count in config.\n",
    "        layer_config[channels_attr] -= len(channel_indices)\n",
    "\n",
    "        # Delete weights corresponding to deleted channels from config.\n",
    "        # Except for recurrent layers, the weights' channels dimension is last.\n",
    "        # Each recurrent layer type has a different internal weights layout.\n",
    "        if layer.__class__.__name__ == 'SimpleRNN':\n",
    "            weights = [np.delete(w, channel_indices, axis=-1)\n",
    "                       for w in layer.get_weights()]\n",
    "            weights[1] = np.delete(weights[1], channel_indices, axis=0)\n",
    "        elif layer.__class__.__name__ == 'GRU':\n",
    "            # Repeat the channel indices for all internal GRU weights.\n",
    "            channel_indices_gru = [layer.units * m + i for m in range(3)\n",
    "                                   for i in channel_indices]\n",
    "            weights = [np.delete(w, channel_indices_gru, axis=-1)\n",
    "                       for w in layer.get_weights()]\n",
    "            weights[1] = np.delete(weights[1], channel_indices, axis=0)\n",
    "        elif layer.__class__.__name__ == 'LSTM':\n",
    "            # Repeat the channel indices for all interal LSTM weights.\n",
    "            channel_indices_lstm = [layer.units * m + i for m in range(4)\n",
    "                                    for i in channel_indices]\n",
    "            weights = [np.delete(w, channel_indices_lstm, axis=-1)\n",
    "                       for w in layer.get_weights()]\n",
    "            weights[1] = np.delete(weights[1], channel_indices, axis=0)\n",
    "        else:\n",
    "            weights = [np.delete(w, channel_indices, axis=-1)\n",
    "                       for w in layer.get_weights()]\n",
    "        layer_config['weights'] = weights\n",
    "\n",
    "        # Create new layer from the modified configuration and return it.\n",
    "        return type(layer).from_config(layer_config)\n",
    "\n",
    "    def _make_delete_mask(self, layer, channel_indices):\n",
    "        \"\"\"Make the boolean delete mask for layer's output deleting channels.\n",
    "\n",
    "        The mask is used to remove the weights of the downstream layers which\n",
    "        were connected to channels which have been deleted in this layer.\n",
    "        The mask is a boolean array with the same size as the layer output\n",
    "        excluding the first (batch) dimension.\n",
    "        All elements of the mask corresponding to the removed channels are set\n",
    "        to False. Other elements are set to True.\n",
    "\n",
    "        Arguments:\n",
    "            layer: A layer\n",
    "            channel_indices: The indices of the channels to be deleted.\n",
    "\n",
    "        Returns:\n",
    "            A Numpy array of booleans of the same size as the output of layer\n",
    "            excluding the batch dimension.\n",
    "        \"\"\"\n",
    "        data_format = getattr(layer, 'data_format', 'channels_last')\n",
    "        new_delete_mask = np.ones(layer.output_shape[1:], dtype=bool)\n",
    "        if data_format == 'channels_first':\n",
    "            new_delete_mask[channel_indices, ...] = False\n",
    "        elif data_format == 'channels_last':\n",
    "            print(new_delete_mask.shape,np.array(channel_indices).shape,channel_indices)\n",
    "            new_delete_mask[..., channel_indices] = False\n",
    "        else:\n",
    "            ValueError('Invalid data_format property value')\n",
    "        return new_delete_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_apoz(model, layer, x_val, node_indices=None):\n",
    "    if isinstance(layer, str):\n",
    "        layer = model.get_layer(name=layer)\n",
    "\n",
    "    # Check that layer is in the model\n",
    "    if layer not in model.layers:\n",
    "        raise ValueError('layer is not a valid Layer in model.')\n",
    "\n",
    "    layer_node_indices = find_nodes_in_model(model, layer)\n",
    "    print('layer:',layer,layer_node_indices)\n",
    "    # If no nodes are specified, all of the layer's inbound nodes which are\n",
    "    # in model are selected.\n",
    "    if not node_indices:\n",
    "        node_indices = layer_node_indices\n",
    "    # Check for duplicate node indices\n",
    "    elif len(node_indices) != len(set(node_indices)):\n",
    "        raise ValueError('`node_indices` contains duplicate values.')\n",
    "    # Check that all of the selected nodes are in the layer\n",
    "    elif not set(node_indices).issubset(layer_node_indices):\n",
    "        raise ValueError('One or more nodes specified by `layer` and '\n",
    "                         '`node_indices` are not in `model`.')\n",
    "\n",
    "    data_format = getattr(layer, 'data_format', 'channels_last')\n",
    "    # Perform the forward pass and get the activations of the layer.\n",
    "    mean_calculator = MeanCalculator(sum_axis=0)\n",
    "    for node_index in node_indices:\n",
    "        act_layer, act_index = find_activation_layer(layer, node_index)\n",
    "        print('act layer',act_layer, act_index)\n",
    "        # Get activations\n",
    "        if hasattr(x_val, \"__iter__\"):\n",
    "            temp_model = Model(model.inputs,\n",
    "                               act_layer.get_output_at(act_index))\n",
    "            print('before: act output',act_layer.get_output_at(act_index))\n",
    "            a = temp_model.predict(x_val)\n",
    "            #a=temp_model.predict_generator(x_val, x_val.n // x_val.batch_size)\n",
    "            print('after:',layer,a.shape)\n",
    "        else:\n",
    "            get_activations = k.function(\n",
    "                [single_element(model.inputs), k.learning_phase()],\n",
    "                [act_layer.get_output_at(act_index)])\n",
    "            a = get_activations([x_val, 0])[0]\n",
    "            # Ensure that the channels axis is last\n",
    "        if data_format == 'channels_first':\n",
    "            a = np.swapaxes(a, 1, -1)\n",
    "        # Flatten all except channels axis\n",
    "        activations = np.reshape(a, [-1, a.shape[-1]])\n",
    "        zeros = (activations == 0).astype(int)\n",
    "        mean_calculator.add(zeros)\n",
    "\n",
    "    return mean_calculator.calculate()\n",
    "\n",
    "\n",
    "def high_apoz(apoz, method=\"std\", cutoff_std=1, cutoff_absolute=0.99):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        apoz: List of the APoZ values for each channel in the layer.\n",
    "        method: Cutoff method for high APoZ. \"std\", \"absolute\" or \"both\".\n",
    "        cutoff_std: Channels with a higher APoZ than the layer mean plus\n",
    "            `cutoff_std` standard deviations will be identified for pruning.\n",
    "        cutoff_absolute: Channels with a higher APoZ than `cutoff_absolute`\n",
    "            will be identified for pruning.\n",
    "\n",
    "    Returns:\n",
    "        high_apoz_channels: List of indices of channels with high APoZ.\n",
    "\n",
    "    \"\"\"\n",
    "    if method not in {'std', 'absolute', 'both'}:\n",
    "        raise ValueError('Invalid `mode` argument. '\n",
    "                         'Expected one of {\"std\", \"absolute\", \"both\"} '\n",
    "                         'but got', method)\n",
    "    if method == \"std\":\n",
    "        cutoff = apoz.mean() + apoz.std()*cutoff_std\n",
    "    elif method == 'absolute':\n",
    "        cutoff = cutoff_absolute\n",
    "    else:\n",
    "        cutoff = min([cutoff_absolute, apoz.mean() + apoz.std()*cutoff_std])\n",
    "\n",
    "    return np.where(apoz >= cutoff)[0]\n",
    "\n",
    "def prune_model(model, apoz_df, n_channels_delete):\n",
    "    # Identify channels with the highest APoZ in model\n",
    "    sorted_apoz_df = apoz_df.sort_values('apoz', ascending=False)\n",
    "    high_apoz_index = sorted_apoz_df.iloc[0:n_channels_delete, :]\n",
    "\n",
    "    # Create the Surgeon and add a 'delete_channels' job for each layer\n",
    "    # whose channels are to be deleted.\n",
    "    surgeon = Surgeon(model, copy=True)\n",
    "    for name in high_apoz_index.index.unique().values:\n",
    "        channels = list(pd.Series(high_apoz_index.loc[name, 'index'],\n",
    "                                  dtype=np.int64).values)\n",
    "        print('before add_job:',name,channels)\n",
    "        surgeon.add_job('delete_channels', model.get_layer(name),\n",
    "                        channels=channels)\n",
    "    # Delete channels\n",
    "    return surgeon.operate()\n",
    "\n",
    "def is_conv(layer):\n",
    "    return layer.__class__.__name__ == 'Conv2D' and '_project' not in layer.name #and layer.name!='Conv_1'# or layer.__class__.__name__ == 'DepthwiseConv2D'\n",
    "    #return layer.__class__.__name__ == 'Conv2D' and layer.name=='Conv_1'\n",
    "\n",
    "def get_total_channels(model):\n",
    "    start = None\n",
    "    end = None\n",
    "    channels = 0\n",
    "    for layer in model.layers[start:end]:\n",
    "        if is_conv(layer):\n",
    "            channels += layer.filters\n",
    "    return channels\n",
    "\n",
    "def get_images():\n",
    "    base_dir=TRAIN_DATA_DIR\n",
    "    img_dirs = sorted(os.listdir(base_dir))\n",
    "    images=[]\n",
    "    \n",
    "    y=[]\n",
    "    class_ind=0\n",
    "    \n",
    "    for label in img_dirs:\n",
    "        img_dir=os.path.join(base_dir,label)\n",
    "        img_files = sorted(os.listdir(img_dir))\n",
    "        shuffle(img_files)\n",
    "        for f in img_files[:3]:\n",
    "            img=cv2.imread(os.path.join(img_dir,f))\n",
    "            img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "            img=cv2.resize(img,INPUT_SIZE)\n",
    "            images.append(net_model.preprocess_input(img.astype(np.float32)))\n",
    "            y.append(class_ind)\n",
    "        class_ind+=1\n",
    "    images=np.array(images)\n",
    "    y=np.array(y)\n",
    "    return images,y\n",
    "\n",
    "def get_model_apoz(model, val_images):\n",
    "    # Get APoZ\n",
    "    start = None\n",
    "    end = None\n",
    "    apoz = []\n",
    "    index=0\n",
    "    for layer in model.layers[start:end]:\n",
    "        if is_conv(layer):\n",
    "            print(layer.name)\n",
    "            #np.random.shuffle(val_images)\n",
    "            images,_=get_images()\n",
    "            print(images.shape)\n",
    "            apoz.extend([(layer.name, i, value) for (i, value)\n",
    "                         in enumerate(get_apoz(model, layer, images))]) #val_images[:1000]\n",
    "            index+=1\n",
    "            #if index>=2:\n",
    "            #    break\n",
    "\n",
    "    layer_name, index, apoz_value = zip(*apoz)\n",
    "    apoz_df = pd.DataFrame({'layer': layer_name, 'index': index,\n",
    "                            'apoz': apoz_value})\n",
    "    apoz_df = apoz_df.set_index('layer')\n",
    "    return apoz_df\n",
    "\n",
    "def prune_model_random(model, percent_channels_delete):\n",
    "    start = None\n",
    "    end = None\n",
    "    # Create the Surgeon and add a 'delete_channels' job for each layer\n",
    "    # whose channels are to be deleted.\n",
    "    surgeon = Surgeon(model, copy=True)\n",
    "    for layer in model.layers[start:end]:\n",
    "        if is_conv(layer):\n",
    "            print(layer.name)\n",
    "            num_total_channels=layer.output_shape[-1]\n",
    "            total_channels = list(range(num_total_channels))\n",
    "            shuffle(total_channels)\n",
    "            num_removed_channels=int(num_total_channels*percent_channels_delete/100)//16*16\n",
    "            if num_removed_channels>0:\n",
    "                channels=total_channels[:num_removed_channels]\n",
    "                print('before add_job:',layer.name,channels,len(channels),num_total_channels)\n",
    "                surgeon.add_job('delete_channels', layer,channels=channels)\n",
    "            \n",
    "    # Delete channels\n",
    "    return surgeon.operate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_channels_apoz_importance(model, layer, x_val, node_indices=None):\n",
    "    if isinstance(layer, str):\n",
    "        layer = model.get_layer(name=layer)\n",
    "\n",
    "    # Check that layer is in the model\n",
    "    if layer not in model.layers:\n",
    "        raise ValueError('layer is not a valid Layer in model.')\n",
    "\n",
    "    layer_node_indices = find_nodes_in_model(model, layer)\n",
    "    print('layer:',layer,layer_node_indices)\n",
    "    # If no nodes are specified, all of the layer's inbound nodes which are\n",
    "    # in model are selected.\n",
    "    if not node_indices:\n",
    "        node_indices = layer_node_indices\n",
    "    # Check for duplicate node indices\n",
    "    elif len(node_indices) != len(set(node_indices)):\n",
    "        raise ValueError('`node_indices` contains duplicate values.')\n",
    "    # Check that all of the selected nodes are in the layer\n",
    "    elif not set(node_indices).issubset(layer_node_indices):\n",
    "        raise ValueError('One or more nodes specified by `layer` and '\n",
    "                         '`node_indices` are not in `model`.')\n",
    "\n",
    "    data_format = getattr(layer, 'data_format', 'channels_last')\n",
    "    # Perform the forward pass and get the activations of the layer.\n",
    "    mean_calculator = MeanCalculator(sum_axis=0)\n",
    "    for node_index in node_indices:\n",
    "        act_layer, act_index = find_activation_layer(layer, node_index)\n",
    "        print('act layer',act_layer, act_index)\n",
    "        # Get activations\n",
    "        if hasattr(x_val, \"__iter__\"):\n",
    "            temp_model = Model(model.inputs,\n",
    "                               act_layer.get_output_at(act_index))\n",
    "            print('before: act output',act_layer.get_output_at(act_index))\n",
    "            a = temp_model.predict(x_val)\n",
    "            #a=temp_model.predict_generator(x_val, x_val.n // x_val.batch_size)\n",
    "            print('after:',layer,a.shape)\n",
    "        else:\n",
    "            get_activations = k.function(\n",
    "                [single_element(model.inputs), k.learning_phase()],\n",
    "                [act_layer.get_output_at(act_index)])\n",
    "            a = get_activations([x_val, 0])[0]\n",
    "            # Ensure that the channels axis is last\n",
    "        if data_format == 'channels_first':\n",
    "            a = np.swapaxes(a, 1, -1)\n",
    "        # Flatten all except channels axis\n",
    "        activations = np.reshape(a, [-1, a.shape[-1]])\n",
    "        zeros = (activations == 0).astype(int)\n",
    "        mean_calculator.add(zeros)\n",
    "\n",
    "    return mean_calculator.calculate()\n",
    "\n",
    "def get_channels_gradients(model, layer, x_val, y , node_indices=None):\n",
    "    if isinstance(layer, str):\n",
    "        layer = model.get_layer(name=layer)\n",
    "\n",
    "    # Check that layer is in the model\n",
    "    if layer not in model.layers:\n",
    "        raise ValueError('layer is not a valid Layer in model.')\n",
    "\n",
    "    layer_node_indices = utils.find_nodes_in_model(model, layer)\n",
    "    print('layer:',layer,layer_node_indices)\n",
    "    # If no nodes are specified, all of the layer's inbound nodes which are\n",
    "    # in model are selected.\n",
    "    if not node_indices:\n",
    "        node_indices = layer_node_indices\n",
    "    # Check for duplicate node indices\n",
    "    elif len(node_indices) != len(set(node_indices)):\n",
    "        raise ValueError('`node_indices` contains duplicate values.')\n",
    "    # Check that all of the selected nodes are in the layer\n",
    "    elif not set(node_indices).issubset(layer_node_indices):\n",
    "        raise ValueError('One or more nodes specified by `layer` and '\n",
    "                         '`node_indices` are not in `model`.')\n",
    "\n",
    "    data_format = getattr(layer, 'data_format', 'channels_last')\n",
    "    # Perform the forward pass and get the activations of the layer.\n",
    "    importances=[]\n",
    "    print('layer:',layer,layer_node_indices,node_indices)\n",
    "    if len(node_indices)>1:\n",
    "        print('ERROR!')\n",
    "    # Get activations\n",
    "    if hasattr(x_val, \"__iter__\"):\n",
    "        grads = K.gradients(model.total_loss, layer.output)[0]\n",
    "        input_tensors = [model.inputs[0], # input data\n",
    "                 model.sample_weights[0], # how much to weight each sample by\n",
    "                 model.targets[0], # labels\n",
    "                 K.learning_phase(), # train or test mode\n",
    "        ]\n",
    "        mul_a_grads_tensor=layer.output*grads\n",
    "        if K.image_data_format() == 'channels_first':\n",
    "            x = K.permute_dimensions(mul_a_grads_tensor, (1, 0, 2, 3))\n",
    "        else:\n",
    "            x = K.permute_dimensions(mul_a_grads_tensor, (3, 0, 1, 2))\n",
    "        \n",
    "        x_shape=K.int_shape(x)\n",
    "        #print(x_shape)\n",
    "        x=K.reshape(x,(x_shape[0],-1,x_shape[2]*x_shape[3]))\n",
    "        x=K.sum(x,axis=2)\n",
    "        x=K.abs(x)\n",
    "        x=K.sum(x,axis=1)\n",
    "        func=K.function(input_tensors, [x])\n",
    "        print('before: act output',layer.output)\n",
    "        delta=64\n",
    "        importances=None\n",
    "        for i in range(0,x_val.shape[0],delta):\n",
    "            x=x_val[i:i+delta]\n",
    "            q_part= func([x,np.ones(x.shape[0]),y[i:i+delta],0])[0]\n",
    "            \n",
    "            if importances is None:\n",
    "                importances=q_part.copy()\n",
    "            else:\n",
    "                importances+=q_part\n",
    "        print('after:',importances.shape,layer.output.shape,data_format)\n",
    "    return importances\n",
    "\n",
    "def prune_model_by_layer(model, percent_channels_delete):\n",
    "    start = None\n",
    "    end = None\n",
    "    model.compile(loss='sparse_categorical_crossentropy', optimizer=SGD(lr=0.001), metrics=['accuracy'])\n",
    "    # Create the Surgeon and add a 'delete_channels' job for each layer\n",
    "    # whose channels are to be deleted.\n",
    "    surgeon = Surgeon(model, copy=True)\n",
    "    for layer in model.layers[start:end]:\n",
    "        if is_conv(layer):\n",
    "            print(layer.name)\n",
    "            \n",
    "            \n",
    "            num_total_channels=layer.output_shape[-1]\n",
    "            num_removed_channels=int(num_total_channels*percent_channels_delete/100)//8*8\n",
    "            if num_removed_channels>0:\n",
    "                images,y=get_images()\n",
    "                importances=get_channels_gradients(model, layer, images,y)\n",
    "                total_channels_sorted=np.argsort(importances)\n",
    "                print(importances)\n",
    "                \n",
    "                channels=total_channels_sorted[:num_removed_channels]\n",
    "                print('before add_job:',layer.name,channels,len(channels),num_total_channels)\n",
    "                surgeon.add_job('delete_channels', layer,channels=channels)\n",
    "            \n",
    "    # Delete channels\n",
    "    return surgeon.operate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "percent_pruned = 0\n",
    "percent_pruning=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py:270: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    }
   ],
   "source": [
    "reduced_model = load_model('places_mobilenet2_alpha=1.4_augm_ft_sgd_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, 225, 225, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 112, 112, 32) 864         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 113, 113, 96) 0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 57, 57, 144)  0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 29, 29, 192)  0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 15, 15, 576)  0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1280)         0           out_relu[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 431)          552111      global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 2,810,095\n",
      "Trainable params: 2,775,983\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 112, 112, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 112, 112, 32) 128         Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 112, 112, 32) 0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 112, 112, 32) 288         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 112, 112, 32) 128         expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 112, 112, 32) 0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 112, 112, 16) 512         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 112, 112, 96) 1536        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 112, 112, 96) 384         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 112, 112, 96) 0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 56, 56, 24)   2304        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 56, 56, 144)  3456        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 56, 56, 144)  1296        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 56, 56, 144)  576         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 56, 56, 144)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 56, 56, 24)   3456        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 56, 56, 144)  3456        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 56, 56, 144)  576         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 56, 56, 144)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 28, 28, 144)  1296        block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 28, 28, 144)  576         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 28, 28, 144)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 28, 28, 32)   4608        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 28, 28, 192)  6144        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 28, 28, 32)   6144        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 28, 28, 192)  6144        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 28, 28, 192)  1728        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 28, 28, 192)  768         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 28, 28, 192)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 28, 28, 32)   6144        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 28, 28, 192)  6144        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 28, 28, 192)  768         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 28, 28, 192)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 14, 14, 192)  1728        block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 14, 14, 192)  768         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 14, 14, 192)  0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 14, 14, 64)   12288       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 14, 14, 384)  24576       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 14, 14, 64)   24576       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 14, 14, 384)  24576       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 14, 14, 64)   24576       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 14, 14, 384)  24576       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 14, 14, 384)  1536        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 14, 14, 384)  0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 14, 14, 384)  3456        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 14, 14, 384)  1536        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 14, 14, 384)  0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 14, 14, 64)   24576       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 14, 14, 384)  24576       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 14, 14, 384)  1536        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 14, 14, 384)  0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 14, 14, 384)  3456        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 14, 14, 384)  1536        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 14, 14, 384)  0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 14, 14, 96)   36864       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 14, 14, 576)  55296       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 14, 14, 96)   55296       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 14, 14, 576)  55296       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 14, 14, 576)  5184        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 14, 14, 576)  2304        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 14, 14, 576)  0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 14, 14, 96)   55296       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 14, 14, 576)  55296       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 14, 14, 576)  2304        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 14, 14, 576)  0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 7, 7, 160)    92160       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 7, 7, 960)    153600      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 7, 7, 160)    153600      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 7, 7, 960)    153600      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 7, 7, 160)    153600      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 7, 7, 960)    153600      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 7, 7, 960)    3840        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 7, 7, 960)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 7, 7, 960)    8640        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 7, 7, 960)    3840        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 7, 7, 960)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 7, 7, 320)    307200      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 7, 7, 1280)   409600      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 7, 7, 1280)   5120        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 7, 7, 1280)   0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 1280)         0           out_relu[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 431)          552111      global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 2,810,095\n",
      "Trainable params: 2,775,983\n",
      "Non-trainable params: 34,112\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def remove_zeropadds(model):\n",
    "    print(model.layers.__class__)\n",
    "    zero_layers=[]\n",
    "    for layer in model.layers:\n",
    "        if layer.__class__.__name__ == 'ZeroPadding2D':\n",
    "            zero_layers.append(layer)\n",
    "        elif layer.__class__.__name__ in ['Conv2D','DepthwiseConv2D']:\n",
    "            layer.padding='same'\n",
    "    print(zero_layers)\n",
    "    for zero_layer in zero_layers:\n",
    "        model.layers.remove(zero_layer)\n",
    "\n",
    "def remove_zeropadds1(model):\n",
    "    for layer in model.layers:\n",
    "        #layer.dtype='float16'\n",
    "        if layer.__class__.__name__ in ['Conv2D','DepthwiseConv2D']:\n",
    "            layer.padding='same'  \n",
    "    surgeon = Surgeon(model, copy=True)\n",
    "    for layer in model.layers:\n",
    "        if layer.__class__.__name__ == 'ZeroPadding2D':\n",
    "            surgeon.add_job('delete_layer', layer)\n",
    "    new_model=surgeon.operate()\n",
    "    \n",
    "    return new_model\n",
    "\n",
    "if True:\n",
    "    model_name=checkpoint_name\n",
    "    #model_name='mobilenet_pruning_30percent'\n",
    "    #reduced_model = load_model(model_name + '.h5')\n",
    "    #reduced_model.load_weights(model_name+'_ft.h5')\n",
    "    \n",
    "    reduced_model=model\n",
    "    reduced_model.summary()\n",
    "    new_model=remove_zeropadds1(reduced_model)\n",
    "    reduced_model=new_model\n",
    "    reduced_model.summary()\n",
    "    #save_model(reduced_model,'places_mobilenet2_alpha=1.0_augm_ft_sgd_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv_1\n",
      "(1293, 224, 224, 3)\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f151a91d9b0> [0]\n",
      "act layer <keras.layers.advanced_activations.ReLU object at 0x7f151a91d470> 0\n",
      "before: act output Tensor(\"out_relu_1/Minimum:0\", shape=(?, 7, 7, 477), dtype=float32)\n",
      "after: <keras.layers.convolutional.Conv2D object at 0x7f151a91d9b0> (1293, 7, 7, 477)\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "#del apoz_df\n",
    "#del reduced_model_new\n",
    "gc.collect()\n",
    "\n",
    "checkpoint_name='mobilenet_pruning_25percent'\n",
    "#reduced_model = load_model(checkpoint_name + '.h5')\n",
    "#reduced_model.load_weights(checkpoint_name+'_ft.h5')\n",
    "\n",
    "#reduced_model.compile(optimizer=SGD(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "apoz_df = get_model_apoz(reduced_model, val_images) #val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_pad (ZeroPadding2D)       (None, 225, 225, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 112, 112, 23) 621         Conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 112, 112, 23) 92          Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 112, 112, 23) 0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 112, 112, 23) 207         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 112, 112, 23) 92          expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 112, 112, 23) 0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 112, 112, 24) 552         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 112, 112, 24) 96          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 112, 112, 124 2976        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 112, 112, 124 496         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 112, 112, 124 0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_pad (ZeroPadding2D)     (None, 113, 113, 124 0           block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 56, 56, 124)  1116        block_1_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 56, 56, 124)  496         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 56, 56, 124)  0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 56, 56, 32)   3968        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 56, 56, 32)   128         block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 56, 56, 189)  6048        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 56, 56, 189)  756         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 56, 56, 189)  0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 56, 56, 189)  1701        block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 56, 56, 189)  756         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 56, 56, 189)  0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 56, 56, 32)   6048        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 56, 56, 32)   128         block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 56, 56, 32)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 56, 56, 174)  5568        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 56, 56, 174)  696         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 56, 56, 174)  0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_pad (ZeroPadding2D)     (None, 57, 57, 174)  0           block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 28, 28, 174)  1566        block_3_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 28, 28, 174)  696         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 28, 28, 174)  0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 28, 28, 48)   8352        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 28, 28, 48)   192         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 28, 28, 274)  13152       block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 28, 28, 274)  1096        block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 28, 28, 274)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 28, 28, 274)  2466        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 28, 28, 274)  1096        block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 28, 28, 274)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 28, 28, 48)   13152       block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 28, 28, 48)   192         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 28, 28, 48)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 28, 28, 279)  13392       block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 28, 28, 279)  1116        block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 28, 28, 279)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 28, 28, 279)  2511        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 28, 28, 279)  1116        block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 28, 28, 279)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 28, 28, 48)   13392       block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 28, 28, 48)   192         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 28, 28, 48)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 28, 28, 263)  12624       block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 28, 28, 263)  1052        block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 28, 28, 263)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_pad (ZeroPadding2D)     (None, 29, 29, 263)  0           block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 14, 14, 263)  2367        block_6_pad[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 14, 14, 263)  1052        block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 14, 14, 263)  0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 14, 14, 88)   23144       block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 14, 14, 88)   352         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 14, 14, 507)  44616       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 14, 14, 507)  2028        block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 14, 14, 507)  0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 14, 14, 507)  4563        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 14, 14, 507)  2028        block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 14, 14, 507)  0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 14, 14, 88)   44616       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 14, 14, 88)   352         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 14, 14, 88)   0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 14, 14, 507)  44616       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 14, 14, 507)  2028        block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 14, 14, 507)  0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 14, 14, 507)  4563        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 14, 14, 507)  2028        block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 14, 14, 507)  0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 14, 14, 88)   44616       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 14, 14, 88)   352         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 14, 14, 88)   0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 14, 14, 486)  42768       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 14, 14, 486)  1944        block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 14, 14, 486)  0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 14, 14, 486)  4374        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 14, 14, 486)  1944        block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 14, 14, 486)  0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 14, 14, 88)   42768       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 14, 14, 88)   352         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 14, 14, 88)   0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 14, 14, 524)  46112       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 14, 14, 524)  2096        block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 14, 14, 524)  0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 14, 14, 524)  4716        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 14, 14, 524)  2096        block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 14, 14, 524)  0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 14, 14, 136)  71264       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 14, 14, 136)  544         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 14, 14, 706)  96016       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 14, 14, 706)  2824        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 14, 14, 706)  0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 14, 14, 706)  6354        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 14, 14, 706)  2824        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 14, 14, 706)  0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 14, 14, 136)  96016       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 14, 14, 136)  544         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 14, 14, 136)  0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 14, 14, 654)  88944       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 14, 14, 654)  2616        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 14, 14, 654)  0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 14, 14, 654)  5886        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 14, 14, 654)  2616        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 14, 14, 654)  0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 14, 14, 136)  88944       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 14, 14, 136)  544         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 14, 14, 136)  0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 14, 14, 419)  56984       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 14, 14, 419)  1676        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 14, 14, 419)  0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_pad (ZeroPadding2D)    (None, 15, 15, 419)  0           block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 7, 7, 419)    3771        block_13_pad[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 7, 7, 419)    1676        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 7, 7, 419)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 7, 7, 224)    93856       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 7, 7, 224)    896         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 7, 7, 1243)   278432      block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 7, 7, 1243)   4972        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 7, 7, 1243)   0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 7, 7, 1243)   11187       block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 7, 7, 1243)   4972        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 7, 7, 1243)   0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 7, 7, 224)    278432      block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 7, 7, 224)    896         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 7, 7, 224)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 7, 7, 1129)   252896      block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 7, 7, 1129)   4516        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 7, 7, 1129)   0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 7, 7, 1129)   10161       block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 7, 7, 1129)   4516        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 7, 7, 1129)   0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 7, 7, 224)    252896      block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 7, 7, 224)    896         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 7, 7, 224)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 7, 7, 795)    178080      block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 7, 7, 795)    3180        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 7, 7, 795)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 7, 7, 795)    7155        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 7, 7, 795)    3180        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 7, 7, 795)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 7, 7, 448)    356160      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 7, 7, 448)    1792        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 7, 7, 477)    213696      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 7, 7, 477)    1908        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 7, 7, 477)    0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 477)          0           out_relu[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 431)          206018      global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 3,193,123\n",
      "Trainable params: 3,154,761\n",
      "Non-trainable params: 38,362\n",
      "__________________________________________________________________________________________________\n",
      "95\n",
      "pruning up to  30 % of the original model weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "before add_job: Conv_1 [219, 97, 462, 200, 117, 60, 183, 319, 196, 317, 354, 109, 49, 181, 406, 253, 348, 455, 191, 211, 195, 413, 160, 177, 328, 338, 173, 362, 365, 351, 24, 255, 150, 50, 165, 136, 20, 314, 436, 446, 38, 230, 236, 304, 251, 206, 44, 15, 437, 1, 176, 284, 128, 121, 107, 278, 289, 21, 144, 368, 208, 212, 349, 392, 444, 105, 83, 394, 416, 386, 2, 41, 71, 19, 8, 224, 36, 11, 182, 357, 237, 68, 372, 216, 339, 207, 27, 76, 171, 138, 378, 316, 227, 53, 201]\n",
      "(7, 7, 477) (95,) [219, 97, 462, 200, 117, 60, 183, 319, 196, 317, 354, 109, 49, 181, 406, 253, 348, 455, 191, 211, 195, 413, 160, 177, 328, 338, 173, 362, 365, 351, 24, 255, 150, 50, 165, 136, 20, 314, 436, 446, 38, 230, 236, 304, 251, 206, 44, 15, 437, 1, 176, 284, 128, 121, 107, 278, 289, 21, 144, 368, 208, 212, 349, 392, 444, 105, 83, 394, 416, 386, 2, 41, 71, 19, 8, 224, 36, 11, 182, 357, 237, 68, 372, 216, 339, 207, 27, 76, 171, 138, 378, 316, 227, 53, 201]\n",
      "Deleting 95/477 channels from layer: Conv_1\n"
     ]
    }
   ],
   "source": [
    "percent_pruning=20 #5\n",
    "total_channels = get_total_channels(reduced_model)\n",
    "n_channels_delete = int(math.floor(percent_pruning / 100 * total_channels))\n",
    "reduced_model.summary()\n",
    "print(n_channels_delete)\n",
    "percent_pruned += percent_pruning\n",
    "print('pruning up to ', str(percent_pruned),'% of the original model weights')\n",
    "#print(apoz_df)\n",
    "reduced_model_new = prune_model(reduced_model, apoz_df, n_channels_delete)\n",
    "\n",
    "checkpoint_name = ('mobilenet_pruning_' + str(percent_pruned) + 'percent')\n",
    "reduced_model_new.compile(optimizer=SGD(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy',top_k_categorical_accuracy])\n",
    "reduced_model_new.save(checkpoint_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pruning up to  20 % of the original model weights\n",
      "Conv1\n",
      "block_1_expand\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e289a20> [0]\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e289a20> [0] [0]\n",
      "before: act output Tensor(\"block_1_expand/convolution:0\", shape=(?, 112, 112, 72), dtype=float32)\n",
      "after: (72,) (?, 112, 112, 72) channels_last\n",
      "[1.8242675 4.1574874 8.027346  1.3498267 7.7273474 2.259204  1.9351901\n",
      " 1.9289862 3.4736958 5.690966  2.2244048 3.5733032 5.442465  2.1517525\n",
      " 1.8455912 6.0661645 2.0661376 1.6192698 8.254786  5.762231  1.4316514\n",
      " 1.9986949 2.4795985 5.8053813 2.0882683 3.082886  2.9629116 1.6696634\n",
      " 2.2322543 2.789154  2.8192225 2.881893  3.8183737 1.3873432 2.549829\n",
      " 1.9715102 3.6117046 5.1251693 2.2167072 6.971096  7.259971  1.4211854\n",
      " 8.1924    5.825683  2.2879112 6.6664658 1.9860713 3.5774887 1.9752846\n",
      " 2.070279  1.3560817 1.6130283 1.7242495 6.478664  3.3665688 3.5772595\n",
      " 6.559766  1.7514586 2.400577  2.0651143 6.9653716 1.8445395 1.4401094\n",
      " 3.670204  4.3712907 1.4427029 8.399582  1.3456311 3.7493954 5.6273675\n",
      " 2.7049346 2.1881964]\n",
      "before add_job: block_1_expand [67  3 50 33 41 20 62 65] 8 72\n",
      "block_2_expand\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e29d358> [0]\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e29d358> [0] [0]\n",
      "before: act output Tensor(\"block_2_expand/convolution:0\", shape=(?, 56, 56, 112), dtype=float32)\n",
      "after: (112,) (?, 56, 56, 112) channels_last\n",
      "[2.4052372  1.2259645  5.978803   1.0151689  2.2597172  5.5627127\n",
      " 1.5567315  1.3960049  1.4362737  2.68975    1.6826167  1.1845505\n",
      " 1.5814432  1.7813616  1.832616   1.5159748  1.7766061  2.1931393\n",
      " 0.99479985 1.5281484  1.1565838  1.5238616  2.6245885  1.2925444\n",
      " 2.0033839  1.535965   1.3146183  2.3911974  1.4614004  1.6294805\n",
      " 1.4654864  1.8162276  1.3327571  1.9308504  2.2015874  1.1300958\n",
      " 1.0252765  4.0310225  3.069054   2.2166753  1.5321716  1.0531738\n",
      " 1.3517132  1.547832   1.1911283  1.43071    2.5581834  1.1699922\n",
      " 0.9135583  1.1694765  1.3737442  6.16273    1.1304718  1.1866397\n",
      " 0.98465216 1.112561   2.5743806  3.1318805  2.3933516  1.3345556\n",
      " 2.1730647  1.6437342  1.3207396  2.643806   1.8459338  1.2283514\n",
      " 1.8951627  3.6482413  2.2975814  1.2242767  1.7978172  1.1571426\n",
      " 1.1790015  2.2552114  1.4366007  1.871278   1.0723193  1.048718\n",
      " 1.8550982  2.0976536  1.4086684  2.5878603  1.1810617  3.2576547\n",
      " 1.35       1.388859   1.177999   1.3064892  1.1585356  1.4621117\n",
      " 0.8846849  2.0232506  1.6930999  0.67160565 1.1829128  1.5339532\n",
      " 1.7009792  1.7734404  2.6346314  1.4403557  1.6020144  4.1570244\n",
      " 1.2812173  2.2119973  1.5688529  1.7095305  1.668955   1.5386333\n",
      " 1.6840907  0.9698374  2.79981    2.7044559 ]\n",
      "before add_job: block_2_expand [ 93  90  48 109  54  18   3  36  77  41  76  55  35  52  20  71] 16 112\n",
      "block_3_expand\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e29dc88> [0]\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e29dc88> [0] [0]\n",
      "before: act output Tensor(\"block_3_expand/convolution:0\", shape=(?, 56, 56, 112), dtype=float32)\n",
      "after: (112,) (?, 56, 56, 112) channels_last\n",
      "[6.0726447  0.87614906 5.9388227  2.5437553  6.324257   3.5821412\n",
      " 4.798566   1.0504307  1.9503486  1.5272977  4.2900276  3.5269384\n",
      " 3.72494    3.6406054  3.4289262  2.8278344  0.80400485 2.9783509\n",
      " 4.242671   5.5051923  4.209782   1.3088269  4.0423346  1.1769657\n",
      " 4.863132   6.066695   3.5536578  1.5517483  1.0642639  2.925392\n",
      " 1.2707418  3.3182545  2.165562   4.332192   4.1738377  2.4397006\n",
      " 3.7468271  7.574727   2.7036436  2.3859186  3.1384733  3.7043526\n",
      " 1.1699175  5.4058676  1.4317603  3.0353389  2.18175    2.192811\n",
      " 0.98572713 1.718255   4.9454823  2.0351322  1.9021084  3.3452752\n",
      " 3.7976162  7.023449   4.28929    1.1770446  1.6628573  3.1789207\n",
      " 2.1810873  2.159559   4.303605   3.727285   3.1737173  3.60555\n",
      " 3.9546854  3.4764533  1.5393757  1.10714    4.1064234  2.0565135\n",
      " 4.8417387  1.5719224  5.1805434  0.87874836 9.088147   0.9216727\n",
      " 2.9182572  5.715156   6.0500426  2.5497048  1.1055956  3.826071\n",
      " 4.0867043  4.58436    1.5472778  2.7287078  4.213289   2.1369214\n",
      " 6.5765824  1.0169199  3.5754337  1.0728433  4.8045387  1.275214\n",
      " 2.4985466  1.4793081  1.2290256  2.4195278  2.205972   2.1000478\n",
      " 1.0652897  3.7274578  1.6860601  1.0785451  8.671476   5.6654987\n",
      " 4.815582   4.0992417  4.500223   3.6167433 ]\n",
      "before add_job: block_3_expand [ 16   1  75  77  48  91   7  28 102  93 105  82  69  42  23  57] 16 112\n",
      "block_4_expand\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e2925c0> [0]\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e2925c0> [0] [0]\n",
      "before: act output Tensor(\"block_4_expand/convolution:0\", shape=(?, 28, 28, 144), dtype=float32)\n",
      "after: (144,) (?, 28, 28, 144) channels_last\n",
      "[0.9212375  0.7492874  2.358634   1.2578129  0.7887439  2.160737\n",
      " 1.1742753  0.8510177  0.7244761  1.4964368  0.78801966 2.035464\n",
      " 0.6154421  1.1270728  0.82419026 0.85272026 0.7302158  0.7430941\n",
      " 1.2384474  0.7738781  0.9142897  0.91706514 1.4137213  1.2012147\n",
      " 0.9948596  1.6774822  0.6411458  0.811105   0.66777015 0.90752554\n",
      " 1.5260981  0.9895697  1.7129695  0.7182643  0.9966024  0.72130466\n",
      " 0.6594791  0.94505537 0.65287954 0.7641064  0.7010604  1.2154143\n",
      " 1.047246   1.0903587  1.4777824  0.7398262  1.1994188  1.0098845\n",
      " 0.8790958  0.68211603 0.76641643 1.2707486  0.9175277  0.9587057\n",
      " 1.1772487  0.80535704 1.233311   1.2394478  0.82908785 0.8192197\n",
      " 0.76701635 1.3885713  1.2850894  0.93941414 0.9020584  0.743209\n",
      " 0.65227324 1.6344725  0.5616999  0.96964806 0.8309774  1.8308961\n",
      " 1.0963757  1.0371939  0.7322254  0.55386317 1.2822387  1.069708\n",
      " 0.8572981  0.7249903  0.59673077 1.6784309  1.0189102  0.7385877\n",
      " 0.73638284 0.84806526 0.7464328  0.909856   0.71536094 0.6518759\n",
      " 0.7936174  1.0128689  1.0419155  0.69338936 0.66378975 0.76174855\n",
      " 0.8188921  1.9516385  0.55708075 0.92248815 0.5965547  0.6884988\n",
      " 0.6680239  0.8969674  0.91091686 1.0716324  0.95054185 1.0197637\n",
      " 1.1057056  0.63303715 1.1580813  1.2806451  1.1741263  0.7535488\n",
      " 1.0559002  0.61470187 0.860601   1.2195663  0.9164525  0.87472874\n",
      " 1.0723327  0.98730195 1.313515   0.9456133  1.367893   1.1487916\n",
      " 0.59945595 0.88618034 0.55032057 0.71666145 1.0685954  0.7148233\n",
      " 0.84469295 1.2424558  0.88260406 1.3009589  0.88969415 0.6478034\n",
      " 0.9744354  1.321649   0.76394624 2.5005617  1.1321579  1.1555357 ]\n",
      "before add_job: block_4_expand [128  75  98  68 100  80 126 115  12 109  26 137  89  66  38  36  94  28\n",
      " 102  49 101  93  40 131] 24 144\n",
      "block_5_expand\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e292ef0> [0]\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e292ef0> [0] [0]\n",
      "before: act output Tensor(\"block_5_expand/convolution:0\", shape=(?, 28, 28, 144), dtype=float32)\n",
      "after: (144,) (?, 28, 28, 144) channels_last\n",
      "[1.1060516  0.6373704  1.1478735  0.67785704 1.2866294  0.64767355\n",
      " 1.3462151  1.0489529  1.3037393  1.4506055  1.2386867  0.8189303\n",
      " 1.4958957  0.83392274 2.2398324  0.8624441  1.260807   1.1535944\n",
      " 1.09934    0.8158205  1.7441314  0.7600617  1.319264   0.7136046\n",
      " 1.5364102  0.7913483  0.6294346  1.8851447  0.8737584  0.8191015\n",
      " 1.219628   0.7619225  0.8412374  0.78688395 1.6793982  0.7870203\n",
      " 0.88227516 1.0966598  0.71281874 0.8754796  0.7147161  0.66010416\n",
      " 1.4461989  1.1909194  0.8130171  0.6705009  1.2873638  0.9387704\n",
      " 1.1262884  0.67209506 1.1597239  1.3073957  0.78389573 1.1711481\n",
      " 2.7025733  0.8704958  0.866117   0.98341316 1.2273314  1.4816194\n",
      " 0.86907977 0.979437   0.6921114  0.82243645 0.8180542  1.0317428\n",
      " 2.8673544  1.107662   1.2611847  0.90303284 0.8503243  1.0101247\n",
      " 1.100769   0.75707924 1.1742467  1.3234385  0.80246866 0.95626205\n",
      " 1.0302732  0.997921   0.9190843  0.9084464  1.2512794  1.2085304\n",
      " 1.2838773  0.7209952  1.2966237  0.7185939  0.8391571  0.9462343\n",
      " 0.8785382  1.5893722  0.80466175 1.0227798  0.8102274  1.3139791\n",
      " 0.841367   1.4607048  0.7972101  0.7111392  1.3714849  2.2245984\n",
      " 0.91321784 0.85713017 0.8648054  1.0664848  0.91261476 0.95964545\n",
      " 0.9678201  0.86132616 0.71233636 0.791985   2.4259224  0.75112087\n",
      " 0.74117285 1.4599237  1.0533292  0.9898961  0.9760699  1.6225331\n",
      " 1.0264119  1.019461   1.2116652  1.419406   2.374228   0.856976\n",
      " 2.414792   0.83317125 1.2172381  1.0736184  0.77501065 2.1391141\n",
      " 0.7416605  0.8793288  1.0463834  1.5868139  0.69419694 0.6880372\n",
      " 0.831776   0.92233413 1.3380336  0.7213968  1.244172   0.6696459 ]\n",
      "before add_job: block_5_expand [ 26   1   5  41 143  45  49   3 137  62 136  99 110  38  23  40  87  85\n",
      " 141 114 132 113  73  21] 24 144\n",
      "block_6_expand\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e2ac860> [0]\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e2ac860> [0] [0]\n",
      "before: act output Tensor(\"block_6_expand/convolution:0\", shape=(?, 28, 28, 144), dtype=float32)\n",
      "after: (144,) (?, 28, 28, 144) channels_last\n",
      "[2.683003   2.34546    1.4757521  2.485758   1.7121197  3.4564416\n",
      " 2.4005504  1.9605358  1.0109615  3.6496158  1.0726118  2.4901788\n",
      " 2.386322   1.7060496  5.351925   2.8377166  1.8497815  4.335504\n",
      " 2.513755   0.98636526 1.3691688  2.8294036  2.5666623  2.6305232\n",
      " 2.9515607  2.5818121  2.445516   1.380739   1.2934536  3.9474907\n",
      " 3.8094137  2.6283922  1.4322652  5.438942   3.1002731  2.3396494\n",
      " 3.107364   2.2027142  2.5408962  2.7962422  2.283192   2.4673483\n",
      " 1.8068624  2.8003652  2.417659   2.191989   3.5158474  2.5696912\n",
      " 2.9309964  1.089349   2.3964984  2.4203527  4.7490177  3.637816\n",
      " 3.7468338  2.8118923  3.2814898  3.6165185  1.5402328  1.3920878\n",
      " 1.402786   2.3872902  2.4323685  2.3079624  2.0250335  1.8332715\n",
      " 2.7475715  3.0422173  2.2768364  2.02139    2.6859188  2.441139\n",
      " 1.4381506  2.2639368  1.8818276  3.0485504  5.0041637  2.4972053\n",
      " 3.9167047  1.765091   4.223441   2.322196   2.8788612  1.7407026\n",
      " 2.859158   2.230355   4.136949   2.5691128  3.9943638  1.8677801\n",
      " 3.1068704  3.2954435  1.8639781  2.0872848  4.020202   1.7086166\n",
      " 1.7308102  2.3375547  2.884364   3.0224833  2.8961558  1.3113282\n",
      " 1.3644451  2.875968   1.6274208  2.7251756  1.984216   1.9756228\n",
      " 3.5557194  2.1570022  1.1275723  2.3895965  1.1408603  3.6374044\n",
      " 3.8885393  1.3205016  2.7275121  2.8898997  3.048724   1.2292802\n",
      " 1.672242   2.1896563  1.9129485  2.877407   2.4365823  0.95203227\n",
      " 2.7683356  2.5776246  4.409869   1.4536729  2.2549758  1.0564613\n",
      " 2.896151   1.7072415  3.549427   2.617278   2.3462963  2.2348442\n",
      " 2.336696   2.5769565  2.8472886  1.576379   4.93262    3.1403384 ]\n",
      "before add_job: block_6_expand [125  19   8 131  10  49 110 112 119  28 101 115 102  20  27  59  60  32\n",
      "  72 129   2  58 141 104] 24 144\n",
      "block_7_expand\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e2b2198> [0]\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e2b2198> [0] [0]\n",
      "before: act output Tensor(\"block_7_expand/convolution:0\", shape=(?, 14, 14, 288), dtype=float32)\n",
      "after: (288,) (?, 14, 14, 288) channels_last\n",
      "[0.63653576 0.5189036  0.43090504 0.8109455  0.6707428  0.37113968\n",
      " 0.48890424 0.39708847 0.53098035 0.40319663 0.6538523  0.44856858\n",
      " 0.35499328 0.42254257 0.42865625 0.49537462 0.3554865  0.3741886\n",
      " 0.28622812 0.41222513 0.8415395  0.34538364 0.5627664  0.38954747\n",
      " 0.2926033  0.31863475 0.4870212  0.7491263  0.45061296 0.37749076\n",
      " 0.45467606 0.8208805  0.29155824 0.33733943 0.4338772  0.32150146\n",
      " 0.38916674 0.541395   0.42215484 0.4242136  0.51257926 0.38092053\n",
      " 0.511899   0.4647692  0.38977033 0.6603517  0.4409515  0.36797842\n",
      " 0.4087431  0.31649408 0.46058482 0.56733227 0.41583237 0.41018486\n",
      " 0.36759055 0.36836034 0.9877179  0.46980432 0.3817672  0.59956723\n",
      " 0.4592332  0.5038316  0.30359086 0.37322497 0.36954975 0.4789686\n",
      " 0.34511033 0.32809788 0.5952852  0.73286235 0.5778651  0.57920873\n",
      " 0.393467   0.36723384 0.59121764 0.4030992  0.33110866 0.38558257\n",
      " 0.33521378 0.5834891  0.32869136 0.3842238  0.4045712  0.48674557\n",
      " 0.3134317  0.32437938 0.39159516 0.46549127 0.3205347  0.43899226\n",
      " 0.28284177 0.40762788 0.44057444 0.7715608  0.71513414 0.28166112\n",
      " 0.6753127  0.35188058 0.38376907 0.6110623  0.7734719  0.392093\n",
      " 0.3689272  0.49557996 0.4061471  0.30072793 0.29946235 0.418616\n",
      " 0.3023752  0.3323725  0.30663806 0.5413408  0.55587703 0.34872556\n",
      " 0.6934147  0.4203394  0.6209491  1.1670552  0.31711555 0.4085316\n",
      " 0.58084583 0.34211484 0.82041234 0.43968815 0.7874725  0.44237134\n",
      " 0.3861369  0.38495257 0.50447404 0.40469137 0.49258026 0.4107495\n",
      " 0.5114289  0.57828057 0.43814892 0.4766774  0.35054183 0.41373384\n",
      " 0.47220618 0.59823877 0.52382505 0.68112415 0.53931135 0.4354965\n",
      " 0.4974175  0.41095856 0.3770941  0.6320429  0.40926525 0.3482023\n",
      " 1.0471282  0.77076864 0.33773446 0.43222266 0.3659327  0.41567767\n",
      " 0.5055066  0.32017186 0.42320713 0.53645855 0.390554   0.45485577\n",
      " 0.39622077 0.3560774  0.33861294 1.0524093  0.4214862  0.47364604\n",
      " 0.40564826 0.6562093  0.85793006 0.39430317 0.45819822 0.38721874\n",
      " 0.94909793 0.382827   0.5318633  0.54712534 0.39168352 0.72615784\n",
      " 0.47813538 0.8225266  0.33886486 0.7342029  0.42264032 0.6028155\n",
      " 0.33609894 0.36603448 0.36630857 0.4261299  0.55187064 0.46670264\n",
      " 0.60212594 0.61828107 0.47109646 0.40931135 0.30189618 0.45948008\n",
      " 0.416033   0.698566   0.50817126 0.24894977 0.48098668 0.37811837\n",
      " 0.5428127  0.52684665 0.41465226 0.4064097  0.5582057  1.0716662\n",
      " 0.4110173  0.61695933 0.6147875  0.4419094  0.45721042 0.3553801\n",
      " 0.3688211  0.43617743 0.37638023 0.38483885 0.6951126  0.67300355\n",
      " 0.7748399  0.4293155  0.45506653 0.63310504 0.5195069  0.3927418\n",
      " 0.60718024 0.4602811  0.38439208 0.40128958 0.55469733 0.69275635\n",
      " 0.38057858 0.30574673 0.41974154 0.69069266 0.72795784 0.68037224\n",
      " 0.4180931  0.5376884  0.36874902 0.75791365 0.4111844  0.36022457\n",
      " 0.48679662 0.47982454 0.3402678  0.34034765 0.4876882  0.8463181\n",
      " 0.45770684 0.3681143  0.6103891  0.31401965 0.36759126 0.45351663\n",
      " 0.41377112 0.3782175  0.9425118  0.30939937 0.5249313  0.36236006\n",
      " 0.7143186  0.3659002  0.3186447  0.40220004 0.3386083  0.3945185\n",
      " 0.38936323 0.4828338  0.5144288  0.3607775  0.35346007 0.354269\n",
      " 0.3680025  0.5929232  0.36069638 0.40479898 0.8498283  0.6363882\n",
      " 0.68669945 0.44861645 0.37377423 1.0233375  0.3902996  0.3998333 ]\n",
      "before add_job: block_7_expand [201  95  90  18  32  24 106 105 196 108  62 235 110 261  84 255  49 118\n",
      "  25 266 157  88  35  85  67  80  76 109  78 186  33 152 268 164 182 248\n",
      " 249 121  66  21 149 113 136  97 274 275  12 215  16 163 245 278 273 263\n",
      " 265 154] 56 288\n",
      "block_8_expand\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e2b2ac8> [0]\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e2b2ac8> [0] [0]\n",
      "before: act output Tensor(\"block_8_expand/convolution:0\", shape=(?, 14, 14, 288), dtype=float32)\n",
      "after: (288,) (?, 14, 14, 288) channels_last\n",
      "[0.3902071  0.47338888 0.607139   0.58773035 0.36962995 0.31215268\n",
      " 0.53035057 0.54192644 0.32032162 0.37707466 0.596733   0.32131764\n",
      " 0.93065125 0.35517162 0.6315149  0.43952924 0.45521167 0.42029294\n",
      " 0.40776968 0.40841976 0.50872004 0.40639105 0.29200923 0.30115414\n",
      " 0.4219574  0.41460073 0.33233765 0.37591866 0.65409184 0.40007344\n",
      " 0.6837145  0.57803    0.49844813 0.46524748 0.7891986  0.3751683\n",
      " 0.5378043  0.40817147 0.86838996 0.32450408 0.5910653  0.6649079\n",
      " 0.6397278  0.5535291  0.31702733 1.0027716  0.3162571  0.35297716\n",
      " 0.33576    0.4385544  0.49066854 0.32362777 0.33832023 0.45734045\n",
      " 0.7089387  0.33059046 0.3881248  0.6976984  0.30839345 0.6357302\n",
      " 0.40471464 0.7705048  0.32217756 0.31006205 0.38043734 0.28552693\n",
      " 0.35564184 0.39504534 0.63329107 0.35039046 0.37204072 0.428488\n",
      " 0.3895171  0.48979098 0.5082447  0.46232605 0.5792591  0.3398697\n",
      " 0.38338906 0.3284901  0.7763737  0.49058378 0.40301183 0.6102044\n",
      " 0.34000626 0.4042821  0.40843293 0.6531419  0.4094019  0.2528192\n",
      " 0.3208932  0.32326362 0.5084041  0.6498868  0.539155   0.81945103\n",
      " 0.7793431  0.27578592 0.48355654 0.41466743 0.60382885 0.2636956\n",
      " 0.6655163  0.32632804 1.3730847  0.33930278 0.8530599  0.32997328\n",
      " 0.9008772  0.43157658 0.36075267 0.43137217 0.32727525 0.4107359\n",
      " 0.30033726 0.28463984 0.5408674  0.403792   0.80023974 0.8093199\n",
      " 0.31722105 0.31779224 0.32198572 0.56602734 0.3381607  0.45800266\n",
      " 0.43226326 0.29382837 0.5437517  0.3469643  0.39693183 0.3632128\n",
      " 0.33941972 0.3057097  0.4459258  0.50949055 0.5571262  0.38778824\n",
      " 0.5277679  0.60050666 0.35583454 0.37157926 0.33661145 0.30574554\n",
      " 0.54222685 0.9507186  0.3004181  0.7392358  0.78222525 0.28534976\n",
      " 0.4150721  0.52749693 0.51006037 0.45112288 0.45424002 0.41107973\n",
      " 0.38261768 0.3660881  0.64494526 0.7886034  0.39057738 0.65847373\n",
      " 0.45411217 0.3699984  0.3601899  0.3574596  0.45437562 0.6336498\n",
      " 0.3885759  0.49056756 0.443093   0.3912151  0.43858922 0.30179283\n",
      " 0.47468984 0.6583909  0.30817822 0.4893016  0.47236136 0.30596557\n",
      " 0.46997425 0.9294462  0.57584846 0.3470447  0.3914719  0.54865247\n",
      " 0.32891017 0.34486112 0.5575563  0.50025547 0.46608028 0.49994615\n",
      " 0.43414363 0.43759298 0.8433443  0.5443524  0.374555   0.53712064\n",
      " 0.34255528 0.77916497 0.48462605 0.5140671  0.7184321  0.7369571\n",
      " 0.41377345 0.31146097 0.41030422 0.3300576  0.41870663 0.48802835\n",
      " 0.4253668  0.6557247  0.5191923  0.55216306 0.4931105  0.36197218\n",
      " 0.47425556 0.28653952 1.4499234  1.0797743  0.31329536 0.4713167\n",
      " 0.3864402  0.31376794 0.5200783  0.2860741  0.34203434 0.500882\n",
      " 0.37313616 0.35844857 0.34928674 0.5618164  0.3832638  0.3082754\n",
      " 0.33536366 0.31823605 0.50830066 0.47230303 0.48721153 0.4821908\n",
      " 0.47364274 0.3672211  0.34224564 1.1576039  0.33188212 0.43525115\n",
      " 0.43441254 0.4185065  0.74708134 0.942513   0.44514212 0.42416707\n",
      " 0.34652948 0.2796045  0.40571114 0.39285007 0.61695176 0.67320246\n",
      " 0.6082116  0.32439515 0.39634898 0.4537458  0.32681394 0.42168543\n",
      " 0.5320236  0.31842938 0.34622166 0.44196087 0.32364914 0.31024882\n",
      " 0.4104943  0.6934353  0.5108399  0.53878355 0.34883052 0.5579175\n",
      " 0.36806026 0.48864877 0.2918465  0.44188234 0.67255896 0.5154582\n",
      " 0.76573634 0.4091917  0.4038809  0.46535036 0.36033422 0.32411498]\n",
      "before add_job: block_8_expand [ 89 101  97 253 115 149  65 225 217 278  22 127 114 146  23 173 133 143\n",
      " 179 176 233  58  63 269 205   5 220 223  46  44 120 121 235 265   8  90\n",
      "  11 122  62  91  51 268 287 259  39 103 262 112  79 186 107 207  55 244\n",
      "  26 234] 56 288\n",
      "block_9_expand\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e27f470> [0]\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e27f470> [0] [0]\n",
      "before: act output Tensor(\"block_9_expand/convolution:0\", shape=(?, 14, 14, 288), dtype=float32)\n",
      "after: (288,) (?, 14, 14, 288) channels_last\n",
      "[0.45004562 0.9884274  0.65832204 0.33091724 0.83211017 0.42823094\n",
      " 0.47080603 0.654479   0.51168865 0.54980147 0.38472536 0.32005918\n",
      " 0.6548352  0.30082107 0.45055535 0.542356   0.35268918 0.38121712\n",
      " 1.0953606  0.4615313  0.37633073 0.34329587 0.33720893 0.79838896\n",
      " 0.525293   0.5121633  0.49066535 0.34579924 0.4006858  0.9363353\n",
      " 0.6989783  0.3969132  0.61462957 0.40342298 1.0442563  0.33337435\n",
      " 0.51712245 0.6201952  0.3280584  0.68932503 0.5298957  0.3879547\n",
      " 1.1783365  0.30171007 0.83743054 0.32258722 0.43408772 0.38301206\n",
      " 0.4592843  0.32302266 0.38157597 0.9863261  0.36016533 0.37179413\n",
      " 0.33108336 0.4533224  0.42728183 0.37826768 0.5761473  0.41571313\n",
      " 0.42125642 0.45897868 0.5183442  0.5007088  0.47963735 0.7722266\n",
      " 0.4641905  0.7745853  0.46331125 0.321185   0.59022176 0.6101715\n",
      " 0.723284   0.6174721  0.38410804 0.3733652  0.6548144  1.2338772\n",
      " 0.42888305 0.6576993  0.5611405  0.33103564 0.3959472  0.71715015\n",
      " 0.3245928  0.66674936 0.48957247 0.77260727 0.52459097 0.76294714\n",
      " 0.39692634 0.37964246 0.2876064  0.6659876  0.49102855 0.52030575\n",
      " 0.32916507 0.39292893 0.4138026  0.59490126 0.72378325 0.6042077\n",
      " 0.47329247 0.28303906 0.45324224 0.351868   0.66347647 0.43545675\n",
      " 0.31680983 0.5148867  0.3749627  0.7395461  0.33389664 0.66905487\n",
      " 0.3427612  0.51316524 0.61917824 0.60312116 0.5302823  0.28872648\n",
      " 0.45585933 0.6059906  0.40203667 0.33262467 0.4605228  0.58350754\n",
      " 0.28735924 0.5210144  0.3230565  0.46445528 0.7531108  0.54665935\n",
      " 0.32686293 0.4241686  0.49598637 0.4595996  1.2490134  0.35680398\n",
      " 0.33778676 0.55964947 0.51788735 0.35191882 0.36903232 0.4245588\n",
      " 0.8307281  0.40532005 0.44923764 0.36698768 0.3575985  0.29945934\n",
      " 0.84320533 0.38475457 0.32884234 0.7231283  0.58501697 0.8137769\n",
      " 0.8048135  0.99538404 0.6221652  0.49047932 0.3854291  0.36173266\n",
      " 0.37142223 0.49675602 0.3583016  0.42374945 0.54741895 0.544319\n",
      " 0.38476777 0.5528539  0.43036628 0.3895332  0.37498125 0.8092257\n",
      " 0.34095022 0.50553197 0.61910653 0.8601587  0.7780339  0.42260385\n",
      " 0.78571784 0.4194256  0.42813462 3.4041195  0.406922   0.40877926\n",
      " 0.6055714  1.5898519  0.6415071  0.69083905 0.43297428 0.30923718\n",
      " 0.86556584 0.39604002 0.344952   0.5900897  0.4851088  0.39396554\n",
      " 0.31892732 0.34299797 0.5568897  1.1510856  0.56017673 0.5551638\n",
      " 1.0875536  0.40018168 0.36780438 0.32200998 0.42348215 0.46803766\n",
      " 0.45258293 1.0006214  0.4280886  0.29596624 0.629702   0.9156274\n",
      " 0.49648935 0.8062071  0.38099644 0.311159   0.33227468 0.40922892\n",
      " 0.6974016  0.5116851  0.38287827 0.29186594 0.43680322 0.36181358\n",
      " 0.8600591  0.5279329  0.42525464 0.7472554  0.5292101  0.4077813\n",
      " 0.8931557  0.34995723 0.6487731  0.70303214 0.5882379  0.3462574\n",
      " 0.31438726 0.37783667 0.35106462 0.3665392  0.31073478 0.33849505\n",
      " 0.39704067 0.36712798 0.6769154  0.5966348  0.4090948  0.6281568\n",
      " 0.4392726  0.43497047 0.68663985 0.41164112 0.6458378  0.4255914\n",
      " 0.39735126 0.52170587 0.5105439  0.91874725 0.5540379  0.38536695\n",
      " 0.3355402  0.9193871  0.40087193 0.4007814  0.37917787 0.4926782\n",
      " 0.35061035 0.37297133 0.37764055 0.35447547 0.4192236  0.63398737\n",
      " 0.7717567  0.3064214  0.6723859  0.4285046  0.5258866  0.38299757\n",
      " 0.41578197 0.32333308 0.43278542 0.48237798 0.39863697 0.3285944 ]\n",
      "before add_job: block_9_expand [103 126  92 119 225 213 149  13  43 277 191 244 219 240 108 198  11  69\n",
      " 207  45  49 128 283  84 132  38 287 152  96   3  81  54 220 123  35 112\n",
      " 264  22 138 245 174 114 199  21 194  27 239 235 270 242 105 141  16 273\n",
      " 137 148] 56 288\n",
      "block_10_expand\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e27fda0> [0]\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e27fda0> [0] [0]\n",
      "before: act output Tensor(\"block_10_expand/convolution:0\", shape=(?, 14, 14, 288), dtype=float32)\n",
      "after: (288,) (?, 14, 14, 288) channels_last\n",
      "[1.0563228  1.704083   0.8792122  1.3052946  1.0846045  2.0928633\n",
      " 0.81763756 1.9589183  1.602008   1.4056836  0.8865937  1.9520388\n",
      " 1.2897134  2.4624815  0.6535428  1.7266695  1.0972377  1.0883591\n",
      " 0.96886206 1.9622     1.8276024  1.1439961  1.1004689  1.6044605\n",
      " 2.1125712  1.3826286  0.7886157  1.9849455  0.9306308  0.98382694\n",
      " 1.3778429  0.99639225 1.4078814  1.0424477  1.6445547  0.9212052\n",
      " 1.8748778  0.9989782  1.0803951  0.8970014  1.0184504  1.6230338\n",
      " 1.8683891  1.5881783  1.1058333  0.8802137  1.4356633  1.1648002\n",
      " 1.2878318  1.2151992  1.5122166  0.9679459  1.218286   1.3956937\n",
      " 1.0084085  0.87856644 1.1756867  1.4907085  1.3032391  0.89365065\n",
      " 1.0272051  0.9553265  1.2004101  1.692628   2.263988   1.4366945\n",
      " 0.8928606  1.0423284  1.4298797  1.3876444  1.0161251  2.0229828\n",
      " 1.2208658  1.2499219  1.4404718  0.9973923  0.8640467  1.4416271\n",
      " 0.80950516 1.714415   0.80259657 0.8179046  0.8077597  0.8400657\n",
      " 0.7187183  1.3687888  1.1769763  1.046602   1.4561876  1.1916118\n",
      " 0.92456234 0.8959376  0.91602534 1.0625193  1.4940149  0.79901284\n",
      " 0.8641373  1.1636525  0.9416491  2.181227   1.1057405  1.1067357\n",
      " 1.7236474  1.1657354  1.2579324  1.5945647  1.3437876  1.1982952\n",
      " 1.9077451  0.79882544 0.9320178  0.93533725 0.86331415 1.7373985\n",
      " 1.4313514  1.3201078  1.0241047  1.7940183  1.2883271  1.5290554\n",
      " 0.8660141  1.0137277  1.4469678  1.2624003  0.84860724 0.8251002\n",
      " 1.152183   1.224552   0.89668566 1.3508692  1.0614249  1.0733796\n",
      " 1.5283006  1.0158322  1.3926706  0.7992131  0.91254663 1.3614451\n",
      " 2.0137558  1.8308845  0.7534162  1.2153721  1.2497603  0.9004316\n",
      " 1.5438577  0.7141744  1.2759355  1.4511943  1.3640766  1.0870265\n",
      " 1.3625075  1.8516694  1.4913269  0.78676224 1.110318   1.2001823\n",
      " 0.8987528  0.7038005  1.1312193  1.4679813  1.2726879  1.6233604\n",
      " 1.2907706  0.9621809  0.8199196  0.91199684 1.6526215  0.8436803\n",
      " 0.8694633  1.6168718  0.7559858  0.7819516  1.2955164  0.930234\n",
      " 1.5831662  1.2240347  0.9696809  1.1964993  1.3642001  1.1576751\n",
      " 0.9666297  0.95020336 1.2620789  0.77385634 1.8998668  1.0183624\n",
      " 1.7139473  1.4165925  1.0623173  1.0055163  1.3433394  0.8800258\n",
      " 1.3695     1.5139942  1.1357008  1.5674059  1.0542535  0.9270719\n",
      " 1.222875   1.0083973  0.8389524  1.0583106  0.91182584 0.8976962\n",
      " 1.135167   0.8537856  0.8113204  1.197912   0.7475036  1.6435672\n",
      " 1.5037544  0.9815767  1.0228767  0.92473173 0.70018506 0.8995261\n",
      " 1.4909105  0.86257434 0.71851397 0.8205832  1.9705725  1.6072007\n",
      " 1.2479721  2.1224148  1.5036443  2.3384504  0.97621006 1.7423706\n",
      " 0.9240152  1.2252308  0.74111176 0.81405264 2.4279168  1.5241723\n",
      " 0.8190704  0.8191277  1.8496612  1.0587718  1.2012082  1.065641\n",
      " 0.832193   1.1284112  1.1656072  1.45754    1.1195117  1.4957598\n",
      " 2.3222842  1.2709007  0.99997866 1.497272   1.6238151  0.9920806\n",
      " 1.7439871  1.7724109  1.0101684  1.7133257  1.3812608  0.83852535\n",
      " 1.5949343  1.0846515  1.1584804  1.6581017  1.5870578  1.0776818\n",
      " 1.0971487  1.1143017  1.0647017  1.9436141  0.6617333  1.9933776\n",
      " 1.6208917  1.1733558  1.0942715  1.5114002  1.937259   1.1659808\n",
      " 1.7372831  1.0557586  1.5710435  1.520749   0.9637953  1.6950618\n",
      " 1.0276922  0.8374011  1.279616   0.84788644 0.9569657  0.7930996 ]\n",
      "before add_job: block_10_expand [ 14 268 214 157 145 218  84 230 208 140 170 183 171 153  26 287 109  95\n",
      " 135  80  82  78 206 231   6  81 234 235 164 219 125 240 283 257 200  83\n",
      " 167 285 124 205 217 112  76  96 120 168  55   2 191  45  10  66  59  91\n",
      " 128  39] 56 288\n",
      "block_11_expand\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e2b06a0> [0]\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e2b06a0> [0] [0]\n",
      "before: act output Tensor(\"block_11_expand/convolution:0\", shape=(?, 14, 14, 432), dtype=float32)\n",
      "after: (432,) (?, 14, 14, 432) channels_last\n",
      "[1.1399167  1.5545276  0.9815056  0.6187054  0.4057182  0.36671707\n",
      " 0.6695849  0.4070967  0.39984298 0.43765852 1.1153986  0.38897973\n",
      " 0.34589556 0.58962744 0.71357304 1.3032006  0.4137739  0.81150496\n",
      " 0.4456494  0.69430375 0.3755276  0.40650225 0.5556268  1.1937877\n",
      " 0.7558661  0.5008074  0.64355594 0.29166293 1.0884957  0.5736768\n",
      " 0.53417313 0.45562318 0.48767987 1.0245426  0.7283332  0.94454837\n",
      " 0.529264   0.3914734  0.37695426 0.47777632 0.90049016 0.35513136\n",
      " 0.3273937  1.2951264  0.52463096 0.49559176 0.6162035  0.6582328\n",
      " 0.8618788  0.57794464 0.26089785 0.97650254 0.7529641  0.6132249\n",
      " 0.53504324 0.44470972 0.45746458 0.5599958  0.43491328 0.6052069\n",
      " 0.38329878 0.5483289  0.42760202 0.51906896 0.8628048  0.55145794\n",
      " 0.46409994 0.47322506 0.6447127  0.41557902 0.92383295 0.473971\n",
      " 0.44304863 0.41634995 0.6554249  0.8343492  1.1840371  1.0392143\n",
      " 1.3631637  0.7757996  1.214691   0.7125741  0.8736439  0.6734213\n",
      " 0.75289655 0.88111126 0.43712324 0.85508144 0.42336506 0.45503497\n",
      " 0.94590765 0.5478852  0.8811168  0.85873574 0.38141337 0.87204933\n",
      " 0.4272002  0.8067474  1.4530207  0.5451195  1.0389287  0.90763724\n",
      " 0.43193883 0.37902048 1.2903489  1.1789366  0.4849934  0.71282756\n",
      " 0.38246214 0.6057328  0.6152455  0.4860254  0.46931362 0.6558336\n",
      " 0.51926863 0.75254446 0.40379274 0.90569717 0.50278974 0.546666\n",
      " 0.98121434 0.95793796 0.4861651  0.47656205 0.7023142  1.0199496\n",
      " 0.98770034 0.44998473 0.53123647 0.47347915 0.47397035 0.4864809\n",
      " 0.48015833 0.8978175  0.35287678 1.0877962  0.42116407 0.59502524\n",
      " 0.43220726 0.42121428 0.4337725  0.9637713  0.58628404 0.9925929\n",
      " 0.5348718  0.74242747 0.42129204 0.9486591  0.53052956 0.47993153\n",
      " 0.58025265 0.39445996 0.60565305 0.34805793 0.79115164 0.38204098\n",
      " 0.5628375  0.49415064 0.36820066 0.40156892 0.41841096 0.5842195\n",
      " 0.55129296 0.5683425  0.5803453  0.76569796 0.3351547  0.7519708\n",
      " 0.92000693 1.4233409  1.5518589  0.65685475 0.3447525  0.39299226\n",
      " 0.3855703  1.1699548  0.65150064 1.0973463  0.4432765  0.42289805\n",
      " 0.4264081  1.0580575  0.81314534 0.6058134  0.45577845 0.32603088\n",
      " 0.7122284  0.6401605  0.8213893  0.43624783 0.9157799  0.76840305\n",
      " 0.4505659  0.5335436  0.3652712  0.4562524  0.8317586  0.5958044\n",
      " 0.7448892  0.6728201  0.6022496  0.98351634 0.9431606  1.0032156\n",
      " 0.5441183  0.8129556  0.42428112 1.0538894  0.5158773  0.91146654\n",
      " 0.6520051  0.42833874 0.7257353  0.5488307  0.5333913  0.49657974\n",
      " 0.4575131  0.39901844 0.71527636 0.45582563 0.48428363 0.44545418\n",
      " 0.84224236 0.44142827 0.58153695 0.4852021  0.71451813 0.60870767\n",
      " 0.47490853 0.51633203 0.7214425  1.1786214  1.267066   0.48339063\n",
      " 0.8359791  1.0149492  0.35451683 0.8215344  0.68533874 1.0335083\n",
      " 1.0103368  0.5754393  0.45328376 0.4187803  1.2558942  0.570709\n",
      " 1.1033156  0.768366   0.41947204 0.36071917 0.5319916  0.38813123\n",
      " 0.6239131  0.9142755  0.4099627  0.87911415 0.46298596 0.98985946\n",
      " 0.3646514  0.9748058  0.6470175  0.9229828  0.5007495  0.75110054\n",
      " 0.5505287  0.5965769  0.5294015  0.607729   0.61650336 1.0826497\n",
      " 1.4678108  0.419834   0.6631251  0.89652056 1.3156745  0.9689196\n",
      " 0.9176321  0.62105334 0.728934   0.535828   1.0685682  0.85291713\n",
      " 0.7996445  0.5723982  0.71494156 0.6977903  0.49976468 0.5767047\n",
      " 0.47302037 0.59786874 0.5513316  0.44690645 0.87956345 1.205706\n",
      " 0.9716765  0.5885326  0.88703984 0.43180615 0.43908104 0.63859856\n",
      " 1.0776871  0.46838483 0.3882683  0.48858476 1.1576903  1.0129018\n",
      " 0.55120474 1.2407063  0.47544426 0.60461724 0.66661286 0.7076746\n",
      " 0.41405162 0.8348777  0.3545079  0.8440472  0.50297403 0.5223064\n",
      " 0.82663584 0.48175508 0.44603914 0.47742707 0.47063226 0.37584573\n",
      " 0.4412668  0.6973683  0.48605055 1.1436083  0.51974815 0.46345833\n",
      " 0.720109   0.93049884 0.5273596  0.8993201  0.33567795 1.5800773\n",
      " 0.4323142  1.1911188  0.4930801  0.8671233  0.82933205 0.92477506\n",
      " 0.42051655 0.5582951  0.5261951  0.38653222 0.4678481  1.0685188\n",
      " 0.5522205  0.3985865  0.44139737 0.50198096 0.9912696  0.9551285\n",
      " 0.5981713  0.39332363 0.40680218 0.92064905 1.0642221  0.547395\n",
      " 0.7506469  0.33658868 1.1474785  0.67167264 1.1279352  0.5481697\n",
      " 0.41687876 0.36780947 0.7482075  0.7940281  0.7679468  0.7264682\n",
      " 0.7652476  1.2752248  0.3621593  0.7862491  0.67792135 0.5100265\n",
      " 0.38355023 0.5337931  0.63298833 0.62810296 0.37647456 0.44902697\n",
      " 0.5188757  0.48865548 0.8928966  0.86273825 0.53918964 0.56908065\n",
      " 0.57197475 1.3626357  0.6483584  1.27363    0.9053332  1.0282121\n",
      " 0.5401083  0.6286311  0.4094698  0.43372527 0.69392866 0.49246255\n",
      " 0.36378667 0.5074706  0.7446543  0.5936285  0.6118466  1.1581751\n",
      " 0.7080883  0.3740863  0.58804625 0.9166032  1.3020724  0.46805194\n",
      " 0.35263795 0.86573535 0.43462938 0.99727446 0.91762596 0.7939598\n",
      " 0.41334528 0.43812293 0.7106458  0.80553454 0.4783336  0.8297569\n",
      " 0.41320223 0.4696718  0.51900566 0.43319172 0.72749877 0.51719576]\n",
      "before add_job: block_11_expand [ 50  27 185  42 166 334 361 172  12 153 414 134 314 236  41 249 374 402\n",
      " 258 194   5 367 158 409  20 323 382  38 103  94 155 108  60 378 174 345\n",
      " 251 302  11  37 173 355 151 349 217   8 159 116   4  21 356   7 398 254\n",
      " 426 420  16 312  69  73 366 160 243 248 271 342 136 139 146 179  88 206\n",
      " 180  96  62 211 297 102 138 336] 80 432\n",
      "block_12_expand\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e27ffd0> [0]\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e27ffd0> [0] [0]\n",
      "before: act output Tensor(\"block_12_expand/convolution:0\", shape=(?, 14, 14, 432), dtype=float32)\n",
      "after: (432,) (?, 14, 14, 432) channels_last\n",
      "[0.95518774 0.5724242  0.906855   0.80606246 0.36863327 0.7749263\n",
      " 0.57555896 1.323521   0.9174138  0.7520593  0.71012527 1.1197907\n",
      " 1.0805206  0.7659611  0.43784916 0.8361194  0.6806976  0.60747117\n",
      " 0.47690818 0.62859136 0.56020963 1.0299318  0.7490295  0.9168115\n",
      " 0.73378503 0.3672265  0.5304927  0.57532215 0.53494644 0.86789405\n",
      " 0.7152958  0.77839375 0.9521598  0.9835137  1.273351   1.6570344\n",
      " 0.7587665  0.5577398  0.7582318  0.9319387  0.62796474 0.4417868\n",
      " 0.73966193 0.5768489  0.5984065  0.637602   0.5279814  0.58827007\n",
      " 0.511681   1.079544   0.5611547  0.44797942 0.6447778  0.35151523\n",
      " 0.7120195  0.75223154 0.9611662  0.45210788 0.5368987  0.44868714\n",
      " 1.0039806  0.6852402  1.0121403  0.7410427  0.35272282 0.70789367\n",
      " 0.6764555  0.54507935 0.86322135 0.4000258  1.0358618  0.54133075\n",
      " 0.48883832 0.593659   0.5384781  0.73464686 1.205739   0.854411\n",
      " 0.7436439  0.77482516 0.6454732  0.4313292  0.68274295 0.6382277\n",
      " 0.599731   0.45778638 0.43788424 0.70268905 1.2474542  0.5611613\n",
      " 1.6323806  0.5776054  0.53317744 0.44954112 0.96991354 1.1713905\n",
      " 0.63356465 0.5332762  0.58449227 0.73012245 0.53855133 0.47662708\n",
      " 0.47582412 0.4085556  0.7477512  1.0062767  0.40975463 0.36991876\n",
      " 0.96536994 0.39239466 0.43706304 1.6065109  0.481377   0.57949805\n",
      " 0.6573572  0.94586354 0.424433   0.42807072 0.5155217  0.48973674\n",
      " 0.52892226 0.54800934 0.7024083  0.3727395  0.6363765  0.51632655\n",
      " 0.71279305 0.695033   0.42289877 0.36281845 0.5569705  0.96808434\n",
      " 0.7585401  0.7349403  0.7412928  0.4074502  0.6174601  0.765969\n",
      " 1.0970594  0.534229   0.49917752 0.80488086 1.1145798  0.8053526\n",
      " 1.2793868  0.57007706 0.6817382  0.93142754 0.8421389  0.48558646\n",
      " 0.7253924  0.6758429  0.40512642 0.6939631  0.4634369  0.84901285\n",
      " 0.64856344 0.5876763  0.40526438 0.6718234  0.5766041  0.4690304\n",
      " 0.6334621  0.36746362 0.8449349  0.5439706  0.7230876  0.54068714\n",
      " 0.37665042 0.6192324  0.5634787  0.6278535  0.8075894  0.46871358\n",
      " 0.44594955 0.55930984 0.5471246  0.5420085  0.77143735 0.48226836\n",
      " 2.063378   0.5377985  0.54742104 0.7346384  0.5712828  0.69084215\n",
      " 0.526244   0.87725866 0.69304895 0.9476757  0.5560297  0.6867071\n",
      " 0.42103425 0.7660841  0.81866    0.42421672 0.594184   0.8682344\n",
      " 0.8967116  1.0855635  0.60793525 0.51201344 0.62504244 0.5446905\n",
      " 0.74350744 0.5545109  0.9647907  1.3177667  0.54929984 1.020354\n",
      " 0.6453049  0.5941273  0.8087635  1.4630128  0.6172232  0.87787837\n",
      " 0.8511251  0.4709725  0.55196697 1.2268622  0.51155984 0.77091086\n",
      " 0.94443524 0.90530944 0.6011849  1.4174954  0.98240054 0.422514\n",
      " 0.47062087 0.9079491  1.1732051  1.1192117  1.1980848  0.89530915\n",
      " 0.921751   0.52207786 0.78018135 0.39208633 0.48397282 1.0918616\n",
      " 0.48745984 0.8034769  0.44051608 1.0383765  0.41457734 0.5237249\n",
      " 0.9664291  0.91891444 0.69151264 0.5593011  0.6994867  0.62096024\n",
      " 0.78178406 0.4724999  0.83820355 0.6526554  0.5641141  0.5133814\n",
      " 0.6573912  0.7175859  0.7749177  0.49076137 0.45323375 0.6077532\n",
      " 1.3803037  0.9431359  0.6374601  0.4031083  0.89612806 0.58918095\n",
      " 0.61212313 1.0374569  0.435252   0.50348675 0.4646701  1.095302\n",
      " 0.48662165 0.37645805 1.1833091  0.45105785 0.4748751  0.6494794\n",
      " 0.5539394  0.88808787 1.3859812  0.77100563 0.975199   0.7577916\n",
      " 0.54156107 0.6415861  0.44286728 1.0256518  0.4099677  0.5404264\n",
      " 0.48633465 1.066611   0.9834083  1.2261485  0.5451505  0.5509378\n",
      " 0.5371736  0.9530332  0.46617112 0.87671447 0.5543526  0.41915938\n",
      " 0.46053693 0.6108284  0.94233817 0.72890425 1.2570777  0.43156385\n",
      " 0.86290216 0.65577406 0.8503697  0.68197674 0.6872709  0.7751891\n",
      " 0.47395292 0.88637745 0.8271011  0.57266694 0.65822965 0.75100064\n",
      " 0.43563163 0.44727564 0.52467597 0.8769739  0.56679183 0.42437991\n",
      " 0.38012388 0.6048729  0.71788794 0.54255676 0.5769213  0.3987727\n",
      " 0.42124367 1.0508417  0.5460907  0.82292724 0.39489973 0.62417585\n",
      " 1.1800872  1.0047013  0.95997185 0.78394234 0.48051113 0.6982342\n",
      " 1.226257   0.85591155 0.52632815 1.1427538  1.2148411  0.852025\n",
      " 0.3879914  1.0155143  0.49797553 1.1019646  0.81815135 0.9898434\n",
      " 0.8001409  0.7259489  0.4165264  0.45909783 1.5991464  0.4665124\n",
      " 1.0345129  0.45339942 0.60489625 0.85474896 0.4832229  0.6386698\n",
      " 0.4595763  0.5661437  0.5723867  0.7682729  0.45406032 0.65193045\n",
      " 0.893683   0.89154005 0.5938845  0.47913685 1.0047225  0.7605124\n",
      " 0.73296726 0.5587396  0.52073437 0.88684887 1.3355805  0.55339235\n",
      " 1.7407935  0.5965802  1.2779906  0.72600853 0.6631538  0.39081752\n",
      " 0.69913805 0.68914646 0.9535958  0.8847117  0.5115555  0.8570559\n",
      " 0.54615855 0.41798422 1.4833121  0.75942135 1.2135837  0.5182015\n",
      " 1.0132326  1.1166487  0.5773937  0.7827146  0.7451164  0.5606125\n",
      " 0.7762167  0.5319929  1.1089545  0.91203207 0.6173899  0.45545018\n",
      " 0.6695524  0.7620114  0.4976765  0.9528456  0.8209605  0.59723246\n",
      " 0.75553936 0.47114974 0.5563992  0.42279503 0.4619436  1.5850347 ]\n",
      "before add_job: block_12_expand [ 53  64 129  25 163   4 107 123 277 168 330 354 395 237 109 340 335  69\n",
      " 267 152 158 135 103 106 292 244 362 403 305 192 336 227 429 128 195 329\n",
      " 116 117  81 311 272 324 110  14  86 242  41 290 174 325  51  59  93 279\n",
      "  57 262 367 376 419  85 363 372 306 430 154 274 302 365 173 161 228 217\n",
      " 427 253 318 280 102 101  18 381] 80 432\n",
      "block_13_expand\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e294940> [0]\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e294940> [0] [0]\n",
      "before: act output Tensor(\"block_13_expand/convolution:0\", shape=(?, 14, 14, 432), dtype=float32)\n",
      "after: (432,) (?, 14, 14, 432) channels_last\n",
      "[2.031038  1.5472932 1.8211247 2.089211  1.7378819 1.6714066 2.032915\n",
      " 2.2062001 2.0667646 2.5831823 1.5308083 2.7825284 1.9384195 2.2355483\n",
      " 1.5487463 1.9560765 1.7560902 1.5592208 1.8219105 1.775387  2.1011372\n",
      " 1.4596678 1.463957  1.492485  1.7866715 1.5927976 1.7909061 1.3701574\n",
      " 2.0186064 1.8995215 2.0109968 1.8357692 2.5653741 1.8080115 1.8090473\n",
      " 2.02527   2.767662  1.4978167 2.9887803 2.1886504 1.8118765 2.0068817\n",
      " 2.0600662 2.296715  2.1836476 2.0196674 2.6471963 2.3609946 1.9609662\n",
      " 1.4458262 1.6284364 1.5272845 2.367022  1.8316936 1.640235  1.8528161\n",
      " 1.6922042 1.3924563 2.3736675 1.5748968 1.7037858 2.5677896 2.6009622\n",
      " 2.361691  2.1969957 2.193248  2.543627  1.4975189 2.2822819 1.6930641\n",
      " 1.7752218 1.5067942 1.8881006 1.9676275 2.0478954 2.1416469 1.8984901\n",
      " 1.532175  2.1866598 1.9803803 1.289112  2.009108  1.7417665 2.565662\n",
      " 2.2558372 2.040319  2.123592  1.5259756 2.4262378 1.5960242 2.2776005\n",
      " 1.4591358 1.5225378 1.8061652 1.63784   1.9210459 1.9337775 2.0511286\n",
      " 2.0141919 1.9715984 1.9240447 1.4245645 2.038419  1.6653459 1.4262705\n",
      " 1.9594209 2.0785728 1.4035989 1.9121588 2.540051  1.6654146 2.3929634\n",
      " 1.5577418 1.4817519 1.7123972 2.428777  1.4457595 2.3550997 2.4758759\n",
      " 1.8327714 1.6429741 1.844836  2.0925784 1.7655599 1.5369376 1.8190103\n",
      " 2.0380592 2.1309538 1.68274   2.897215  1.7301153 1.5433478 2.3220973\n",
      " 1.871264  1.3639965 2.1704066 2.0508647 2.600377  1.7947792 2.0947816\n",
      " 1.8312678 1.9669603 1.3400955 2.7776237 2.301134  2.6335812 1.84674\n",
      " 1.4181737 3.3133197 1.7173396 1.8029329 1.895569  2.3721578 1.8357332\n",
      " 2.2286518 1.709596  1.9967867 1.5786976 1.4542072 1.8715588 2.0690694\n",
      " 2.1186903 1.6570843 1.9783013 1.6988822 2.2246115 2.377472  2.0514135\n",
      " 1.7272371 1.6739877 2.134398  2.4097993 1.5160717 1.5745121 1.3783526\n",
      " 1.4696254 1.9005154 2.0994523 2.00361   1.4861939 2.372356  1.8823348\n",
      " 1.8264766 1.8908424 1.8450214 2.5400069 1.7668464 3.0484362 1.5609759\n",
      " 1.5747898 1.8774382 1.3639253 1.9417    2.080297  1.9379761 1.9611374\n",
      " 1.6670331 1.4680779 2.1562717 1.4620284 1.7679515 2.9231136 1.7531774\n",
      " 1.5322502 1.7249002 1.9369353 1.8621991 1.6129615 2.148594  1.8332978\n",
      " 1.9032665 1.7329737 1.5409762 1.6284343 2.0291405 1.4910173 1.2208586\n",
      " 3.238661  1.6914808 1.625645  2.6479452 1.4905635 1.5642246 2.6394734\n",
      " 3.0877066 1.8350447 1.7660334 1.3721513 1.3824836 2.6844423 2.1858728\n",
      " 1.6514618 1.6033535 2.372773  2.3383076 1.50132   2.5076854 1.6134816\n",
      " 2.521219  2.00046   2.4836748 2.6684616 1.9584522 2.7474356 2.3024678\n",
      " 2.1705952 1.9327273 1.4648806 1.6955539 2.021349  1.5318677 2.06751\n",
      " 1.5070566 2.000261  2.3078387 3.143675  1.7799208 1.4219486 2.6690922\n",
      " 1.4809463 2.2856383 1.6872228 1.7278028 1.5003548 2.925963  2.2895916\n",
      " 2.1976752 1.8854362 1.446832  1.8364656 2.8234906 1.3429723 2.6624954\n",
      " 2.0405083 1.5277563 1.6452723 2.5982459 2.1403236 1.698521  1.8518592\n",
      " 2.032414  1.8358461 1.5360153 2.5839932 2.493572  1.8476626 1.6648867\n",
      " 1.7543496 2.06476   1.40792   1.8125015 2.3132927 2.5217566 1.471734\n",
      " 1.2910638 1.8247793 1.8856801 2.7031503 1.9993131 1.7284857 1.5261848\n",
      " 1.6502109 1.4822001 2.1538208 1.9840045 1.55734   2.6384587 1.591541\n",
      " 1.6211532 2.1731822 2.2822845 2.1551673 1.5661074 2.022196  1.8106626\n",
      " 1.4374815 1.6963203 1.864132  2.7279801 1.8928307 2.2278605 2.4705691\n",
      " 2.4430525 1.7036009 1.6952108 1.8397186 1.8954109 2.619911  2.2379541\n",
      " 2.4443672 1.8123099 1.8464121 1.8546283 1.8378685 1.5283414 1.7739688\n",
      " 2.399149  2.2734864 2.285693  1.4440997 1.5229257 1.956141  2.0772247\n",
      " 2.1650198 2.0496657 1.6423337 2.1210754 1.2383347 1.5510488 1.8133082\n",
      " 2.305971  1.8223684 2.9627137 1.9981166 1.8778954 1.584607  1.2917546\n",
      " 1.9272659 1.7490808 2.0381005 2.0444157 2.1485295 1.8709896 1.9773846\n",
      " 1.8222104 1.3774245 1.9200916 1.5776974 1.4624356 2.438779  1.6596067\n",
      " 1.6229277 2.2637186 1.8227098 1.980939  1.7464432 2.1842992 1.6414737\n",
      " 1.8997524 2.5299432 1.8984113 3.0400014 1.9815524 2.0794802 1.8609805\n",
      " 1.7827777 1.6296622 1.7860641 1.6464188 1.4714106 1.6919692 1.5733174\n",
      " 2.1256387 2.173976  1.5459278 1.38168   1.596368  1.9886423 2.2658548\n",
      " 2.1127667 2.0781138 1.4776499 1.6056582 1.8836899 1.5998033 1.5295748\n",
      " 1.5783167 1.6763966 1.8143727 2.22407   1.8693724 2.1156464 1.6676975\n",
      " 1.5261883 2.2865207 1.9506065 2.4629195 1.8544235 2.0217326 2.1990435\n",
      " 2.0498395 1.4640677 1.5366541 1.3167259 1.6755072 2.3153813 1.5075665\n",
      " 1.6503109 2.6940546 1.2139041 2.0870483 2.176023 ]\n",
      "before add_job: block_13_expand [429 216 347  80 294 356 423 142 271 191 134  27 227 365 174 395 228  57\n",
      " 107 289 147 257 101 104 315 339 116  49 268 158  91  21 199 368  22 421\n",
      " 247 197 175 389 293 401 259 113 302 179 221 215  23  67  37 263 235  71\n",
      " 252 426 172  92 340  87 300 413  51 274 334 405  10 250  77 203 282 422\n",
      " 124 212 131 394   1  14 348 305] 80 432\n",
      "block_14_expand\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e2b6278> [0]\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e2b6278> [0] [0]\n",
      "before: act output Tensor(\"block_14_expand/convolution:0\", shape=(?, 7, 7, 720), dtype=float32)\n",
      "after: (720,) (?, 7, 7, 720) channels_last\n",
      "[0.28190112 0.5506228  0.3867257  0.5418454  0.30441377 0.41436026\n",
      " 0.40816703 0.29952753 0.3296479  0.43906382 0.4557998  0.6153599\n",
      " 0.32842067 0.3200283  0.48352772 0.47174886 0.2780834  0.3396388\n",
      " 0.34128582 0.35869226 0.43699992 0.40919206 0.4293363  0.3939808\n",
      " 0.40421766 0.30040103 0.36256945 0.3469979  0.31069842 0.26863414\n",
      " 0.46167997 0.28024083 0.46080276 0.4990354  0.49406672 0.36545202\n",
      " 0.31624174 0.3371974  0.27422866 0.4627417  0.3612461  0.37116948\n",
      " 0.36570275 0.3862408  0.39128286 0.4424976  0.3877169  0.27190503\n",
      " 0.33055377 0.43303382 0.53846735 0.348436   0.48189765 0.30679342\n",
      " 0.66751826 0.41614994 0.51163965 0.49944168 0.3993724  0.36204553\n",
      " 0.4053251  0.37082177 0.32178372 0.31404656 0.37141907 0.32921878\n",
      " 0.34649512 0.35309058 0.41172644 0.39813226 0.32906327 0.9403938\n",
      " 0.3645954  0.24705304 0.32334077 0.24807192 0.36116874 0.30352217\n",
      " 0.71232873 0.36617506 0.70907277 0.29947856 0.26448846 0.339547\n",
      " 0.30903965 0.38290083 0.39999452 0.2824681  0.3796177  0.33858874\n",
      " 0.4665419  0.326423   0.64935327 0.27266595 0.30421436 0.4071262\n",
      " 0.6968174  0.24158451 0.31505683 0.3423148  0.56159776 0.4053905\n",
      " 0.4130333  0.43646866 0.353548   0.6809381  0.80396557 0.54342616\n",
      " 0.28940436 0.61724627 0.7557258  0.29227412 0.27543506 0.5029785\n",
      " 0.31605482 0.30803165 0.43674317 0.34528401 0.5502347  0.29412833\n",
      " 0.34292212 0.29809853 0.45220864 0.33662835 0.4062094  0.39423966\n",
      " 0.4759955  0.5171137  0.39513308 0.4325583  0.28502193 0.31443244\n",
      " 0.33582422 0.30050996 0.3719274  0.5320212  0.32878482 0.33551407\n",
      " 0.2990041  0.4448385  1.3287477  0.41159734 0.468584   0.71576124\n",
      " 0.29164186 0.4096297  0.47039023 0.4259104  0.5600776  0.36486372\n",
      " 0.35146987 0.45433655 0.26344892 0.35485116 0.5583757  0.43294674\n",
      " 0.3123152  0.41843963 0.38052806 0.3813634  0.2557456  0.30571976\n",
      " 0.3672311  0.33698633 0.29676104 0.47449997 0.32185426 0.29392648\n",
      " 0.3284093  0.6423711  0.4846873  0.42460623 0.5190498  0.32480514\n",
      " 0.6362463  0.34285483 0.36588952 0.3858205  0.41174027 0.40281865\n",
      " 0.38418472 0.30529776 0.33274764 0.48301035 0.33180952 0.3427113\n",
      " 0.51396966 0.3910115  0.40225917 0.5142373  0.42313504 0.5494054\n",
      " 0.56832826 0.60191405 0.40875655 0.36513346 0.30972162 0.3895445\n",
      " 0.39078093 0.30975094 0.29334196 0.33369848 0.33811164 0.48669264\n",
      " 0.34227625 0.37649092 0.40994996 0.61385477 0.31612784 0.42312276\n",
      " 0.31779584 0.43695238 0.29784226 0.4779091  0.3935627  0.5264264\n",
      " 0.34179243 0.48624206 0.4020956  0.47227442 0.5395888  0.3252378\n",
      " 0.4954148  0.34425604 0.3899908  0.67374873 0.345057   0.3770769\n",
      " 0.5336681  0.39140144 0.40550905 0.35227734 0.3722694  0.39120072\n",
      " 0.38703036 0.5009836  0.42749184 0.3570092  0.3088161  0.38896522\n",
      " 0.6612179  0.40477327 0.31757075 0.36476374 0.27664807 0.39708167\n",
      " 0.40396607 0.31303123 0.422987   0.35915208 0.3343872  0.39743197\n",
      " 0.45211574 0.35378048 0.4774654  0.42401958 0.23751928 0.45771584\n",
      " 0.3783264  0.33359617 0.44718447 0.6061269  0.43825355 0.6908245\n",
      " 0.38124827 0.40140378 0.28286535 0.30869627 0.3492423  0.3033441\n",
      " 0.3209818  0.3607761  0.45504487 0.27975532 0.6457546  0.27661198\n",
      " 0.47775128 0.6956678  0.46204713 0.28247157 0.39628273 0.3148032\n",
      " 0.40154937 0.399169   0.40148422 0.43223262 0.21895431 0.4368297\n",
      " 0.34189084 0.4956226  0.4479659  0.7600635  0.33994067 0.39799133\n",
      " 0.33458862 0.35328606 0.32422742 0.43959945 0.44897136 0.3966289\n",
      " 0.35606462 0.47511807 0.5288428  0.27140507 0.43360654 0.31820855\n",
      " 0.83887565 0.4289773  0.54192734 0.44706127 0.3703864  0.48553762\n",
      " 0.3075727  0.46099013 0.4254161  0.46025318 0.293041   0.44225198\n",
      " 0.28469652 0.3258159  0.38366526 0.36236417 0.34309587 0.49395427\n",
      " 0.3816419  0.4094561  0.36044714 0.43906265 0.29015437 0.27707118\n",
      " 0.31029359 0.59443915 0.3560119  0.54313785 0.46287608 0.30873337\n",
      " 0.5098522  0.43033364 0.40244672 0.38649455 0.322819   0.40029922\n",
      " 0.5863872  0.7881144  0.49340576 0.30508047 0.4287899  0.24660404\n",
      " 0.44480047 0.6265295  0.31860688 0.3171682  0.5739877  0.3779446\n",
      " 0.2814835  0.36253014 0.38631898 0.40299818 0.24127157 0.5465301\n",
      " 0.4321108  0.28872392 0.5009004  0.32713172 0.45543852 0.38612983\n",
      " 0.5421361  0.34564173 0.47197074 0.344032   0.40819347 0.38727334\n",
      " 0.31178862 0.35460058 0.38179627 0.7201047  0.39589813 0.4014145\n",
      " 0.31595227 0.44549415 0.3766664  0.34651268 0.4500683  0.280286\n",
      " 0.45134    0.32355583 0.35709172 0.28268683 0.45709744 0.38879225\n",
      " 0.73842347 0.34240955 0.41814253 0.27994987 0.2940929  0.33497947\n",
      " 0.4820509  0.35254645 0.31621417 0.3410212  0.4860735  0.6580932\n",
      " 0.34478143 0.40628302 0.43481004 0.43743527 0.4253037  0.26262528\n",
      " 0.7767996  0.32240584 0.40016076 0.43066242 0.31385088 0.5276654\n",
      " 0.3108575  0.6249763  0.28935784 0.425085   0.87771994 0.39000335\n",
      " 0.36192733 0.31441814 0.31393543 0.3357153  0.32044968 0.55584\n",
      " 0.4474887  0.31270975 0.4239089  0.33291855 0.43893093 0.5323288\n",
      " 0.39703292 0.46641144 0.46824145 0.31671277 0.37040806 0.5068091\n",
      " 0.26776293 0.388728   0.38321736 0.6039274  0.83422875 0.45272428\n",
      " 0.2924188  0.30018544 0.63130856 0.63313574 0.35529873 0.8235017\n",
      " 0.32256734 0.31878555 0.32596877 0.26919872 0.6567867  0.39064312\n",
      " 0.28577957 0.3892606  0.6020403  0.42346904 0.41826403 0.42040586\n",
      " 0.39193532 0.4847146  0.5330632  0.4247355  0.6066673  0.4296064\n",
      " 0.31349862 0.6444     0.29502225 0.38848627 0.28763962 0.7383375\n",
      " 0.3080584  0.56582254 0.45668438 0.3829593  0.3021064  0.42251268\n",
      " 0.3474112  0.29940456 0.29584467 0.38885832 0.38591844 0.72354317\n",
      " 0.34101704 0.4912506  0.54126656 0.47232825 0.44317988 0.31578377\n",
      " 0.43946072 0.4154592  0.34443796 0.57596725 0.2934566  0.39652762\n",
      " 0.4698422  0.5095822  0.39062598 0.5846195  0.53626037 0.36100733\n",
      " 0.61841005 0.38100463 0.4272926  0.4360469  0.2794389  0.425069\n",
      " 0.4736734  0.49205133 0.28180125 0.2820031  0.2850853  0.4798349\n",
      " 0.3744093  0.39890233 0.872711   0.29718426 0.3957331  0.4963075\n",
      " 0.36551827 0.44664714 0.36637223 0.31456387 0.5066043  0.32961002\n",
      " 0.45270514 0.4041668  0.3218601  0.67863    0.34876823 0.29838145\n",
      " 0.40564284 0.4066176  0.46999928 0.51924276 0.5746568  0.32118475\n",
      " 0.3188193  0.43009487 0.29338208 0.4912989  0.43732455 0.552961\n",
      " 0.50214344 0.35187736 0.35360393 0.33276087 0.4148936  0.6889331\n",
      " 0.492139   0.48969838 0.46886024 0.45012337 0.48467493 0.34893113\n",
      " 0.4631245  0.371216   0.38992587 0.29723594 0.283271   0.35812292\n",
      " 0.3330799  0.30056906 0.34172872 0.47041816 0.33746925 0.3584897\n",
      " 0.43447107 0.48051476 0.3356199  0.32005942 0.37340668 0.5640574\n",
      " 0.52025634 0.46742684 0.5190633  0.3491562  0.3632555  0.39891067\n",
      " 0.30046555 0.30893818 0.6491337  0.2759258  0.7111188  0.3982453\n",
      " 0.42189622 0.5066498  0.5154927  0.26896256 0.34269932 0.5431501\n",
      " 0.4639531  0.3361846  0.4672853  0.32119676 0.25574216 0.38007692\n",
      " 0.467375   0.34782854 0.31965932 0.53162664 0.30554512 0.56632507\n",
      " 0.345818   0.39604124 0.5886906  0.326655   0.6651336  0.35999024\n",
      " 0.3389401  0.45558265 0.3069012  0.9638271  0.31032827 0.26049373\n",
      " 0.59989923 0.44661275 0.35014462 0.3267473  0.32201588 0.3541223\n",
      " 0.57250416 0.3540177  0.294129   0.514576   0.5453747  0.3376319\n",
      " 0.39025787 0.5932703  0.2661494  0.4607042  0.2914198  0.3627426\n",
      " 0.35674134 0.33216327 0.31912753 0.39894697 0.35751653 0.39587894\n",
      " 0.38908485 0.79135793 0.50778514 0.55640393 0.4323303  0.3213384\n",
      " 0.72077256 0.3839606  0.5072934  0.31949922 0.3241961  0.29781806\n",
      " 0.27982756 0.5389584  0.34637308 0.31959778 0.36484227 0.5260638\n",
      " 0.40190208 0.42049623 0.325937   0.53518224 0.5254592  0.30757296\n",
      " 0.5547734  0.28475907 0.3443153  0.35365087 0.4454684  0.5078816\n",
      " 0.4131925  0.3237406  0.35115656 0.5467305  0.4471535  0.41167107\n",
      " 0.4932435  0.29947165 0.6384188  0.33766285 0.36704352 0.35744286\n",
      " 0.26299992 0.41433805 0.39470202 0.46551484 0.6155487  0.37570718\n",
      " 0.38516718 0.2997905  0.37340993 0.43176442 0.30166778 0.5687035\n",
      " 0.31217527 0.29499578 0.52703255 0.26931232 0.5365535  0.34457275\n",
      " 0.48747697 0.3340676  0.37981844 0.29789186 0.28874353 0.46275973\n",
      " 0.48246032 0.31346118 0.30071568 0.41424245 0.3410594  0.5186019\n",
      " 0.7049049  0.45671496 0.47721535 0.31267762 0.3574313  0.3812636 ]\n",
      "before add_job: block_14_expand [286 256 358  97 347  73  75 598 160 617 407 684 152  82 632 438  29 591\n",
      " 453 699 303  47  93  38 112 585 275 244 329  16 508 273 654 393  31 383\n",
      " 354 512   0 513  87 279 387 266 562 318 667 130 514 456 472 361 706 416\n",
      " 108 328 634 144 111 444 316 200 542 496 167 394 119 626 697 470 482 164\n",
      " 519 561 653 212 705 121 533 138 481 679  81   7 691 445  25 582 133 565\n",
      " 710 694 478 269  77  94   4 345 181 604 161  53 614 312 665 115 474 267\n",
      " 335 238 583  84 196 199 330 616  28 414 372 696 156 717 427 247 709 468\n",
      " 412 422  63 421 131 525 281  98 491 378 114 208 398  36 435 351 242 210] 144 720\n",
      "block_15_expand\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e2b6ba8> [0]\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e2b6ba8> [0] [0]\n",
      "before: act output Tensor(\"block_15_expand/convolution:0\", shape=(?, 7, 7, 720), dtype=float32)\n",
      "after: (720,) (?, 7, 7, 720) channels_last\n",
      "[0.56242317 0.3352995  0.27429187 0.457568   0.45385888 0.43118474\n",
      " 0.30471402 0.39865354 0.6793052  0.32048666 0.5614089  0.59299934\n",
      " 0.54222614 0.3116146  0.63000345 0.4262101  0.32726502 0.46249196\n",
      " 0.5006412  0.50157976 0.9746161  0.29630333 0.4270865  0.4515911\n",
      " 0.4970696  0.3109572  0.47381684 0.45327798 0.42465279 0.38071007\n",
      " 0.40768892 0.5711776  0.34519085 0.39450762 0.44037467 0.51739025\n",
      " 0.47568092 0.2692352  0.5366344  0.6927712  0.49150735 0.29542676\n",
      " 0.4704883  0.43874666 0.7537789  0.5115697  0.38968217 0.48438993\n",
      " 0.45427725 0.61772084 0.43864697 0.5717877  0.39885402 0.48305368\n",
      " 0.30371854 0.9317427  0.31430632 0.26540676 0.5480263  0.45207363\n",
      " 0.5431355  0.2624401  0.38811448 0.6669917  0.5921511  0.5410668\n",
      " 0.45347494 0.39026532 0.3656942  0.36933422 0.33661836 0.39426035\n",
      " 0.725219   0.4448824  0.5665049  0.6379391  0.4250752  0.81104094\n",
      " 0.3489345  0.51352465 0.5951722  0.730443   0.33631876 0.7437941\n",
      " 0.53711814 0.36363205 0.3412349  0.3079786  1.0915747  0.32018176\n",
      " 0.51066077 0.40813708 0.43086636 0.5596029  0.49382013 0.756968\n",
      " 0.33643746 0.3091138  0.7990889  0.42564285 0.33709496 0.6025638\n",
      " 0.4065408  0.31348908 0.36696514 0.31164908 0.34573287 0.45000494\n",
      " 0.37972823 0.3478438  0.357935   0.4373903  0.3537937  0.4964451\n",
      " 0.3779874  0.4601656  1.2005398  0.4108416  0.6411665  0.681475\n",
      " 0.37882337 0.4057931  0.73761475 0.3379786  0.84837914 0.38563073\n",
      " 0.7420517  0.29343522 0.36041495 0.41185626 0.32432005 0.36442658\n",
      " 0.60431755 0.33277053 0.52449435 0.32019955 0.3254152  0.3675708\n",
      " 0.600531   0.3455623  0.42541867 0.34076557 0.2739855  0.41698542\n",
      " 0.45742008 0.39460915 0.3942603  0.458938   0.43270692 0.49013937\n",
      " 0.40189582 0.56141937 0.2948005  0.42768598 0.48855868 0.41732168\n",
      " 0.32160076 0.6583349  0.506443   0.742933   0.5721573  0.2149408\n",
      " 0.43682164 0.6288809  0.363763   0.4010231  0.34819934 0.55361867\n",
      " 0.3300329  0.68146956 0.34639022 0.7101825  0.4065537  0.34077847\n",
      " 0.43463755 0.47456717 0.4584121  0.46467006 0.43670607 0.5282834\n",
      " 0.45144844 0.23436531 0.3238997  0.34571862 0.8432706  0.48032224\n",
      " 0.35911992 0.3246979  0.41905764 0.4205069  0.3531836  0.38942\n",
      " 0.403634   0.33279297 0.40189838 0.32952744 0.28933612 0.61720717\n",
      " 0.3356834  0.5000199  0.41896644 0.4557553  1.5936149  0.51214606\n",
      " 0.46614942 0.37711933 0.3832649  0.19563185 0.43226695 0.38643116\n",
      " 0.41069394 0.60293406 0.67097783 0.46012136 0.3961093  0.6678378\n",
      " 0.52596873 0.79247403 0.48710293 0.45912457 0.6401318  0.28118154\n",
      " 0.35706463 0.40585738 0.27860764 0.70820457 0.30642155 0.4272518\n",
      " 0.31524295 0.23814878 0.56265414 0.3648203  0.37962875 0.435082\n",
      " 0.2501096  0.9239489  0.2920921  0.40985453 0.4792266  0.39846066\n",
      " 0.73728997 0.44645247 0.31117952 0.26198712 0.29789886 0.48969683\n",
      " 0.5710839  0.2853044  0.34659797 0.6495779  0.57827675 0.43809128\n",
      " 0.5522882  0.41808066 0.28681675 0.34986538 0.53401774 0.4595797\n",
      " 0.4629508  0.35818204 0.42857325 0.32727563 0.39571118 0.36577654\n",
      " 0.4584962  0.39053872 0.64825153 0.6152273  0.5237473  0.3227373\n",
      " 0.41537377 0.32318583 0.36264047 0.35141817 0.53671515 0.7066481\n",
      " 0.29018334 0.41611502 0.50433207 1.2839468  0.4675867  0.3508174\n",
      " 0.37726578 0.28493747 0.2682132  0.36417642 0.39071164 0.38553205\n",
      " 0.5075648  0.664365   0.50276697 0.4187258  0.35434705 0.3669477\n",
      " 0.51270205 0.4021594  0.2959847  0.315013   0.70191234 0.3033382\n",
      " 0.39617428 0.56583333 0.38422757 0.38325697 0.3534694  0.4953406\n",
      " 0.51189303 0.38529775 0.43926418 0.29435858 0.57730526 0.41985315\n",
      " 0.41268674 0.34986046 0.33333743 0.4447917  0.34610516 0.65343577\n",
      " 0.338487   0.6671678  0.46933985 0.44685945 0.28972018 0.7896475\n",
      " 0.39244857 0.43567508 0.47398624 0.5010049  0.55074    0.3499248\n",
      " 0.45055598 0.52403414 0.5046363  0.28942332 0.60704356 0.42683372\n",
      " 0.55270886 0.6072394  0.6349443  0.81874514 0.33321843 0.29892462\n",
      " 0.40962562 0.41516885 0.7336627  0.7503946  0.33611783 0.25658846\n",
      " 0.40992042 0.42937568 0.33387107 0.6669919  0.4016346  0.28360137\n",
      " 0.34502754 0.7278859  0.30215532 0.4513509  0.28542867 0.6854142\n",
      " 0.54034364 0.40031755 0.31659913 0.5135815  1.1681864  0.5908055\n",
      " 0.47342807 0.50060344 0.3389346  0.5228008  0.34328094 0.43284094\n",
      " 0.38208872 0.31471506 0.38519835 0.4675763  0.24478963 0.5437301\n",
      " 0.54029644 0.38997006 0.36283958 0.35079107 0.79650074 0.33217925\n",
      " 0.29093644 0.4489626  0.4897204  0.38852206 0.4061267  0.40633407\n",
      " 0.5008125  0.32182157 0.32000536 0.2715261  0.34577107 0.7162881\n",
      " 0.37670308 0.2743634  0.36087006 0.43997592 0.5806136  0.3282748\n",
      " 0.84032863 0.45792913 0.42842013 0.40431222 0.57941663 0.46780157\n",
      " 0.4239823  0.46450087 0.33873102 0.3541346  0.30264387 0.50826716\n",
      " 0.8313512  0.3172981  0.34363067 0.4535368  0.30645332 0.50162995\n",
      " 0.54119307 0.41190943 0.46236673 0.40892297 0.45886332 0.20715281\n",
      " 0.5498682  0.5506664  0.88475364 0.35716084 0.34651965 0.44842416\n",
      " 0.33410826 0.3729382  0.44253147 0.3287611  0.41484556 0.36763376\n",
      " 0.48543817 0.35757604 0.40383357 0.3682218  0.44853047 0.52983195\n",
      " 0.43890107 0.5264392  0.32237893 0.46091884 0.2953585  0.5481848\n",
      " 0.92579246 0.51300645 0.5408695  0.5095853  0.4521934  0.3414486\n",
      " 0.27828154 0.42013034 0.38766235 0.84210193 0.42904097 0.4206531\n",
      " 0.5265503  0.4846246  0.7102377  0.30771095 0.35404277 0.5682153\n",
      " 0.40502492 0.3511989  0.3386459  0.29564196 0.39252535 0.87138814\n",
      " 0.43725148 0.5633492  0.54429305 0.4154704  0.6559627  0.5721403\n",
      " 0.39978167 0.48489803 0.44670665 0.5726743  0.23095074 0.48082852\n",
      " 0.35349908 0.22825906 0.46858418 0.39182574 0.27852803 0.44576058\n",
      " 0.53507394 0.19846019 0.3364878  0.32768902 0.55140245 0.30990565\n",
      " 0.66570944 0.44479847 0.48970923 0.27787217 0.47495842 0.5179481\n",
      " 0.4845555  0.3197514  0.50872415 0.4837806  0.39958596 0.40456864\n",
      " 0.45728338 0.2942308  0.4057964  0.418073   0.36268282 0.34035155\n",
      " 0.5280732  0.40475014 0.3770792  0.8741014  0.4853343  0.39564905\n",
      " 0.29056522 0.33336607 0.32289556 0.49580348 0.46725932 0.26988447\n",
      " 0.8076936  0.32481235 0.2914402  0.36084795 0.4031184  0.32117197\n",
      " 0.5742687  0.42794758 0.3770317  0.37442794 0.8170504  0.3300235\n",
      " 0.22560495 0.3841436  0.41308814 0.2920366  0.38633958 0.75341445\n",
      " 0.29411295 0.491348   0.74105465 0.32763073 0.32589296 0.289348\n",
      " 0.3374244  0.80019367 0.38554835 0.6182547  0.32421628 0.30254567\n",
      " 0.28283182 0.536087   0.61916405 0.31956568 0.6461811  0.6765298\n",
      " 0.4903584  0.37470752 0.37261695 0.42343554 0.38143468 0.33912888\n",
      " 0.41039383 0.32359415 0.37337393 0.37357372 0.526048   0.5078743\n",
      " 0.42229047 0.74399877 0.3667585  0.67564565 0.3768101  0.58765286\n",
      " 0.32843357 0.6145828  0.30588472 0.6419297  0.41527137 0.636822\n",
      " 0.576239   0.548523   0.37538806 0.24444647 0.2892549  0.38071275\n",
      " 0.4406125  0.56717545 0.45792943 0.26550266 0.2867753  0.36214095\n",
      " 0.5624642  0.4892375  0.3018667  0.45680395 0.39261997 0.8840491\n",
      " 0.45767528 0.7652341  0.30837837 0.5135131  1.0462521  0.17287208\n",
      " 0.40196002 0.3772606  0.4255513  0.65615404 0.2353959  0.3001072\n",
      " 0.34468916 0.29424942 0.3624366  0.5573088  0.5317491  0.5832232\n",
      " 0.3284433  0.45992994 0.50661063 0.4733904  0.6587258  0.28531906\n",
      " 0.33389395 0.3499882  0.5336631  0.43538076 0.41330466 0.29750952\n",
      " 0.5107809  0.49111304 0.6543523  0.48017064 0.31916225 0.4238717\n",
      " 0.5634156  0.31035295 0.32388297 0.5349955  0.3421807  0.3411357\n",
      " 0.3481973  0.49184394 0.28764588 0.60675913 0.33302173 0.31070754\n",
      " 0.33218366 0.62450856 0.22329992 0.3509343  0.5521626  0.3539941\n",
      " 0.325545   0.37095982 0.35465446 0.4163545  0.95851034 1.204055\n",
      " 0.5916829  0.8117666  0.5613272  0.3444084  0.42865494 0.44791162\n",
      " 0.4850359  0.3741149  0.382504   0.57005864 0.5375435  0.38596305\n",
      " 0.23974887 0.29754925 0.51203763 0.36333463 0.52984506 0.36069134\n",
      " 0.3763656  0.47109932 0.5965636  0.5889884  0.5687364  0.38151103\n",
      " 0.6752283  0.2890184  0.49599722 0.3475831  0.32958376 0.41163832\n",
      " 0.44231978 0.7645879  0.37194967 0.36888787 0.30916625 0.48324597\n",
      " 0.49350888 0.30530542 0.550056   0.4117696  0.31015113 0.4919954\n",
      " 0.32823256 0.81428105 0.45504123 0.54517466 0.2701384  0.67699134\n",
      " 0.4653349  0.41035333 0.5779915  0.38370946 0.36966056 0.42763788]\n",
      "before add_job: block_15_expand [611 207 493 425 161 656 540 487 484 181 616 229 678 591 376 234 347 243\n",
      "  61  57 597 284  37 527 712 393 142   2 397 501 456 490 224 221 558 353\n",
      " 283 247 629 358 598 254 650 691 592 196 551 333 322 276 522 384 530 543\n",
      " 236 127 546 511 619 309 152 448  41 471 296  21 635 679 244 341 617 602\n",
      " 356 557 412 299  54   6 703 584 226 418 465  87 608  97 700 497 706 643\n",
      " 653  25 242  13 105 103  56 373 297 228 362 415 640 561 505 392  89 135\n",
      "   9 533 156 391 446 269 524 271 571 644 182 556 130 187 529 136 660 550\n",
      "  16 261 549 495 708 401 582 624 435 195 694 539 168 383 654 133 193 652] 144 720\n",
      "block_16_expand\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e2b9518> [0]\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e2b9518> [0] [0]\n",
      "before: act output Tensor(\"block_16_expand/convolution:0\", shape=(?, 7, 7, 720), dtype=float32)\n",
      "after: (720,) (?, 7, 7, 720) channels_last\n",
      "[0.87459683 1.2057381  1.2219673  0.56899774 0.8927508  1.1284335\n",
      " 0.9572793  1.4645503  1.0636405  0.8414736  0.9968327  0.7587975\n",
      " 1.063853   1.3358184  0.9689399  1.0636764  0.580676   1.097222\n",
      " 0.89841616 1.0765958  1.0992782  1.0276309  0.6185436  1.0243294\n",
      " 1.512153   0.83562106 0.99276567 1.0557227  0.633814   1.5535215\n",
      " 0.67787856 0.75064176 0.68418884 0.7668671  0.86811584 0.94599116\n",
      " 1.2264582  1.1862303  0.8456641  0.8633064  0.88608605 0.6445322\n",
      " 1.076144   1.3405277  0.87645596 1.1855385  0.9675346  0.995742\n",
      " 0.92356473 0.9312966  1.259377   1.0521178  0.7484884  0.93836594\n",
      " 0.724111   1.3446001  1.1885687  1.1422429  1.4317117  1.6254927\n",
      " 0.8862927  0.9382465  0.9516814  0.859782   0.8578443  0.7292623\n",
      " 1.0507321  0.7202465  1.0390251  1.2929202  0.83959496 1.4279746\n",
      " 1.103914   1.1620766  1.0920676  0.77941424 0.9158412  0.8960926\n",
      " 0.89783    0.91920763 1.4511207  1.1834352  0.8616623  0.7508547\n",
      " 1.1358867  1.1469301  1.0083966  0.67609763 0.8453901  1.147563\n",
      " 1.1165495  1.3475412  0.8726965  0.8003163  0.6712199  0.8132349\n",
      " 1.0855955  1.198955   1.0785335  0.57337785 1.0317625  0.8941051\n",
      " 0.9429795  1.211267   0.73249745 0.7453409  0.73689747 0.57085186\n",
      " 0.87025577 0.86149395 0.9043605  1.0517796  0.77855337 1.1715835\n",
      " 0.95109946 0.9209923  1.4044273  0.77504385 0.59901166 0.69557285\n",
      " 0.7237316  1.006777   0.8532592  1.1302928  1.2676816  0.8503477\n",
      " 0.95068824 0.8536671  0.708605   1.1972281  0.8829483  0.98043233\n",
      " 0.94443715 0.8481405  0.81120986 0.79239386 0.98515993 1.1793505\n",
      " 1.0601515  1.1313035  1.1434386  0.772397   1.2826173  1.3823224\n",
      " 0.9941963  0.67075586 1.0849608  1.3621129  1.2888768  0.79276156\n",
      " 0.9164331  0.69251597 0.90920013 0.81957453 0.9778801  0.5468267\n",
      " 0.82457817 0.72064257 0.64525586 1.3260273  1.269997   0.6971919\n",
      " 1.3925191  1.2076812  1.1334299  0.9705403  0.9784159  0.7405793\n",
      " 0.98301095 1.0018556  0.8845788  0.7520508  1.2416626  0.7224239\n",
      " 0.9931515  1.5152159  0.9356707  0.8998976  0.99716794 0.87574893\n",
      " 0.86135304 0.8122911  0.96710443 1.0497353  1.2797846  1.0597272\n",
      " 1.114969   0.7057019  0.9286883  1.2303234  0.80695176 0.9457178\n",
      " 1.0894641  0.8554748  0.88033956 0.98641574 1.0958047  1.1349742\n",
      " 0.87128145 1.0300336  1.0133632  1.2265851  1.0641872  0.53611517\n",
      " 0.68467075 0.7703605  1.0031971  0.6863861  1.2467117  1.0748072\n",
      " 1.2973852  0.89488685 1.5340512  1.207156   0.95484114 0.7639711\n",
      " 1.4805696  0.90261185 0.90381444 0.98983365 0.9430692  1.0063484\n",
      " 1.0556391  0.98435074 1.067674   0.7844812  0.60495    1.0701809\n",
      " 0.85440403 1.2103199  1.2818613  1.2367003  0.69564843 1.1043702\n",
      " 1.1113944  1.3947616  0.90455896 0.89969504 1.4368035  1.4000518\n",
      " 0.8070073  0.9651955  0.75973564 1.2676439  0.8289813  0.858672\n",
      " 1.2742078  0.70984614 1.2407813  0.6167695  1.2252691  1.3223954\n",
      " 0.892539   0.84555835 0.8514521  0.8808046  0.8809068  0.7474111\n",
      " 0.9494394  1.0096028  1.2149283  0.87582034 1.189129   0.6997519\n",
      " 1.0605983  0.8795137  1.1933273  1.0258335  0.69301057 1.0337919\n",
      " 1.1173632  1.0846186  0.9359018  1.0883356  0.8553228  1.3825171\n",
      " 0.49932975 0.9180061  1.3362669  1.0308154  1.0456438  1.1049042\n",
      " 1.4691938  1.0283303  1.06291    1.2081957  0.8255902  0.88297045\n",
      " 0.8095225  0.8738294  1.1288066  0.8924649  0.8757354  0.7194177\n",
      " 1.1453587  0.849686   1.034912   0.65198743 0.97323656 1.1518253\n",
      " 1.2611253  1.1083784  1.0029753  0.9142707  0.98980284 1.2006404\n",
      " 0.7985611  1.1718494  1.354705   1.2905333  1.4345217  1.0889566\n",
      " 0.6559083  1.1985378  1.0164734  0.92320555 1.0796522  1.1079087\n",
      " 1.168122   1.3880087  1.0778279  0.92124176 0.72313035 1.3563479\n",
      " 0.7974431  0.9249634  0.9622586  1.4862916  1.040246   0.94437796\n",
      " 1.2884781  0.86329734 0.6685007  0.7063796  1.2670574  0.8733564\n",
      " 1.1344268  0.9103651  1.0540917  0.98236775 1.282269   1.1154823\n",
      " 1.2797253  1.2445688  0.80970764 1.1825376  0.6597916  0.78999954\n",
      " 0.74613786 1.1112051  0.7786162  0.6610295  1.2429621  0.7663964\n",
      " 0.7623713  1.2908244  1.1668496  0.8144914  0.8685678  1.2266034\n",
      " 1.0552758  0.89274246 0.82074237 0.8505354  0.6907482  1.0645723\n",
      " 1.1704675  1.0256974  0.94229126 0.8496797  1.1450146  1.7933911\n",
      " 0.780654   1.4008155  0.6758338  1.1655872  1.2822418  1.1590788\n",
      " 1.0260094  0.78890514 1.1827099  0.76492417 1.0784396  0.8189741\n",
      " 1.0395669  1.3404275  0.884898   0.70829886 1.0415529  1.0210255\n",
      " 0.97519785 0.72269845 0.909195   0.7536172  1.0504721  1.3557153\n",
      " 1.2514929  0.9149944  0.84155864 1.0057039  1.0002908  0.71173704\n",
      " 1.3871108  1.028344   1.199618   0.99730325 1.0356528  0.8537801\n",
      " 0.824814   1.04298    0.9475693  0.8415351  0.6987653  1.5586444\n",
      " 1.0095923  0.7744914  1.0413594  1.4785576  1.2349652  0.85518855\n",
      " 0.8200924  0.58634585 0.90190697 0.7342775  0.8231843  1.0419383\n",
      " 0.8754711  0.9885426  1.1283541  0.7883351  0.8182877  0.6905505\n",
      " 0.97366595 0.73694867 0.5145064  1.0456116  0.8536047  0.9370222\n",
      " 1.1600064  0.7470744  1.0747182  0.99973655 0.8184983  1.0226895\n",
      " 0.85729265 0.88033354 0.96621984 0.75577736 1.0299865  1.2839514\n",
      " 0.7174417  1.3124045  1.034473   1.1370434  0.62164    0.87777185\n",
      " 0.92319614 1.2466686  0.95411336 0.9621015  1.0286224  0.83558226\n",
      " 1.0829046  1.0034436  1.0661503  0.8945029  1.4467273  1.0021721\n",
      " 1.1026982  1.0095981  0.71136713 1.3331351  1.2552933  1.3094991\n",
      " 1.3633021  1.1597112  1.2078425  1.251878   0.89321816 0.877551\n",
      " 0.9408221  0.8438697  0.89007956 1.0323608  0.8336144  0.80964214\n",
      " 0.9431684  0.6360526  0.9477851  1.1763198  1.0162919  1.0984696\n",
      " 1.4954683  0.85060906 0.88215226 1.3710223  0.8883604  0.94762367\n",
      " 1.0621381  0.96673113 0.9334668  1.2137785  0.9541024  1.0610292\n",
      " 1.2240949  0.6966556  1.1275848  0.91039926 0.98724985 0.8932156\n",
      " 1.5214429  0.92525846 0.9725847  1.4174263  1.0023204  0.92621034\n",
      " 0.8848737  0.9079525  0.92747444 0.97949713 0.93299085 0.8260024\n",
      " 1.0584933  1.0648775  1.1547801  0.7244425  0.99834156 0.98362964\n",
      " 1.2775229  0.9092478  0.81312597 1.2922525  1.0461684  1.2148404\n",
      " 1.1758895  1.1220654  0.72982645 1.1307619  0.94063526 0.87592304\n",
      " 1.4050038  1.4762317  0.6840076  0.86342907 0.9059442  0.88322526\n",
      " 1.1776507  0.6271368  0.78013486 0.9951073  0.6915619  0.72779274\n",
      " 0.8759635  0.60349834 0.7495174  1.1601486  1.0345491  1.0322926\n",
      " 0.91287506 0.5811351  1.0854317  1.2589304  0.90007854 1.2604275\n",
      " 0.6743855  0.79053694 1.106056   1.4359119  0.46984535 0.8176571\n",
      " 0.8701496  0.7671857  0.9664867  0.7167839  0.9124303  1.1761649\n",
      " 0.80969524 0.8355011  0.88736427 0.7576209  1.3549376  0.7400669\n",
      " 0.8444322  1.1874765  0.8869986  0.97080714 0.96987695 0.8207117\n",
      " 1.0959984  0.8215777  0.8856925  0.8455476  0.87363756 1.1850344\n",
      " 0.9040314  1.2538972  0.9020151  0.91645664 1.1642538  1.0511838\n",
      " 1.0580244  0.86346513 0.7790031  0.93364096 0.6665663  1.0086752\n",
      " 1.339284   0.8475882  1.3208953  0.83986247 0.963812   0.81369084\n",
      " 1.0553545  1.0423465  0.99727017 1.0456089  0.7333755  1.1697724\n",
      " 1.0955551  0.9464408  0.7480868  0.83769786 0.636631   0.8616048\n",
      " 0.7748064  1.1805706  0.7299618  1.0733819  1.0792049  1.0895619\n",
      " 1.1334373  1.0595586  0.75360215 1.0172821  1.5594083  1.0930552\n",
      " 0.76763505 1.6950991  1.007438   0.8033693  1.3603799  1.1522961\n",
      " 1.1215382  0.8666084  1.2826439  1.121003   0.9316708  0.9918324\n",
      " 0.7845913  1.1170707  1.2470139  1.0714656  0.9589801  1.2457426\n",
      " 0.95077676 0.63671124 0.99355346 1.2286681  0.757407   1.1208109\n",
      " 0.5552469  0.8661444  0.87031484 1.2447779  0.6462685  0.9656175\n",
      " 1.0682281  0.9143297  1.1074121  0.9604953  1.3058872  1.0145047\n",
      " 1.0357898  1.0967382  1.2534139  1.03278    1.2418835  0.9820638\n",
      " 0.86302114 0.9545332  1.085608   0.90264744 0.89584273 1.1678494\n",
      " 1.1413071  0.9011133  0.7149835  0.90846837 0.89331466 1.0622752\n",
      " 1.1735274  0.99783975 1.0631593  0.67328125 0.7034429  1.0763403\n",
      " 1.2849635  1.4822117  0.8549678  0.9586392  0.9578619  0.9881488\n",
      " 0.9648824  1.0594548  0.7700161  1.4349326  1.1210197  1.8190947\n",
      " 1.2789664  1.0433725  1.0183129  0.90521    0.7378722  0.8562673\n",
      " 0.8199374  1.0731375  1.0434515  0.7701483  0.9377893  1.3253114 ]\n",
      "before add_job: block_16_expand [568 276 434 203 155 660   3 107  99  16 559 421 118 553 226 249  22 454\n",
      " 547  28 487 622 655  41 158 664 297 312 346 351 604 332 145  94 693 564\n",
      " 374  87  30 542  32 204 207 431 364 550 151 268 119 232 505 161 412 263\n",
      " 694 187 333 387 128 247 470 401 686 573 450 293  67 157 173 391 322 120\n",
      "  54 525 551  65 536 626 104 616 423 106 433 712 581 167 105 348 439 257\n",
      " 620  52 554  31  83 171 632 393 447 658 579  11 242 354 215 381 353  33\n",
      " 571 636 704 717 205 141 415 624 117 112 350 602  75 548 372 225 648 429\n",
      " 379 347 565 135 149 324 306  93 639 190 240 288 485 576 344 134 181 530] 144 720\n",
      "Conv_1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e2b9e10> [0]\n",
      "layer: <keras.layers.convolutional.Conv2D object at 0x7f100e2b9e10> [0] [0]\n",
      "before: act output Tensor(\"Conv_1/convolution:0\", shape=(?, 7, 7, 960), dtype=float32)\n",
      "after: (960,) (?, 7, 7, 960) channels_last\n",
      "[0.7657327  1.038944   1.0249546  0.98666954 1.0802397  0.8803545\n",
      " 1.1212177  1.1182969  1.055265   0.95173967 0.91472816 0.8618819\n",
      " 0.9293218  0.9129016  0.80456036 1.1281677  1.1340628  0.92047113\n",
      " 0.82515043 0.9817794  1.1517725  0.8512178  1.0572939  1.0201951\n",
      " 0.96806073 1.149495   1.2095333  0.8771857  0.9241119  1.010375\n",
      " 1.2964556  1.1267718  1.0218756  0.973327   1.08141    0.88886577\n",
      " 1.0996087  0.78259814 0.9068837  0.9855405  1.2028946  0.8150992\n",
      " 1.0270842  1.0502174  1.1093818  0.75699764 0.9790864  1.0612229\n",
      " 0.9302621  1.3409382  1.2849454  0.9859219  1.0060604  1.1341585\n",
      " 0.95124143 0.927297   1.0470529  1.0356168  1.1124688  0.8207586\n",
      " 0.9930183  0.96992433 0.8904972  1.2869713  1.0716861  0.90737\n",
      " 0.95073116 0.87207097 0.86512905 1.00601    0.8685169  0.97312343\n",
      " 1.1901221  0.8739537  0.9756115  0.92527056 0.9455586  1.1278628\n",
      " 1.106887   0.90620375 1.3565526  0.9927246  1.0186323  1.0342605\n",
      " 0.8467642  0.959362   1.0227185  1.123109   1.1036434  1.2412852\n",
      " 0.95977294 1.078143   0.89664614 0.9930422  1.0228386  0.93251705\n",
      " 0.94779384 1.130387   1.0160463  0.869806   0.87351984 0.95401025\n",
      " 0.7909671  1.148659   0.94756365 0.8930076  1.2014201  0.7387265\n",
      " 0.88396114 0.9605852  0.84588736 1.154021   0.959219   1.0206677\n",
      " 1.1221775  0.8593971  0.9268838  0.9603525  1.2033567  0.9573329\n",
      " 1.2474091  1.0347303  0.9175013  1.1253443  0.9014005  0.97770023\n",
      " 1.1806813  1.0709515  0.8225587  1.2127469  1.0592947  0.8819761\n",
      " 0.99605864 1.0072813  0.79567826 1.0159382  0.810866   1.0493252\n",
      " 0.9436689  0.7952541  0.89334714 1.002645   0.9435773  1.0504053\n",
      " 1.0355594  1.2230452  1.1447523  1.0918804  0.9714633  1.0064898\n",
      " 0.94432193 1.034551   1.0145739  0.908939   1.0827565  0.9962754\n",
      " 0.7627891  0.8910361  0.95315    0.78112435 0.9733968  1.1120249\n",
      " 0.84021306 0.99931014 1.0094848  1.076755   1.0855144  1.0984464\n",
      " 1.0399053  1.2661102  1.0054386  1.1358587  0.86598426 1.1729242\n",
      " 1.1545243  1.0216657  0.9231223  1.0426165  0.8551108  0.90493053\n",
      " 0.9781354  1.1538929  0.91861403 0.8714044  0.8206026  0.9927515\n",
      " 1.1303343  0.8421325  0.9477943  0.83015823 0.8444551  0.77437556\n",
      " 1.066689   1.0684388  0.89374197 1.1305007  1.1948695  0.8597058\n",
      " 0.9447298  0.90989774 0.9919173  1.0239981  0.9526717  1.013909\n",
      " 0.90592813 0.8860835  1.0501405  1.1350518  1.0525241  1.2319629\n",
      " 1.2991532  0.9603504  0.9871871  1.2470453  0.9058284  1.0432367\n",
      " 1.0541124  0.81673455 0.92156625 0.94973624 1.0898724  1.0593082\n",
      " 1.1511986  0.9493539  0.94239926 1.2886432  1.0352522  0.9382465\n",
      " 0.9939955  1.1990215  1.0862081  0.86182094 0.950197   1.0603982\n",
      " 0.8455643  0.90402603 0.9248852  1.1261573  0.92813456 1.1176327\n",
      " 0.9866225  1.2089361  0.88264835 1.1473337  1.085614   0.93469936\n",
      " 0.9919137  0.91873556 0.9553723  0.9979473  1.0462317  1.0509746\n",
      " 0.8248922  1.0605662  0.88565475 1.0058098  0.8796023  0.97769463\n",
      " 0.9718653  0.944237   1.0861157  1.0721617  1.091949   0.88959086\n",
      " 0.98110694 0.92449707 0.94012266 0.9223516  1.1821198  1.0163034\n",
      " 0.9862255  1.0620943  0.8751246  1.045809   0.76233435 1.1651508\n",
      " 0.95773304 1.1258653  1.0166272  0.9117764  0.729028   0.88453466\n",
      " 0.93909794 0.85743785 0.91580176 0.99958247 1.0073042  0.9542367\n",
      " 1.1437777  1.2658443  0.8761188  0.9794111  1.024528   1.0877498\n",
      " 0.832878   0.9714953  1.019022   0.9621326  0.97702825 0.90051246\n",
      " 1.137163   0.8312236  1.0217274  0.860476   0.8907609  0.950334\n",
      " 0.79784983 0.82401246 0.9426393  0.9853076  1.0329664  1.0124036\n",
      " 1.0939925  1.0941267  0.96576226 0.89767647 1.1915065  0.9005424\n",
      " 0.8211368  0.86788446 0.9543133  1.0763862  1.1420282  0.9948379\n",
      " 1.1312985  1.3945881  0.97119504 0.92901486 0.9897512  0.84522307\n",
      " 1.0421295  0.8014634  0.9938839  1.1206971  0.97211266 0.8461649\n",
      " 1.1528034  1.0455303  0.80519557 1.031243   1.0147882  1.0472413\n",
      " 0.96641326 0.90418136 0.8811103  0.99212754 0.7989024  0.924736\n",
      " 1.1563684  1.2312422  1.2323822  0.9717776  0.9188078  0.98923826\n",
      " 0.87175864 1.013997   0.9749249  0.9663724  1.0004138  1.0733845\n",
      " 0.9643496  1.051414   1.1296074  1.081194   0.95898837 1.1231058\n",
      " 0.79700136 1.0820062  1.0490999  0.7797229  0.88622946 0.98084486\n",
      " 0.9612403  1.1316121  1.0119848  1.1594535  1.0148791  0.95570666\n",
      " 0.83439124 1.1519164  1.1285106  0.9271919  1.0333306  1.261911\n",
      " 0.9117879  0.7764752  0.95623684 0.9038636  1.1626898  0.8478879\n",
      " 0.8577969  0.985442   1.1376367  1.0313019  1.0439663  0.9304075\n",
      " 1.0269854  1.1177455  0.89661604 1.3002857  1.4084132  0.88141865\n",
      " 1.0590771  0.77084625 0.88516045 0.9003831  0.94738114 1.2362908\n",
      " 0.8714202  0.8524066  1.130387   1.1023743  0.75323164 1.0459394\n",
      " 1.017833   0.8967078  1.0356793  0.89885384 0.977195   0.948052\n",
      " 1.0310911  0.84682876 0.9454689  0.9760482  1.169672   0.9105568\n",
      " 1.0972152  1.0530196  1.110384   0.9934623  1.0708866  0.87999094\n",
      " 1.0431587  1.1000247  1.178412   0.89904964 0.83993006 1.0875326\n",
      " 0.91549027 0.8719006  0.8818333  1.2167056  1.1748186  0.8064252\n",
      " 1.1093292  1.0217382  1.0261759  1.0512794  1.2033143  0.82903564\n",
      " 0.9666765  1.0874075  0.7882853  0.9891369  0.8399449  0.80200654\n",
      " 0.9604061  1.2054564  0.83747673 1.2962449  0.88435614 1.0287192\n",
      " 1.1239033  1.0729176  1.193567   1.201849   0.909069   0.96090746\n",
      " 0.9011237  0.9079917  1.0220625  0.9681001  1.0723537  1.1304181\n",
      " 0.8889527  0.8769305  0.96021044 0.9911756  0.9145706  0.9652268\n",
      " 1.0428153  1.0630063  1.1281807  0.9484722  0.91878754 1.0028362\n",
      " 0.9196876  1.0155222  1.082192   0.971748   1.0050236  1.3005762\n",
      " 1.0589551  1.0335742  1.1930552  1.1512246  0.8482514  0.9565942\n",
      " 1.2664647  0.8435358  0.8499141  1.1232914  0.9323991  1.0165769\n",
      " 0.9395329  0.8559211  1.023254   0.73569745 1.0955863  0.97044766\n",
      " 1.1823623  1.0099026  1.0330337  1.4875739  0.79925025 0.97821623\n",
      " 0.7656222  0.97942406 1.1353807  0.9045194  0.8916807  0.91427267\n",
      " 0.8918119  0.95952654 0.91825944 0.9728196  1.138832   1.0104377\n",
      " 0.97684246 1.0587499  0.95951045 1.036484   0.8230419  0.92762494\n",
      " 0.94882005 0.9151633  0.914558   1.0413139  0.892707   1.0053458\n",
      " 1.0831267  0.9860896  0.74662054 0.9558571  0.9794101  1.2675322\n",
      " 0.81125253 1.0217136  0.9834492  1.0884179  1.09343    1.2219596\n",
      " 1.0457174  0.881451   1.0095507  0.9259389  0.932822   0.9288908\n",
      " 0.9490246  0.84178203 1.1434722  0.8280362  1.2114354  0.9400751\n",
      " 1.1500651  0.99127084 1.0578752  1.0030328  0.9156468  0.9890903\n",
      " 1.2168708  1.1111515  1.0171549  0.8315116  1.0621768  0.9068056\n",
      " 0.9138319  0.895961   1.3306067  1.1701603  1.1071181  0.8514391\n",
      " 0.96290815 0.90607214 1.0657088  1.0417198  0.9287398  1.0553792\n",
      " 0.96382785 1.0289583  0.9889042  0.9542819  1.0054041  1.0625819\n",
      " 0.849956   0.77294225 1.0799687  1.0292293  0.98698276 0.91024053\n",
      " 0.8161172  0.94439805 0.924936   1.1054425  1.0011175  1.062222\n",
      " 1.011311   0.9058452  0.9393153  1.0198677  1.2942868  1.0288254\n",
      " 1.0845716  0.9100143  0.9780608  0.8096522  1.0763803  0.8707225\n",
      " 0.9686415  1.1425115  0.8171262  1.0018711  0.87793857 0.7645568\n",
      " 1.0348194  0.9194757  0.89849925 1.1017662  0.8193835  0.70561236\n",
      " 1.2453517  0.88367265 1.0449301  0.89819777 0.94718957 0.98937184\n",
      " 0.9012269  1.179344   1.1597192  1.0183461  1.0572414  1.0789804\n",
      " 1.0592803  1.1685061  1.1520973  1.0607082  1.1329837  0.8922646\n",
      " 1.0033015  1.3162119  0.894077   0.93335474 0.9545626  0.79590905\n",
      " 1.1592603  0.9813457  0.66407835 1.0204179  1.0534366  0.8076477\n",
      " 1.1332957  0.88649946 0.89605236 1.1327891  0.96731645 1.0231522\n",
      " 1.0885829  0.8716042  0.84888816 0.90832627 1.1031151  0.95461774\n",
      " 0.9619497  1.1088566  1.0291497  0.96429276 0.9453619  1.12985\n",
      " 1.0396994  1.0227402  0.9541564  1.0832479  1.0844027  1.0378592\n",
      " 0.94377786 1.2712625  1.0723057  0.8529098  0.936622   1.1139418\n",
      " 1.2317252  0.8993022  0.969448   0.94287527 0.9249183  1.2088059\n",
      " 1.0401515  1.3453474  0.84007156 1.0129447  0.955757   0.88175\n",
      " 0.9398054  0.8502192  0.9425678  1.2252365  0.78582186 1.040113\n",
      " 1.2376562  1.1279739  1.0413163  0.97844905 0.91927516 1.0098343\n",
      " 1.2612921  1.0982567  1.1227137  0.86574215 0.77909243 0.9339346\n",
      " 0.93917775 0.9852277  0.9997571  1.1422734  0.8749127  0.8667624\n",
      " 0.9581538  1.4672476  0.89225215 1.035988   0.94753826 1.0918022\n",
      " 0.8944412  1.1392146  1.1525875  0.9756668  0.87580365 1.1237385\n",
      " 0.80963516 1.1836629  1.1438922  1.1500797  0.8796402  1.1929448\n",
      " 0.8806013  0.99064523 1.0432488  1.0069941  0.9530872  1.0912364\n",
      " 0.912065   0.94495994 0.8550136  0.83039457 0.97550815 0.86664414\n",
      " 0.8618682  1.0965365  1.073158   1.0350666  0.93520194 0.93119705\n",
      " 1.169945   1.0298861  0.896459   0.96031725 1.1807815  1.0559534\n",
      " 1.0218405  0.9423417  0.87303    0.8925772  1.0348547  1.0988095\n",
      " 1.0214962  1.2675198  0.8712749  0.9178602  1.1680825  0.8573575\n",
      " 0.9102203  0.87900025 0.9352725  0.92041874 0.9429922  0.99438477\n",
      " 0.88356054 0.97285587 0.84895784 0.9529294  1.1705904  1.1839647\n",
      " 1.0048442  1.1193352  0.8777893  0.92623186 1.0216023  0.89162576\n",
      " 1.0870578  0.8341737  1.3881576  0.9678876  1.2269692  0.8045206\n",
      " 1.0239656  0.9504131  0.92366046 0.87434363 1.0775896  1.2237563\n",
      " 0.9577622  0.6964484  0.8916315  0.86737335 0.89606667 0.972096\n",
      " 0.8829674  1.0707937  0.8744563  1.0654566  0.8777832  1.0411514\n",
      " 0.91351646 0.9972278  1.0315686  0.94948965 0.8232664  0.954889\n",
      " 1.13537    1.0795964  1.0339121  0.9000515  0.75378233 0.9818423\n",
      " 1.1556805  1.1213174  0.9017148  1.0117012  0.8240286  1.0922313\n",
      " 0.9387703  0.9515825  1.0764159  1.0571871  0.8932291  1.0292432\n",
      " 0.9353374  1.296799   1.0343018  1.0964248  0.8263762  0.9052034\n",
      " 0.9537538  0.83077973 1.2621208  1.0906951  1.0082632  0.89795977\n",
      " 1.3548713  0.8941296  0.90717775 1.1984284  0.9630437  0.9676985\n",
      " 1.1238366  0.89595705 1.2635723  0.9773291  0.8562156  0.93460417\n",
      " 1.1015933  1.043334   1.0486693  0.9841263  1.0733798  0.83500195\n",
      " 0.79003155 1.1577506  1.0312097  1.1045012  1.1670496  0.9917548\n",
      " 0.7691832  0.8051868  0.89257747 1.1017957  0.8916736  0.88622326\n",
      " 0.90963846 1.0923972  0.9636809  0.9448712  0.8709703  0.8834147\n",
      " 1.1138294  1.0998942  0.9554323  1.0522387  0.8855877  1.0567689\n",
      " 0.9902674  0.8631806  1.0452824  0.96747977 0.99394226 0.9213315\n",
      " 1.0099965  0.95449734 1.2875465  0.9128205  1.1700342  0.97292256\n",
      " 1.0173861  0.86875415 0.8785745  1.3695527  1.4189736  1.0725054\n",
      " 0.9837928  1.167723   1.1562679  1.0520015  0.8377694  1.1032798\n",
      " 1.0368615  0.9575375  1.0066282  0.89485645 1.0203023  1.1075661\n",
      " 0.8449449  1.1809142  1.0317804  1.0523409  0.96021587 0.94287586\n",
      " 1.0729451  1.1396525  0.99187547 1.1063235  1.1238241  0.880639\n",
      " 1.1573073  0.94628936 1.0116521  0.90324926 0.9850101  0.777843\n",
      " 1.1733736  1.0145178  0.69889516 0.9999411  0.829298   0.9600222\n",
      " 0.9347521  1.339743   1.002972   0.82120013 0.9618338  0.95224404]\n",
      "before add_job: Conv_1 [656 811 950 629 280 507 107 542 412 832  45 274 156 623 516   0 882 403\n",
      " 595 191 385 947 718 369 159  37 706 452 876 102 139 134 653 366 306 346\n",
      " 514 331 455 803  14 883 338 443 659 738 615 136 546  41 600 217 620 628\n",
      " 184  59 318 957 128 532 826 307 838 252  18 850 561 449 952 189 753 853\n",
      " 301 573 294 799 378 875 458 922 436 454 698 162 559 187 499 190 930 329\n",
      " 234 110 335  84 421 389 496 668 788 500 594 703  21 581 409 687 752 178\n",
      " 505 868 779 283 390 115 197 303 231 756  11 901  68 717 172 755 725 813\n",
      " 319  70 913  99 617 892 776 183 408 667 354 439  67 770 100  73 807 818\n",
      " 724 272 736 290 475  27 820 794 622 914 781 256 742 431   5 744 941 344\n",
      " 401 553 701 440 131 242 816 893 786 631 108 460 281 404 898 254 205 887\n",
      " 370 661  35 474 263  62 304 157 797 812 886 520] 192 960\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 112, 72) (8,) [67  3 50 33 41 20 62 65]\n",
      "Deleting 8/72 channels from layer: block_1_expand\n",
      "(1, 1, 72)\n",
      "(3, 3, 72, 1)\n",
      "(3, 3, 72, 1) [3, 3, -1, 1]\n",
      "(3, 3, 64, 1)\n",
      "(56, 56, 112) (16,) [ 93  90  48 109  54  18   3  36  77  41  76  55  35  52  20  71]\n",
      "Deleting 16/112 channels from layer: block_2_expand\n",
      "(1, 1, 112)\n",
      "(3, 3, 112, 1)\n",
      "(3, 3, 112, 1) [3, 3, -1, 1]\n",
      "(3, 3, 96, 1)\n",
      "(56, 56, 112) (16,) [ 16   1  75  77  48  91   7  28 102  93 105  82  69  42  23  57]\n",
      "Deleting 16/112 channels from layer: block_3_expand\n",
      "(1, 1, 112)\n",
      "(3, 3, 112, 1)\n",
      "(3, 3, 112, 1) [3, 3, -1, 1]\n",
      "(3, 3, 96, 1)\n",
      "(28, 28, 144) (24,) [128  75  98  68 100  80 126 115  12 109  26 137  89  66  38  36  94  28\n",
      " 102  49 101  93  40 131]\n",
      "Deleting 24/144 channels from layer: block_4_expand\n",
      "(1, 1, 144)\n",
      "(3, 3, 144, 1)\n",
      "(3, 3, 144, 1) [3, 3, -1, 1]\n",
      "(3, 3, 120, 1)\n",
      "(28, 28, 144) (24,) [ 26   1   5  41 143  45  49   3 137  62 136  99 110  38  23  40  87  85\n",
      " 141 114 132 113  73  21]\n",
      "Deleting 24/144 channels from layer: block_5_expand\n",
      "(1, 1, 144)\n",
      "(3, 3, 144, 1)\n",
      "(3, 3, 144, 1) [3, 3, -1, 1]\n",
      "(3, 3, 120, 1)\n",
      "(28, 28, 144) (24,) [125  19   8 131  10  49 110 112 119  28 101 115 102  20  27  59  60  32\n",
      "  72 129   2  58 141 104]\n",
      "Deleting 24/144 channels from layer: block_6_expand\n",
      "(1, 1, 144)\n",
      "(3, 3, 144, 1)\n",
      "(3, 3, 144, 1) [3, 3, -1, 1]\n",
      "(3, 3, 120, 1)\n",
      "(14, 14, 288) (56,) [201  95  90  18  32  24 106 105 196 108  62 235 110 261  84 255  49 118\n",
      "  25 266 157  88  35  85  67  80  76 109  78 186  33 152 268 164 182 248\n",
      " 249 121  66  21 149 113 136  97 274 275  12 215  16 163 245 278 273 263\n",
      " 265 154]\n",
      "Deleting 56/288 channels from layer: block_7_expand\n",
      "(1, 1, 288)\n",
      "(3, 3, 288, 1)\n",
      "(3, 3, 288, 1) [3, 3, -1, 1]\n",
      "(3, 3, 232, 1)\n",
      "(14, 14, 288) (56,) [ 89 101  97 253 115 149  65 225 217 278  22 127 114 146  23 173 133 143\n",
      " 179 176 233  58  63 269 205   5 220 223  46  44 120 121 235 265   8  90\n",
      "  11 122  62  91  51 268 287 259  39 103 262 112  79 186 107 207  55 244\n",
      "  26 234]\n",
      "Deleting 56/288 channels from layer: block_8_expand\n",
      "(1, 1, 288)\n",
      "(3, 3, 288, 1)\n",
      "(3, 3, 288, 1) [3, 3, -1, 1]\n",
      "(3, 3, 232, 1)\n",
      "(14, 14, 288) (56,) [103 126  92 119 225 213 149  13  43 277 191 244 219 240 108 198  11  69\n",
      " 207  45  49 128 283  84 132  38 287 152  96   3  81  54 220 123  35 112\n",
      " 264  22 138 245 174 114 199  21 194  27 239 235 270 242 105 141  16 273\n",
      " 137 148]\n",
      "Deleting 56/288 channels from layer: block_9_expand\n",
      "(1, 1, 288)\n",
      "(3, 3, 288, 1)\n",
      "(3, 3, 288, 1) [3, 3, -1, 1]\n",
      "(3, 3, 232, 1)\n",
      "(14, 14, 288) (56,) [ 14 268 214 157 145 218  84 230 208 140 170 183 171 153  26 287 109  95\n",
      " 135  80  82  78 206 231   6  81 234 235 164 219 125 240 283 257 200  83\n",
      " 167 285 124 205 217 112  76  96 120 168  55   2 191  45  10  66  59  91\n",
      " 128  39]\n",
      "Deleting 56/288 channels from layer: block_10_expand\n",
      "(1, 1, 288)\n",
      "(3, 3, 288, 1)\n",
      "(3, 3, 288, 1) [3, 3, -1, 1]\n",
      "(3, 3, 232, 1)\n",
      "(14, 14, 432) (80,) [ 50  27 185  42 166 334 361 172  12 153 414 134 314 236  41 249 374 402\n",
      " 258 194   5 367 158 409  20 323 382  38 103  94 155 108  60 378 174 345\n",
      " 251 302  11  37 173 355 151 349 217   8 159 116   4  21 356   7 398 254\n",
      " 426 420  16 312  69  73 366 160 243 248 271 342 136 139 146 179  88 206\n",
      " 180  96  62 211 297 102 138 336]\n",
      "Deleting 80/432 channels from layer: block_11_expand\n",
      "(1, 1, 432)\n",
      "(3, 3, 432, 1)\n",
      "(3, 3, 432, 1) [3, 3, -1, 1]\n",
      "(3, 3, 352, 1)\n",
      "(14, 14, 432) (80,) [ 53  64 129  25 163   4 107 123 277 168 330 354 395 237 109 340 335  69\n",
      " 267 152 158 135 103 106 292 244 362 403 305 192 336 227 429 128 195 329\n",
      " 116 117  81 311 272 324 110  14  86 242  41 290 174 325  51  59  93 279\n",
      "  57 262 367 376 419  85 363 372 306 430 154 274 302 365 173 161 228 217\n",
      " 427 253 318 280 102 101  18 381]\n",
      "Deleting 80/432 channels from layer: block_12_expand\n",
      "(1, 1, 432)\n",
      "(3, 3, 432, 1)\n",
      "(3, 3, 432, 1) [3, 3, -1, 1]\n",
      "(3, 3, 352, 1)\n",
      "(14, 14, 432) (80,) [429 216 347  80 294 356 423 142 271 191 134  27 227 365 174 395 228  57\n",
      " 107 289 147 257 101 104 315 339 116  49 268 158  91  21 199 368  22 421\n",
      " 247 197 175 389 293 401 259 113 302 179 221 215  23  67  37 263 235  71\n",
      " 252 426 172  92 340  87 300 413  51 274 334 405  10 250  77 203 282 422\n",
      " 124 212 131 394   1  14 348 305]\n",
      "Deleting 80/432 channels from layer: block_13_expand\n",
      "(1, 1, 432)\n",
      "(3, 3, 432, 1)\n",
      "(3, 3, 432, 1) [3, 3, -1, 1]\n",
      "(3, 3, 352, 1)\n",
      "(7, 7, 720) (144,) [286 256 358  97 347  73  75 598 160 617 407 684 152  82 632 438  29 591\n",
      " 453 699 303  47  93  38 112 585 275 244 329  16 508 273 654 393  31 383\n",
      " 354 512   0 513  87 279 387 266 562 318 667 130 514 456 472 361 706 416\n",
      " 108 328 634 144 111 444 316 200 542 496 167 394 119 626 697 470 482 164\n",
      " 519 561 653 212 705 121 533 138 481 679  81   7 691 445  25 582 133 565\n",
      " 710 694 478 269  77  94   4 345 181 604 161  53 614 312 665 115 474 267\n",
      " 335 238 583  84 196 199 330 616  28 414 372 696 156 717 427 247 709 468\n",
      " 412 422  63 421 131 525 281  98 491 378 114 208 398  36 435 351 242 210]\n",
      "Deleting 144/720 channels from layer: block_14_expand\n",
      "(1, 1, 720)\n",
      "(3, 3, 720, 1)\n",
      "(3, 3, 720, 1) [3, 3, -1, 1]\n",
      "(3, 3, 576, 1)\n",
      "(7, 7, 720) (144,) [611 207 493 425 161 656 540 487 484 181 616 229 678 591 376 234 347 243\n",
      "  61  57 597 284  37 527 712 393 142   2 397 501 456 490 224 221 558 353\n",
      " 283 247 629 358 598 254 650 691 592 196 551 333 322 276 522 384 530 543\n",
      " 236 127 546 511 619 309 152 448  41 471 296  21 635 679 244 341 617 602\n",
      " 356 557 412 299  54   6 703 584 226 418 465  87 608  97 700 497 706 643\n",
      " 653  25 242  13 105 103  56 373 297 228 362 415 640 561 505 392  89 135\n",
      "   9 533 156 391 446 269 524 271 571 644 182 556 130 187 529 136 660 550\n",
      "  16 261 549 495 708 401 582 624 435 195 694 539 168 383 654 133 193 652]\n",
      "Deleting 144/720 channels from layer: block_15_expand\n",
      "(1, 1, 720)\n",
      "(3, 3, 720, 1)\n",
      "(3, 3, 720, 1) [3, 3, -1, 1]\n",
      "(3, 3, 576, 1)\n",
      "(7, 7, 720) (144,) [568 276 434 203 155 660   3 107  99  16 559 421 118 553 226 249  22 454\n",
      " 547  28 487 622 655  41 158 664 297 312 346 351 604 332 145  94 693 564\n",
      " 374  87  30 542  32 204 207 431 364 550 151 268 119 232 505 161 412 263\n",
      " 694 187 333 387 128 247 470 401 686 573 450 293  67 157 173 391 322 120\n",
      "  54 525 551  65 536 626 104 616 423 106 433 712 581 167 105 348 439 257\n",
      " 620  52 554  31  83 171 632 393 447 658 579  11 242 354 215 381 353  33\n",
      " 571 636 704 717 205 141 415 624 117 112 350 602  75 548 372 225 648 429\n",
      " 379 347 565 135 149 324 306  93 639 190 240 288 485 576 344 134 181 530]\n",
      "Deleting 144/720 channels from layer: block_16_expand\n",
      "(1, 1, 720)\n",
      "(3, 3, 720, 1)\n",
      "(3, 3, 720, 1) [3, 3, -1, 1]\n",
      "(3, 3, 576, 1)\n",
      "(7, 7, 960) (192,) [656 811 950 629 280 507 107 542 412 832  45 274 156 623 516   0 882 403\n",
      " 595 191 385 947 718 369 159  37 706 452 876 102 139 134 653 366 306 346\n",
      " 514 331 455 803  14 883 338 443 659 738 615 136 546  41 600 217 620 628\n",
      " 184  59 318 957 128 532 826 307 838 252  18 850 561 449 952 189 753 853\n",
      " 301 573 294 799 378 875 458 922 436 454 698 162 559 187 499 190 930 329\n",
      " 234 110 335  84 421 389 496 668 788 500 594 703  21 581 409 687 752 178\n",
      " 505 868 779 283 390 115 197 303 231 756  11 901  68 717 172 755 725 813\n",
      " 319  70 913  99 617 892 776 183 408 667 354 439  67 770 100  73 807 818\n",
      " 724 272 736 290 475  27 820 794 622 914 781 256 742 431   5 744 941 344\n",
      " 401 553 701 440 131 242 816 893 786 631 108 460 281 404 898 254 205 887\n",
      " 370 661  35 474 263  62 304 157 797 812 886 520]\n",
      "Deleting 192/960 channels from layer: Conv_1\n"
     ]
    }
   ],
   "source": [
    "percent_pruned=20\n",
    "print('pruning up to ', str(percent_pruned),'% of the original model weights')\n",
    "reduced_model_new = prune_model_by_layer(reduced_model, percent_pruned)\n",
    "\n",
    "percent_pruned+=25\n",
    "checkpoint_name = ('mobilenet_v2_1.0_pruning_grad_' + str(percent_pruned) + 'percent')\n",
    "reduced_model_new.compile(optimizer=SGD(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy',top_k_categorical_accuracy])\n",
    "reduced_model_new.save(checkpoint_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv1\n",
      "block_1_expand\n",
      "before add_job: block_1_expand [70, 59, 77, 80, 47, 118, 113, 49, 87, 100, 3, 61, 130, 142, 124, 37, 44, 30, 62, 36, 103, 134, 109, 7, 15, 65, 66, 107, 98, 128, 78, 115] 32 144\n",
      "block_2_expand\n",
      "before add_job: block_2_expand [72, 95, 106, 128, 116, 137, 62, 159, 177, 43, 144, 40, 53, 141, 109, 152, 21, 42, 131, 114, 87, 113, 17, 75, 171, 22, 174, 63, 30, 167, 33, 77, 112, 7, 12, 11, 169, 47, 10, 146, 183, 180, 83, 175, 67, 81, 34, 127] 48 192\n",
      "block_3_expand\n",
      "before add_job: block_3_expand [188, 104, 150, 3, 160, 9, 34, 182, 121, 81, 30, 166, 163, 44, 168, 110, 137, 19, 0, 41, 157, 146, 64, 82, 172, 136, 158, 87, 93, 91, 10, 58, 178, 75, 112, 134, 145, 14, 151, 39, 119, 65, 21, 124, 190, 170, 86, 2] 48 192\n",
      "block_4_expand\n",
      "before add_job: block_4_expand [3, 162, 120, 187, 176, 177, 202, 242, 19, 160, 83, 124, 129, 30, 17, 193, 67, 0, 94, 218, 47, 240, 194, 280, 122, 80, 251, 272, 63, 107, 238, 93, 12, 171, 32, 118, 245, 268, 27, 7, 87, 241, 127, 130, 98, 57, 72, 278, 89, 6, 207, 76, 84, 228, 203, 163, 135, 271, 49, 106, 208, 81, 119, 274] 64 288\n",
      "block_5_expand\n",
      "before add_job: block_5_expand [107, 88, 198, 278, 191, 14, 219, 238, 19, 32, 250, 73, 235, 35, 69, 231, 176, 29, 108, 272, 284, 58, 41, 10, 265, 229, 120, 210, 46, 37, 52, 279, 125, 134, 71, 94, 121, 86, 70, 122, 175, 263, 146, 100, 8, 112, 275, 226, 128, 165, 15, 56, 264, 138, 187, 55, 42, 247, 77, 62, 90, 221, 105, 143] 64 288\n",
      "block_6_expand\n",
      "before add_job: block_6_expand [184, 44, 45, 153, 87, 277, 80, 123, 159, 183, 278, 85, 147, 224, 177, 11, 157, 145, 261, 84, 89, 113, 106, 241, 132, 268, 219, 223, 125, 88, 8, 12, 264, 126, 206, 66, 77, 40, 71, 58, 29, 237, 170, 67, 117, 116, 53, 60, 253, 282, 285, 22, 37, 155, 225, 134, 135, 142, 70, 120, 96, 194, 17, 212] 64 288\n",
      "block_7_expand\n",
      "before add_job: block_7_expand [159, 440, 287, 185, 183, 504, 324, 524, 422, 254, 326, 269, 265, 356, 414, 278, 225, 49, 343, 337, 346, 120, 262, 180, 44, 407, 514, 66, 125, 416, 319, 390, 80, 394, 275, 204, 190, 95, 8, 92, 456, 438, 497, 2, 149, 193, 424, 27, 389, 418, 83, 461, 522, 472, 510, 226, 387, 157, 11, 154, 506, 253, 129, 333, 508, 73, 485, 452, 316, 224, 392, 279, 272, 105, 341, 162, 312, 84, 286, 475, 482, 282, 86, 207, 307, 437, 222, 520, 250, 277, 232, 172, 126, 384, 54, 339, 85, 239, 523, 471, 393, 385, 382, 502, 371, 124, 217, 266, 25, 498, 87, 169, 189, 102, 455, 473, 350, 259, 77, 481, 81, 12, 67, 235, 135, 431, 209, 175] 128 528\n",
      "block_8_expand\n",
      "before add_job: block_8_expand [503, 58, 239, 514, 252, 139, 366, 272, 141, 378, 344, 49, 189, 326, 351, 106, 458, 321, 479, 233, 164, 119, 120, 276, 148, 490, 243, 438, 6, 524, 184, 50, 304, 67, 102, 405, 484, 349, 468, 5, 196, 359, 431, 388, 18, 274, 4, 279, 232, 171, 176, 28, 486, 223, 21, 320, 260, 76, 31, 9, 459, 420, 105, 117, 240, 518, 158, 116, 381, 185, 526, 294, 40, 42, 356, 411, 110, 101, 399, 54, 521, 363, 142, 134, 220, 338, 443, 210, 433, 209, 473, 350, 483, 225, 24, 427, 324, 327, 293, 437, 416, 376, 59, 81, 374, 404, 66, 8, 323, 104, 166, 79, 135, 309, 396, 314, 154, 500, 474, 499, 219, 367, 7, 508, 291, 341, 268, 211] 128 528\n",
      "block_9_expand\n",
      "before add_job: block_9_expand [97, 329, 149, 371, 242, 0, 163, 172, 372, 282, 302, 21, 280, 213, 142, 224, 204, 65, 130, 412, 45, 27, 356, 118, 207, 237, 276, 343, 190, 452, 424, 480, 236, 373, 214, 403, 345, 255, 500, 498, 100, 260, 341, 253, 429, 193, 355, 60, 91, 432, 241, 473, 141, 361, 258, 98, 50, 527, 10, 105, 16, 322, 20, 198, 19, 369, 469, 152, 169, 196, 520, 167, 272, 263, 273, 14, 475, 466, 195, 440, 390, 39, 336, 270, 219, 360, 334, 159, 362, 381, 315, 483, 416, 522, 400, 4, 13, 487, 353, 138, 454, 208, 349, 310, 245, 268, 99, 75, 202, 89, 7, 442, 407, 76, 18, 173, 83, 342, 397, 347, 502, 262, 332, 108, 458, 31, 185, 246] 128 528\n",
      "block_10_expand\n",
      "before add_job: block_10_expand [324, 138, 261, 458, 353, 463, 292, 84, 339, 96, 79, 179, 126, 501, 515, 188, 500, 44, 130, 413, 265, 281, 269, 489, 94, 412, 13, 226, 386, 231, 67, 103, 497, 301, 527, 122, 322, 212, 365, 54, 334, 76, 237, 131, 110, 148, 184, 317, 52, 209, 332, 302, 175, 8, 312, 305, 238, 30, 343, 336, 392, 486, 46, 176, 398, 370, 506, 217, 293, 507, 47, 350, 7, 477, 5, 403, 75, 229, 166, 243, 55, 449, 465, 105, 448, 441, 155, 427, 112, 154, 320, 267, 419, 205, 429, 60, 438, 452, 401, 66, 342, 306, 199, 447, 245, 511, 318, 445, 161, 380, 118, 170, 19, 189, 460, 478, 313, 191, 420, 524, 378, 171, 384, 185, 91, 225, 234, 1] 128 528\n",
      "block_11_expand\n",
      "before add_job: block_11_expand [178, 411, 147, 802, 135, 186, 191, 78, 562, 596, 260, 471, 340, 659, 366, 390, 218, 97, 272, 205, 505, 582, 365, 24, 680, 231, 805, 148, 439, 349, 440, 568, 812, 791, 285, 518, 16, 414, 143, 368, 581, 725, 530, 651, 299, 763, 731, 382, 697, 777, 499, 541, 745, 574, 413, 764, 543, 775, 335, 750, 424, 93, 319, 723, 686, 735, 37, 388, 738, 252, 753, 248, 317, 151, 210, 109, 196, 737, 263, 730, 259, 307, 361, 579, 112, 144, 542, 83, 500, 22, 219, 679, 585, 193, 157, 81, 189, 370, 113, 294, 716, 459, 100, 214, 51, 504, 197, 152, 683, 668, 502, 780, 50, 31, 23, 170, 461, 79, 482, 456, 623, 125, 254, 315, 19, 705, 515, 55, 573, 327, 649, 789, 311, 256, 322, 492, 393, 498, 469, 772, 389, 279, 638, 187, 497, 288, 27, 609, 11, 208, 92, 80, 417, 162, 544, 531, 101, 801, 141, 532, 514, 68, 305, 484, 283, 814, 756, 232, 536, 615, 784, 669, 630, 509, 179, 20, 383, 253, 566, 613, 226, 709, 207, 635, 320, 729, 394, 642, 653, 718, 815, 540] 192 816\n",
      "block_12_expand\n",
      "before add_job: block_12_expand [528, 752, 44, 480, 682, 439, 661, 419, 791, 216, 659, 268, 97, 376, 99, 86, 734, 561, 592, 109, 213, 748, 751, 209, 78, 409, 814, 566, 175, 550, 89, 501, 4, 255, 757, 17, 694, 279, 297, 538, 38, 358, 440, 426, 611, 784, 502, 507, 335, 746, 81, 479, 84, 462, 0, 515, 643, 776, 326, 774, 244, 652, 516, 476, 88, 74, 338, 290, 467, 679, 291, 428, 532, 392, 185, 763, 286, 640, 5, 406, 706, 599, 441, 785, 160, 437, 793, 792, 55, 564, 764, 604, 443, 756, 472, 741, 307, 639, 197, 788, 342, 525, 608, 587, 557, 586, 12, 464, 666, 224, 83, 397, 263, 635, 366, 638, 177, 484, 495, 210, 466, 322, 436, 386, 686, 493, 371, 433, 72, 77, 7, 497, 31, 203, 546, 401, 416, 576, 320, 794, 779, 488, 458, 512, 424, 66, 704, 513, 542, 146, 459, 215, 620, 647, 94, 153, 478, 333, 732, 57, 27, 127, 323, 393, 106, 132, 496, 669, 381, 660, 574, 645, 470, 90, 717, 19, 56, 150, 485, 673, 103, 642, 571, 649, 377, 316, 707, 140, 804, 448, 548, 389] 192 816\n",
      "block_13_expand\n",
      "before add_job: block_13_expand [755, 109, 807, 489, 223, 299, 541, 2, 613, 181, 605, 302, 380, 638, 445, 217, 598, 573, 356, 219, 793, 647, 164, 399, 506, 672, 788, 514, 733, 781, 205, 564, 768, 578, 735, 623, 579, 496, 238, 233, 194, 537, 61, 400, 228, 401, 771, 693, 585, 481, 269, 160, 499, 166, 725, 436, 36, 492, 67, 813, 237, 615, 397, 660, 457, 150, 294, 137, 309, 668, 409, 650, 213, 587, 343, 688, 335, 446, 646, 43, 591, 728, 103, 290, 261, 325, 212, 385, 744, 267, 584, 502, 19, 739, 257, 111, 184, 802, 206, 329, 464, 792, 675, 717, 182, 663, 310, 536, 84, 617, 789, 736, 757, 145, 410, 327, 770, 80, 138, 483, 596, 471, 776, 289, 262, 276, 201, 552, 134, 752, 158, 465, 241, 283, 624, 566, 814, 803, 466, 367, 493, 176, 760, 524, 468, 8, 146, 659, 485, 72, 427, 79, 775, 39, 284, 503, 279, 18, 435, 652, 719, 529, 127, 612, 292, 353, 82, 370, 114, 203, 498, 528, 141, 126, 642, 110, 342, 322, 534, 185, 562, 97, 431, 298, 346, 124, 707, 655, 631, 589, 304, 229] 192 816\n",
      "block_14_expand\n",
      "before add_job: block_14_expand [1049, 762, 229, 488, 459, 437, 968, 503, 311, 941, 681, 1259, 1137, 125, 177, 96, 380, 1059, 1087, 707, 727, 975, 1100, 820, 618, 24, 1307, 1115, 212, 26, 695, 1138, 1117, 937, 500, 1007, 1141, 486, 872, 142, 834, 1275, 37, 1173, 554, 1153, 293, 1329, 1038, 1263, 940, 590, 25, 439, 1330, 323, 435, 402, 1066, 200, 372, 87, 83, 1067, 944, 371, 622, 992, 482, 244, 395, 1109, 1175, 557, 453, 784, 961, 521, 733, 443, 773, 1335, 670, 487, 352, 625, 563, 274, 716, 51, 720, 462, 421, 1148, 115, 220, 176, 859, 945, 1216, 771, 525, 855, 382, 957, 258, 741, 801, 254, 473, 58, 886, 348, 1291, 1134, 633, 806, 1045, 839, 979, 643, 764, 1236, 1244, 924, 650, 74, 9, 296, 881, 799, 558, 888, 1292, 309, 59, 1116, 1319, 393, 725, 336, 984, 67, 906, 1020, 1013, 149, 711, 572, 188, 1076, 161, 383, 384, 776, 75, 400, 433, 517, 110, 1118, 1180, 1328, 192, 1246, 850, 34, 735, 1256, 429, 164, 379, 939, 349, 649, 569, 290, 635, 847, 805, 990, 204, 1280, 495, 899, 1063, 743, 1310, 718, 1151, 394, 78, 17, 948, 508, 767, 1106, 490, 1093, 631, 870, 683, 79, 365, 1313, 1333, 1340, 793, 198, 955, 1018, 1177, 55, 726, 1322, 15, 257, 444, 684, 1300, 354, 246, 298, 1119, 995, 368, 765, 699, 410, 900, 524, 209, 967, 442, 587, 1284, 916, 466, 1163, 573, 1220, 863, 247, 489, 964, 935, 426, 144, 1312, 918, 114, 740, 612, 141, 1069, 1343, 1074, 419, 628, 1336, 555, 1152, 919, 377, 1229, 19, 1290, 108, 988, 849, 1065, 1308, 710, 36, 1318, 1078, 1021, 416, 1010, 617, 1286, 1230, 321, 3, 902, 1159, 853, 1110, 30, 217, 424, 825, 183, 64, 205, 1008, 620, 1278, 534, 1281, 342, 38, 911, 197, 700, 367, 413, 131, 452, 1248, 777, 1091, 73, 1178, 1241, 137, 261, 582, 166, 1169, 85, 182, 673, 595, 357, 1224, 45, 675, 287, 1325, 86, 412, 588, 341, 245, 21] 336 1344\n",
      "block_15_expand\n",
      "before add_job: block_15_expand [1161, 180, 153, 105, 634, 245, 167, 743, 194, 1176, 648, 921, 56, 816, 19, 1117, 1342, 1053, 620, 414, 420, 1214, 1237, 408, 208, 723, 1285, 705, 987, 106, 582, 733, 1280, 1224, 685, 572, 675, 213, 1165, 671, 284, 858, 1189, 725, 690, 116, 499, 682, 1227, 450, 358, 425, 575, 1242, 440, 95, 1095, 262, 274, 1075, 990, 1339, 1153, 1057, 867, 942, 419, 346, 466, 330, 804, 562, 669, 1115, 114, 240, 443, 473, 771, 609, 811, 184, 476, 838, 1299, 437, 350, 752, 45, 540, 1107, 1219, 9, 1164, 410, 1158, 270, 928, 1193, 340, 649, 277, 163, 337, 943, 1195, 544, 1150, 1205, 534, 40, 223, 1021, 7, 215, 170, 976, 289, 856, 93, 1051, 1002, 501, 786, 490, 368, 546, 968, 504, 433, 753, 1005, 26, 1336, 1031, 386, 73, 1036, 801, 543, 264, 64, 66, 459, 1262, 784, 1210, 559, 683, 258, 503, 1122, 1046, 244, 370, 348, 851, 896, 1142, 510, 972, 58, 51, 679, 991, 1011, 454, 1269, 22, 639, 183, 688, 21, 452, 123, 766, 591, 914, 482, 394, 961, 698, 676, 832, 978, 507, 1157, 708, 48, 242, 265, 53, 1120, 417, 1220, 43, 636, 1251, 108, 703, 1180, 181, 192, 770, 759, 848, 169, 1201, 640, 1296, 177, 699, 925, 444, 952, 994, 1300, 441, 18, 249, 479, 1175, 382, 83, 781, 1306, 954, 1234, 1308, 1215, 1222, 1017, 911, 1064, 1332, 1284, 1108, 924, 578, 810, 920, 1335, 165, 729, 288, 1058, 301, 692, 744, 773, 686, 590, 363, 317, 175, 1174, 225, 478, 6, 329, 820, 783, 429, 912, 798, 915, 520, 17, 77, 1121, 90, 531, 1177, 1104, 1183, 854, 886, 1098, 10, 1328, 269, 1213, 595, 110, 338, 740, 1217, 864, 275, 946, 673, 646, 260, 63, 179, 967, 364, 637, 130, 836, 339, 16, 594, 588, 293, 212, 1286, 974, 1073, 97, 464, 87, 125, 143, 866, 614, 357, 793, 191, 869, 1162, 1249, 527, 754, 862, 434, 1188, 214, 418, 1041, 282, 411, 20, 606, 1240, 873] 336 1344\n",
      "block_16_expand\n",
      "before add_job: block_16_expand [1287, 262, 1045, 993, 1036, 1300, 1053, 606, 586, 450, 1197, 201, 292, 1004, 1200, 525, 888, 784, 699, 963, 1120, 1284, 851, 833, 1177, 1190, 132, 1160, 323, 700, 1213, 173, 1112, 367, 1140, 870, 588, 892, 192, 431, 1066, 894, 21, 1071, 121, 451, 171, 59, 391, 681, 10, 628, 45, 187, 1302, 895, 504, 100, 1072, 419, 937, 781, 68, 91, 1290, 1152, 679, 1237, 484, 319, 210, 908, 1030, 1055, 1119, 433, 63, 352, 482, 268, 33, 261, 1305, 589, 1093, 706, 203, 1118, 867, 135, 218, 1307, 1073, 400, 1309, 97, 1116, 792, 702, 1191, 278, 986, 1264, 257, 442, 646, 26, 1247, 492, 1295, 102, 916, 270, 463, 237, 109, 642, 745, 808, 259, 148, 388, 982, 1115, 670, 567, 821, 113, 1012, 111, 620, 436, 12, 1204, 1207, 718, 1039, 803, 834, 1047, 395, 580, 145, 1261, 427, 1060, 812, 1286, 502, 708, 978, 246, 119, 960, 512, 1029, 790, 544, 345, 11, 713, 1064, 600, 460, 640, 1124, 649, 952, 746, 311, 260, 285, 778, 397, 760, 452, 1052, 454, 940, 418, 933, 1132, 422, 86, 449, 114, 250, 975, 762, 267, 354, 287, 498, 212, 516, 64, 652, 446, 1199, 215, 988, 1279, 384, 1253, 913, 943, 216, 485, 1068, 671, 744, 289, 1153, 326, 1335, 238, 664, 134, 503, 401, 120, 1021, 807, 506, 571, 791, 750, 1078, 184, 601, 265, 732, 1235, 569, 980, 211, 1168, 1164, 1005, 284, 1319, 1256, 1267, 398, 661, 666, 376, 136, 447, 770, 1134, 49, 564, 1042, 1028, 698, 1117, 634, 866, 240, 1303, 335, 1292, 900, 85, 80, 910, 1336, 882, 465, 206, 1188, 44, 464, 275, 334, 365, 1143, 357, 222, 381, 1179, 572, 987, 164, 1275, 596, 390, 1217, 88, 695, 753, 1174, 771, 415, 590, 165, 1107, 180, 133, 31, 1008, 23, 1202, 728, 556, 518, 1138, 1239, 1189, 74, 196, 17, 142, 82, 509, 876, 393, 407, 752, 594, 1216, 507, 36, 478, 140, 295, 566, 195, 380, 875, 1162, 315, 1014, 1161, 585] 336 1344\n",
      "Conv_1\n",
      "before add_job: Conv_1 [613, 55, 786, 1464, 669, 989, 1572, 1569, 195, 1114, 611, 1642, 1064, 722, 30, 1516, 1670, 511, 796, 1411, 1740, 885, 1540, 1482, 912, 250, 114, 1161, 537, 1001, 1484, 1548, 268, 1279, 1178, 1753, 1606, 964, 1201, 681, 271, 1348, 770, 625, 1641, 937, 290, 222, 494, 180, 324, 1156, 107, 452, 1784, 1674, 459, 408, 502, 91, 655, 967, 1210, 926, 1669, 831, 190, 897, 1746, 1206, 4, 1074, 1582, 438, 1364, 1537, 1744, 1278, 585, 407, 309, 1654, 526, 1591, 879, 1703, 1288, 618, 1714, 614, 529, 1687, 601, 1316, 305, 868, 295, 1324, 733, 177, 1696, 1066, 504, 257, 487, 1382, 42, 1084, 1384, 1705, 1261, 1031, 118, 474, 516, 73, 1301, 1727, 744, 587, 72, 612, 44, 783, 1320, 1557, 1340, 1331, 1266, 847, 575, 1229, 889, 1623, 14, 553, 422, 313, 1439, 152, 1088, 586, 203, 82, 542, 1495, 448, 71, 808, 1396, 1758, 187, 973, 827, 89, 1461, 385, 278, 163, 328, 1594, 255, 1629, 1782, 1521, 1160, 354, 543, 377, 707, 822, 446, 217, 1751, 809, 1522, 949, 1456, 1110, 764, 1689, 1252, 894, 1173, 745, 833, 1077, 314, 520, 517, 679, 849, 972, 688, 727, 51, 1068, 1535, 1775, 1597, 1329, 551, 65, 1692, 34, 507, 746, 1092, 1108, 246, 1006, 758, 637, 1567, 1728, 1122, 700, 35, 261, 123, 79, 433, 192, 1090, 1512, 867, 287, 564, 1672, 43, 169, 1057, 1649, 1365, 391, 814, 767, 523, 86, 147, 913, 1765, 1187, 347, 476, 1245, 1739, 304, 155, 348, 1709, 806, 1410, 401, 1174, 240, 413, 1157, 957, 479, 830, 113, 1757, 248, 1081, 1285, 1153, 1690, 968, 1648, 790, 907, 1238, 1336, 490, 1053, 633, 514, 1353, 1377, 1043, 966, 395, 828, 811, 731, 453, 583, 373, 1443, 1372, 906, 1280, 1271, 794, 1130, 1383, 1628, 1455, 308, 116, 593, 6, 1764, 980, 160, 26, 1695, 1172, 631, 832, 626, 1613, 1366, 201, 1233, 344, 1415, 1307, 172, 1511, 672, 1099, 1085, 1571, 1694, 1589, 483, 1209, 357, 864, 890, 738, 1701, 976, 524, 929, 1617, 162, 1702, 214, 762, 1170, 584, 741, 1061, 1400, 997, 621, 286, 698, 115, 1526, 397, 292, 1132, 489, 269, 837, 1513, 1313, 444, 320, 667, 1399, 580, 609, 1655, 759, 829, 182, 995, 189, 1496, 703, 300, 1223, 1756, 349, 20, 335, 1129, 1684, 1460, 730, 1069, 1250, 1428, 1309, 221, 800, 37, 1762, 1134, 985, 1609, 336, 1647, 1104, 1021, 588, 186, 1167, 32, 638, 892, 225, 902, 439, 914, 1111, 1118, 253, 184, 1693, 755, 622, 1051, 851, 136, 547, 1026, 1135, 247, 1354, 1317, 589, 988, 1549, 965, 1631, 98, 1463, 141, 1517, 876, 1071, 632, 1385, 157, 121, 223, 97, 712, 915, 387, 1205, 1667] 448 1792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 112, 144) (32,) [70, 59, 77, 80, 47, 118, 113, 49, 87, 100, 3, 61, 130, 142, 124, 37, 44, 30, 62, 36, 103, 134, 109, 7, 15, 65, 66, 107, 98, 128, 78, 115]\n",
      "Deleting 32/144 channels from layer: block_1_expand\n",
      "(1, 1, 144)\n",
      "(3, 3, 144, 1)\n",
      "(3, 3, 144, 1) [3, 3, -1, 1]\n",
      "(3, 3, 112, 1)\n",
      "(56, 56, 192) (48,) [72, 95, 106, 128, 116, 137, 62, 159, 177, 43, 144, 40, 53, 141, 109, 152, 21, 42, 131, 114, 87, 113, 17, 75, 171, 22, 174, 63, 30, 167, 33, 77, 112, 7, 12, 11, 169, 47, 10, 146, 183, 180, 83, 175, 67, 81, 34, 127]\n",
      "Deleting 48/192 channels from layer: block_2_expand\n",
      "(1, 1, 192)\n",
      "(3, 3, 192, 1)\n",
      "(3, 3, 192, 1) [3, 3, -1, 1]\n",
      "(3, 3, 144, 1)\n",
      "(56, 56, 192) (48,) [188, 104, 150, 3, 160, 9, 34, 182, 121, 81, 30, 166, 163, 44, 168, 110, 137, 19, 0, 41, 157, 146, 64, 82, 172, 136, 158, 87, 93, 91, 10, 58, 178, 75, 112, 134, 145, 14, 151, 39, 119, 65, 21, 124, 190, 170, 86, 2]\n",
      "Deleting 48/192 channels from layer: block_3_expand\n",
      "(1, 1, 192)\n",
      "(3, 3, 192, 1)\n",
      "(3, 3, 192, 1) [3, 3, -1, 1]\n",
      "(3, 3, 144, 1)\n",
      "(28, 28, 288) (64,) [3, 162, 120, 187, 176, 177, 202, 242, 19, 160, 83, 124, 129, 30, 17, 193, 67, 0, 94, 218, 47, 240, 194, 280, 122, 80, 251, 272, 63, 107, 238, 93, 12, 171, 32, 118, 245, 268, 27, 7, 87, 241, 127, 130, 98, 57, 72, 278, 89, 6, 207, 76, 84, 228, 203, 163, 135, 271, 49, 106, 208, 81, 119, 274]\n",
      "Deleting 64/288 channels from layer: block_4_expand\n",
      "(1, 1, 288)\n",
      "(3, 3, 288, 1)\n",
      "(3, 3, 288, 1) [3, 3, -1, 1]\n",
      "(3, 3, 224, 1)\n",
      "(28, 28, 288) (64,) [107, 88, 198, 278, 191, 14, 219, 238, 19, 32, 250, 73, 235, 35, 69, 231, 176, 29, 108, 272, 284, 58, 41, 10, 265, 229, 120, 210, 46, 37, 52, 279, 125, 134, 71, 94, 121, 86, 70, 122, 175, 263, 146, 100, 8, 112, 275, 226, 128, 165, 15, 56, 264, 138, 187, 55, 42, 247, 77, 62, 90, 221, 105, 143]\n",
      "Deleting 64/288 channels from layer: block_5_expand\n",
      "(1, 1, 288)\n",
      "(3, 3, 288, 1)\n",
      "(3, 3, 288, 1) [3, 3, -1, 1]\n",
      "(3, 3, 224, 1)\n",
      "(28, 28, 288) (64,) [184, 44, 45, 153, 87, 277, 80, 123, 159, 183, 278, 85, 147, 224, 177, 11, 157, 145, 261, 84, 89, 113, 106, 241, 132, 268, 219, 223, 125, 88, 8, 12, 264, 126, 206, 66, 77, 40, 71, 58, 29, 237, 170, 67, 117, 116, 53, 60, 253, 282, 285, 22, 37, 155, 225, 134, 135, 142, 70, 120, 96, 194, 17, 212]\n",
      "Deleting 64/288 channels from layer: block_6_expand\n",
      "(1, 1, 288)\n",
      "(3, 3, 288, 1)\n",
      "(3, 3, 288, 1) [3, 3, -1, 1]\n",
      "(3, 3, 224, 1)\n",
      "(14, 14, 528) (128,) [159, 440, 287, 185, 183, 504, 324, 524, 422, 254, 326, 269, 265, 356, 414, 278, 225, 49, 343, 337, 346, 120, 262, 180, 44, 407, 514, 66, 125, 416, 319, 390, 80, 394, 275, 204, 190, 95, 8, 92, 456, 438, 497, 2, 149, 193, 424, 27, 389, 418, 83, 461, 522, 472, 510, 226, 387, 157, 11, 154, 506, 253, 129, 333, 508, 73, 485, 452, 316, 224, 392, 279, 272, 105, 341, 162, 312, 84, 286, 475, 482, 282, 86, 207, 307, 437, 222, 520, 250, 277, 232, 172, 126, 384, 54, 339, 85, 239, 523, 471, 393, 385, 382, 502, 371, 124, 217, 266, 25, 498, 87, 169, 189, 102, 455, 473, 350, 259, 77, 481, 81, 12, 67, 235, 135, 431, 209, 175]\n",
      "Deleting 128/528 channels from layer: block_7_expand\n",
      "(1, 1, 528)\n",
      "(3, 3, 528, 1)\n",
      "(3, 3, 528, 1) [3, 3, -1, 1]\n",
      "(3, 3, 400, 1)\n",
      "(14, 14, 528) (128,) [503, 58, 239, 514, 252, 139, 366, 272, 141, 378, 344, 49, 189, 326, 351, 106, 458, 321, 479, 233, 164, 119, 120, 276, 148, 490, 243, 438, 6, 524, 184, 50, 304, 67, 102, 405, 484, 349, 468, 5, 196, 359, 431, 388, 18, 274, 4, 279, 232, 171, 176, 28, 486, 223, 21, 320, 260, 76, 31, 9, 459, 420, 105, 117, 240, 518, 158, 116, 381, 185, 526, 294, 40, 42, 356, 411, 110, 101, 399, 54, 521, 363, 142, 134, 220, 338, 443, 210, 433, 209, 473, 350, 483, 225, 24, 427, 324, 327, 293, 437, 416, 376, 59, 81, 374, 404, 66, 8, 323, 104, 166, 79, 135, 309, 396, 314, 154, 500, 474, 499, 219, 367, 7, 508, 291, 341, 268, 211]\n",
      "Deleting 128/528 channels from layer: block_8_expand\n",
      "(1, 1, 528)\n",
      "(3, 3, 528, 1)\n",
      "(3, 3, 528, 1) [3, 3, -1, 1]\n",
      "(3, 3, 400, 1)\n",
      "(14, 14, 528) (128,) [97, 329, 149, 371, 242, 0, 163, 172, 372, 282, 302, 21, 280, 213, 142, 224, 204, 65, 130, 412, 45, 27, 356, 118, 207, 237, 276, 343, 190, 452, 424, 480, 236, 373, 214, 403, 345, 255, 500, 498, 100, 260, 341, 253, 429, 193, 355, 60, 91, 432, 241, 473, 141, 361, 258, 98, 50, 527, 10, 105, 16, 322, 20, 198, 19, 369, 469, 152, 169, 196, 520, 167, 272, 263, 273, 14, 475, 466, 195, 440, 390, 39, 336, 270, 219, 360, 334, 159, 362, 381, 315, 483, 416, 522, 400, 4, 13, 487, 353, 138, 454, 208, 349, 310, 245, 268, 99, 75, 202, 89, 7, 442, 407, 76, 18, 173, 83, 342, 397, 347, 502, 262, 332, 108, 458, 31, 185, 246]\n",
      "Deleting 128/528 channels from layer: block_9_expand\n",
      "(1, 1, 528)\n",
      "(3, 3, 528, 1)\n",
      "(3, 3, 528, 1) [3, 3, -1, 1]\n",
      "(3, 3, 400, 1)\n",
      "(14, 14, 528) (128,) [324, 138, 261, 458, 353, 463, 292, 84, 339, 96, 79, 179, 126, 501, 515, 188, 500, 44, 130, 413, 265, 281, 269, 489, 94, 412, 13, 226, 386, 231, 67, 103, 497, 301, 527, 122, 322, 212, 365, 54, 334, 76, 237, 131, 110, 148, 184, 317, 52, 209, 332, 302, 175, 8, 312, 305, 238, 30, 343, 336, 392, 486, 46, 176, 398, 370, 506, 217, 293, 507, 47, 350, 7, 477, 5, 403, 75, 229, 166, 243, 55, 449, 465, 105, 448, 441, 155, 427, 112, 154, 320, 267, 419, 205, 429, 60, 438, 452, 401, 66, 342, 306, 199, 447, 245, 511, 318, 445, 161, 380, 118, 170, 19, 189, 460, 478, 313, 191, 420, 524, 378, 171, 384, 185, 91, 225, 234, 1]\n",
      "Deleting 128/528 channels from layer: block_10_expand\n",
      "(1, 1, 528)\n",
      "(3, 3, 528, 1)\n",
      "(3, 3, 528, 1) [3, 3, -1, 1]\n",
      "(3, 3, 400, 1)\n",
      "(14, 14, 816) (192,) [178, 411, 147, 802, 135, 186, 191, 78, 562, 596, 260, 471, 340, 659, 366, 390, 218, 97, 272, 205, 505, 582, 365, 24, 680, 231, 805, 148, 439, 349, 440, 568, 812, 791, 285, 518, 16, 414, 143, 368, 581, 725, 530, 651, 299, 763, 731, 382, 697, 777, 499, 541, 745, 574, 413, 764, 543, 775, 335, 750, 424, 93, 319, 723, 686, 735, 37, 388, 738, 252, 753, 248, 317, 151, 210, 109, 196, 737, 263, 730, 259, 307, 361, 579, 112, 144, 542, 83, 500, 22, 219, 679, 585, 193, 157, 81, 189, 370, 113, 294, 716, 459, 100, 214, 51, 504, 197, 152, 683, 668, 502, 780, 50, 31, 23, 170, 461, 79, 482, 456, 623, 125, 254, 315, 19, 705, 515, 55, 573, 327, 649, 789, 311, 256, 322, 492, 393, 498, 469, 772, 389, 279, 638, 187, 497, 288, 27, 609, 11, 208, 92, 80, 417, 162, 544, 531, 101, 801, 141, 532, 514, 68, 305, 484, 283, 814, 756, 232, 536, 615, 784, 669, 630, 509, 179, 20, 383, 253, 566, 613, 226, 709, 207, 635, 320, 729, 394, 642, 653, 718, 815, 540]\n",
      "Deleting 192/816 channels from layer: block_11_expand\n",
      "(1, 1, 816)\n",
      "(3, 3, 816, 1)\n",
      "(3, 3, 816, 1) [3, 3, -1, 1]\n",
      "(3, 3, 624, 1)\n",
      "(14, 14, 816) (192,) [528, 752, 44, 480, 682, 439, 661, 419, 791, 216, 659, 268, 97, 376, 99, 86, 734, 561, 592, 109, 213, 748, 751, 209, 78, 409, 814, 566, 175, 550, 89, 501, 4, 255, 757, 17, 694, 279, 297, 538, 38, 358, 440, 426, 611, 784, 502, 507, 335, 746, 81, 479, 84, 462, 0, 515, 643, 776, 326, 774, 244, 652, 516, 476, 88, 74, 338, 290, 467, 679, 291, 428, 532, 392, 185, 763, 286, 640, 5, 406, 706, 599, 441, 785, 160, 437, 793, 792, 55, 564, 764, 604, 443, 756, 472, 741, 307, 639, 197, 788, 342, 525, 608, 587, 557, 586, 12, 464, 666, 224, 83, 397, 263, 635, 366, 638, 177, 484, 495, 210, 466, 322, 436, 386, 686, 493, 371, 433, 72, 77, 7, 497, 31, 203, 546, 401, 416, 576, 320, 794, 779, 488, 458, 512, 424, 66, 704, 513, 542, 146, 459, 215, 620, 647, 94, 153, 478, 333, 732, 57, 27, 127, 323, 393, 106, 132, 496, 669, 381, 660, 574, 645, 470, 90, 717, 19, 56, 150, 485, 673, 103, 642, 571, 649, 377, 316, 707, 140, 804, 448, 548, 389]\n",
      "Deleting 192/816 channels from layer: block_12_expand\n",
      "(1, 1, 816)\n",
      "(3, 3, 816, 1)\n",
      "(3, 3, 816, 1) [3, 3, -1, 1]\n",
      "(3, 3, 624, 1)\n",
      "(14, 14, 816) (192,) [755, 109, 807, 489, 223, 299, 541, 2, 613, 181, 605, 302, 380, 638, 445, 217, 598, 573, 356, 219, 793, 647, 164, 399, 506, 672, 788, 514, 733, 781, 205, 564, 768, 578, 735, 623, 579, 496, 238, 233, 194, 537, 61, 400, 228, 401, 771, 693, 585, 481, 269, 160, 499, 166, 725, 436, 36, 492, 67, 813, 237, 615, 397, 660, 457, 150, 294, 137, 309, 668, 409, 650, 213, 587, 343, 688, 335, 446, 646, 43, 591, 728, 103, 290, 261, 325, 212, 385, 744, 267, 584, 502, 19, 739, 257, 111, 184, 802, 206, 329, 464, 792, 675, 717, 182, 663, 310, 536, 84, 617, 789, 736, 757, 145, 410, 327, 770, 80, 138, 483, 596, 471, 776, 289, 262, 276, 201, 552, 134, 752, 158, 465, 241, 283, 624, 566, 814, 803, 466, 367, 493, 176, 760, 524, 468, 8, 146, 659, 485, 72, 427, 79, 775, 39, 284, 503, 279, 18, 435, 652, 719, 529, 127, 612, 292, 353, 82, 370, 114, 203, 498, 528, 141, 126, 642, 110, 342, 322, 534, 185, 562, 97, 431, 298, 346, 124, 707, 655, 631, 589, 304, 229]\n",
      "Deleting 192/816 channels from layer: block_13_expand\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 816)\n",
      "(3, 3, 816, 1)\n",
      "(3, 3, 816, 1) [3, 3, -1, 1]\n",
      "(3, 3, 624, 1)\n",
      "(7, 7, 1344) (336,) [1049, 762, 229, 488, 459, 437, 968, 503, 311, 941, 681, 1259, 1137, 125, 177, 96, 380, 1059, 1087, 707, 727, 975, 1100, 820, 618, 24, 1307, 1115, 212, 26, 695, 1138, 1117, 937, 500, 1007, 1141, 486, 872, 142, 834, 1275, 37, 1173, 554, 1153, 293, 1329, 1038, 1263, 940, 590, 25, 439, 1330, 323, 435, 402, 1066, 200, 372, 87, 83, 1067, 944, 371, 622, 992, 482, 244, 395, 1109, 1175, 557, 453, 784, 961, 521, 733, 443, 773, 1335, 670, 487, 352, 625, 563, 274, 716, 51, 720, 462, 421, 1148, 115, 220, 176, 859, 945, 1216, 771, 525, 855, 382, 957, 258, 741, 801, 254, 473, 58, 886, 348, 1291, 1134, 633, 806, 1045, 839, 979, 643, 764, 1236, 1244, 924, 650, 74, 9, 296, 881, 799, 558, 888, 1292, 309, 59, 1116, 1319, 393, 725, 336, 984, 67, 906, 1020, 1013, 149, 711, 572, 188, 1076, 161, 383, 384, 776, 75, 400, 433, 517, 110, 1118, 1180, 1328, 192, 1246, 850, 34, 735, 1256, 429, 164, 379, 939, 349, 649, 569, 290, 635, 847, 805, 990, 204, 1280, 495, 899, 1063, 743, 1310, 718, 1151, 394, 78, 17, 948, 508, 767, 1106, 490, 1093, 631, 870, 683, 79, 365, 1313, 1333, 1340, 793, 198, 955, 1018, 1177, 55, 726, 1322, 15, 257, 444, 684, 1300, 354, 246, 298, 1119, 995, 368, 765, 699, 410, 900, 524, 209, 967, 442, 587, 1284, 916, 466, 1163, 573, 1220, 863, 247, 489, 964, 935, 426, 144, 1312, 918, 114, 740, 612, 141, 1069, 1343, 1074, 419, 628, 1336, 555, 1152, 919, 377, 1229, 19, 1290, 108, 988, 849, 1065, 1308, 710, 36, 1318, 1078, 1021, 416, 1010, 617, 1286, 1230, 321, 3, 902, 1159, 853, 1110, 30, 217, 424, 825, 183, 64, 205, 1008, 620, 1278, 534, 1281, 342, 38, 911, 197, 700, 367, 413, 131, 452, 1248, 777, 1091, 73, 1178, 1241, 137, 261, 582, 166, 1169, 85, 182, 673, 595, 357, 1224, 45, 675, 287, 1325, 86, 412, 588, 341, 245, 21]\n",
      "Deleting 336/1344 channels from layer: block_14_expand\n",
      "(1, 1, 1344)\n",
      "(3, 3, 1344, 1)\n",
      "(3, 3, 1344, 1) [3, 3, -1, 1]\n",
      "(3, 3, 1008, 1)\n",
      "(7, 7, 1344) (336,) [1161, 180, 153, 105, 634, 245, 167, 743, 194, 1176, 648, 921, 56, 816, 19, 1117, 1342, 1053, 620, 414, 420, 1214, 1237, 408, 208, 723, 1285, 705, 987, 106, 582, 733, 1280, 1224, 685, 572, 675, 213, 1165, 671, 284, 858, 1189, 725, 690, 116, 499, 682, 1227, 450, 358, 425, 575, 1242, 440, 95, 1095, 262, 274, 1075, 990, 1339, 1153, 1057, 867, 942, 419, 346, 466, 330, 804, 562, 669, 1115, 114, 240, 443, 473, 771, 609, 811, 184, 476, 838, 1299, 437, 350, 752, 45, 540, 1107, 1219, 9, 1164, 410, 1158, 270, 928, 1193, 340, 649, 277, 163, 337, 943, 1195, 544, 1150, 1205, 534, 40, 223, 1021, 7, 215, 170, 976, 289, 856, 93, 1051, 1002, 501, 786, 490, 368, 546, 968, 504, 433, 753, 1005, 26, 1336, 1031, 386, 73, 1036, 801, 543, 264, 64, 66, 459, 1262, 784, 1210, 559, 683, 258, 503, 1122, 1046, 244, 370, 348, 851, 896, 1142, 510, 972, 58, 51, 679, 991, 1011, 454, 1269, 22, 639, 183, 688, 21, 452, 123, 766, 591, 914, 482, 394, 961, 698, 676, 832, 978, 507, 1157, 708, 48, 242, 265, 53, 1120, 417, 1220, 43, 636, 1251, 108, 703, 1180, 181, 192, 770, 759, 848, 169, 1201, 640, 1296, 177, 699, 925, 444, 952, 994, 1300, 441, 18, 249, 479, 1175, 382, 83, 781, 1306, 954, 1234, 1308, 1215, 1222, 1017, 911, 1064, 1332, 1284, 1108, 924, 578, 810, 920, 1335, 165, 729, 288, 1058, 301, 692, 744, 773, 686, 590, 363, 317, 175, 1174, 225, 478, 6, 329, 820, 783, 429, 912, 798, 915, 520, 17, 77, 1121, 90, 531, 1177, 1104, 1183, 854, 886, 1098, 10, 1328, 269, 1213, 595, 110, 338, 740, 1217, 864, 275, 946, 673, 646, 260, 63, 179, 967, 364, 637, 130, 836, 339, 16, 594, 588, 293, 212, 1286, 974, 1073, 97, 464, 87, 125, 143, 866, 614, 357, 793, 191, 869, 1162, 1249, 527, 754, 862, 434, 1188, 214, 418, 1041, 282, 411, 20, 606, 1240, 873]\n",
      "Deleting 336/1344 channels from layer: block_15_expand\n",
      "(1, 1, 1344)\n",
      "(3, 3, 1344, 1)\n",
      "(3, 3, 1344, 1) [3, 3, -1, 1]\n",
      "(3, 3, 1008, 1)\n",
      "(7, 7, 1344) (336,) [1287, 262, 1045, 993, 1036, 1300, 1053, 606, 586, 450, 1197, 201, 292, 1004, 1200, 525, 888, 784, 699, 963, 1120, 1284, 851, 833, 1177, 1190, 132, 1160, 323, 700, 1213, 173, 1112, 367, 1140, 870, 588, 892, 192, 431, 1066, 894, 21, 1071, 121, 451, 171, 59, 391, 681, 10, 628, 45, 187, 1302, 895, 504, 100, 1072, 419, 937, 781, 68, 91, 1290, 1152, 679, 1237, 484, 319, 210, 908, 1030, 1055, 1119, 433, 63, 352, 482, 268, 33, 261, 1305, 589, 1093, 706, 203, 1118, 867, 135, 218, 1307, 1073, 400, 1309, 97, 1116, 792, 702, 1191, 278, 986, 1264, 257, 442, 646, 26, 1247, 492, 1295, 102, 916, 270, 463, 237, 109, 642, 745, 808, 259, 148, 388, 982, 1115, 670, 567, 821, 113, 1012, 111, 620, 436, 12, 1204, 1207, 718, 1039, 803, 834, 1047, 395, 580, 145, 1261, 427, 1060, 812, 1286, 502, 708, 978, 246, 119, 960, 512, 1029, 790, 544, 345, 11, 713, 1064, 600, 460, 640, 1124, 649, 952, 746, 311, 260, 285, 778, 397, 760, 452, 1052, 454, 940, 418, 933, 1132, 422, 86, 449, 114, 250, 975, 762, 267, 354, 287, 498, 212, 516, 64, 652, 446, 1199, 215, 988, 1279, 384, 1253, 913, 943, 216, 485, 1068, 671, 744, 289, 1153, 326, 1335, 238, 664, 134, 503, 401, 120, 1021, 807, 506, 571, 791, 750, 1078, 184, 601, 265, 732, 1235, 569, 980, 211, 1168, 1164, 1005, 284, 1319, 1256, 1267, 398, 661, 666, 376, 136, 447, 770, 1134, 49, 564, 1042, 1028, 698, 1117, 634, 866, 240, 1303, 335, 1292, 900, 85, 80, 910, 1336, 882, 465, 206, 1188, 44, 464, 275, 334, 365, 1143, 357, 222, 381, 1179, 572, 987, 164, 1275, 596, 390, 1217, 88, 695, 753, 1174, 771, 415, 590, 165, 1107, 180, 133, 31, 1008, 23, 1202, 728, 556, 518, 1138, 1239, 1189, 74, 196, 17, 142, 82, 509, 876, 393, 407, 752, 594, 1216, 507, 36, 478, 140, 295, 566, 195, 380, 875, 1162, 315, 1014, 1161, 585]\n",
      "Deleting 336/1344 channels from layer: block_16_expand\n",
      "(1, 1, 1344)\n",
      "(3, 3, 1344, 1)\n",
      "(3, 3, 1344, 1) [3, 3, -1, 1]\n",
      "(3, 3, 1008, 1)\n",
      "(7, 7, 1792) (448,) [613, 55, 786, 1464, 669, 989, 1572, 1569, 195, 1114, 611, 1642, 1064, 722, 30, 1516, 1670, 511, 796, 1411, 1740, 885, 1540, 1482, 912, 250, 114, 1161, 537, 1001, 1484, 1548, 268, 1279, 1178, 1753, 1606, 964, 1201, 681, 271, 1348, 770, 625, 1641, 937, 290, 222, 494, 180, 324, 1156, 107, 452, 1784, 1674, 459, 408, 502, 91, 655, 967, 1210, 926, 1669, 831, 190, 897, 1746, 1206, 4, 1074, 1582, 438, 1364, 1537, 1744, 1278, 585, 407, 309, 1654, 526, 1591, 879, 1703, 1288, 618, 1714, 614, 529, 1687, 601, 1316, 305, 868, 295, 1324, 733, 177, 1696, 1066, 504, 257, 487, 1382, 42, 1084, 1384, 1705, 1261, 1031, 118, 474, 516, 73, 1301, 1727, 744, 587, 72, 612, 44, 783, 1320, 1557, 1340, 1331, 1266, 847, 575, 1229, 889, 1623, 14, 553, 422, 313, 1439, 152, 1088, 586, 203, 82, 542, 1495, 448, 71, 808, 1396, 1758, 187, 973, 827, 89, 1461, 385, 278, 163, 328, 1594, 255, 1629, 1782, 1521, 1160, 354, 543, 377, 707, 822, 446, 217, 1751, 809, 1522, 949, 1456, 1110, 764, 1689, 1252, 894, 1173, 745, 833, 1077, 314, 520, 517, 679, 849, 972, 688, 727, 51, 1068, 1535, 1775, 1597, 1329, 551, 65, 1692, 34, 507, 746, 1092, 1108, 246, 1006, 758, 637, 1567, 1728, 1122, 700, 35, 261, 123, 79, 433, 192, 1090, 1512, 867, 287, 564, 1672, 43, 169, 1057, 1649, 1365, 391, 814, 767, 523, 86, 147, 913, 1765, 1187, 347, 476, 1245, 1739, 304, 155, 348, 1709, 806, 1410, 401, 1174, 240, 413, 1157, 957, 479, 830, 113, 1757, 248, 1081, 1285, 1153, 1690, 968, 1648, 790, 907, 1238, 1336, 490, 1053, 633, 514, 1353, 1377, 1043, 966, 395, 828, 811, 731, 453, 583, 373, 1443, 1372, 906, 1280, 1271, 794, 1130, 1383, 1628, 1455, 308, 116, 593, 6, 1764, 980, 160, 26, 1695, 1172, 631, 832, 626, 1613, 1366, 201, 1233, 344, 1415, 1307, 172, 1511, 672, 1099, 1085, 1571, 1694, 1589, 483, 1209, 357, 864, 890, 738, 1701, 976, 524, 929, 1617, 162, 1702, 214, 762, 1170, 584, 741, 1061, 1400, 997, 621, 286, 698, 115, 1526, 397, 292, 1132, 489, 269, 837, 1513, 1313, 444, 320, 667, 1399, 580, 609, 1655, 759, 829, 182, 995, 189, 1496, 703, 300, 1223, 1756, 349, 20, 335, 1129, 1684, 1460, 730, 1069, 1250, 1428, 1309, 221, 800, 37, 1762, 1134, 985, 1609, 336, 1647, 1104, 1021, 588, 186, 1167, 32, 638, 892, 225, 902, 439, 914, 1111, 1118, 253, 184, 1693, 755, 622, 1051, 851, 136, 547, 1026, 1135, 247, 1354, 1317, 589, 988, 1549, 965, 1631, 98, 1463, 141, 1517, 876, 1071, 632, 1385, 157, 121, 223, 97, 712, 915, 387, 1205, 1667]\n",
      "Deleting 448/1792 channels from layer: Conv_1\n"
     ]
    }
   ],
   "source": [
    "#random pruning\n",
    "percent_pruned=25\n",
    "reduced_model_new=prune_model_random(reduced_model,percent_pruned)\n",
    "\n",
    "checkpoint_name = ('mobilenet_pruning_' + str(percent_pruned) + 'percent_rnd')\n",
    "reduced_model_new.compile(optimizer=SGD(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy',top_k_categorical_accuracy])\n",
    "reduced_model_new.save(checkpoint_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del reduced_model\n",
    "K.clear_session()\n",
    "tf.reset_default_graph()\n",
    "reduced_model = load_model(checkpoint_name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 112, 112, 24) 648         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 112, 112, 24) 96          Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 112, 112, 24) 0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 112, 112, 24) 216         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 112, 112, 24) 96          expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 112, 112, 24) 0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 112, 112, 16) 384         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 112, 112, 64) 1024        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 112, 112, 64) 256         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 112, 112, 64) 0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 56, 56, 64)   576         block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 56, 56, 64)   256         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 56, 56, 64)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 56, 56, 24)   1536        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 56, 56, 96)   2304        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 56, 56, 96)   384         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 56, 56, 96)   0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 56, 56, 24)   2304        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 56, 56, 96)   2304        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 56, 56, 96)   384         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 56, 56, 96)   0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 28, 28, 96)   864         block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 28, 28, 96)   384         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 28, 28, 96)   0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 28, 28, 32)   3072        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 28, 28, 120)  3840        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 28, 28, 120)  480         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 28, 28, 120)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 28, 28, 120)  1080        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 28, 28, 120)  480         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 28, 28, 120)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 28, 28, 32)   3840        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 28, 28, 120)  3840        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 28, 28, 120)  480         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 28, 28, 120)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 28, 28, 120)  1080        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 28, 28, 120)  480         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 28, 28, 120)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 28, 28, 32)   3840        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 28, 28, 120)  3840        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 28, 28, 120)  480         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 28, 28, 120)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 14, 14, 120)  1080        block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 14, 14, 120)  480         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 14, 14, 120)  0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 14, 14, 64)   7680        block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 14, 14, 232)  14848       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 14, 14, 232)  928         block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 14, 14, 232)  0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 14, 14, 232)  2088        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 14, 14, 232)  928         block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 14, 14, 232)  0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 14, 14, 64)   14848       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 14, 14, 232)  14848       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 14, 14, 232)  928         block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 14, 14, 232)  0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 14, 14, 232)  2088        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 14, 14, 232)  928         block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 14, 14, 232)  0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 14, 14, 64)   14848       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 14, 14, 232)  14848       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 14, 14, 232)  928         block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 14, 14, 232)  0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 14, 14, 232)  2088        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 14, 14, 232)  928         block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 14, 14, 232)  0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 14, 14, 64)   14848       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 14, 14, 232)  14848       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 14, 14, 232)  928         block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 14, 14, 232)  0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 14, 14, 232)  2088        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 14, 14, 232)  928         block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 14, 14, 232)  0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 14, 14, 96)   22272       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 14, 14, 352)  33792       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 14, 14, 352)  1408        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 14, 14, 352)  0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 14, 14, 352)  3168        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 14, 14, 352)  1408        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 14, 14, 352)  0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 14, 14, 96)   33792       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 14, 14, 352)  33792       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 14, 14, 352)  1408        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 14, 14, 352)  0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 14, 14, 352)  3168        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 14, 14, 352)  1408        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 14, 14, 352)  0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 14, 14, 96)   33792       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 14, 14, 352)  33792       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 14, 14, 352)  1408        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 14, 14, 352)  0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 7, 7, 352)    3168        block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 7, 7, 352)    1408        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 7, 7, 352)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 7, 7, 160)    56320       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 7, 7, 576)    92160       block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 7, 7, 576)    2304        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 7, 7, 576)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 7, 7, 160)    92160       block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 7, 7, 576)    92160       block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 7, 7, 576)    2304        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 7, 7, 576)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 7, 7, 160)    92160       block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 7, 7, 576)    92160       block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 7, 7, 576)    2304        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 7, 7, 576)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 7, 7, 320)    184320      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 7, 7, 768)    245760      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 7, 7, 768)    3072        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 7, 7, 768)    0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 768)          0           out_relu[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 431)          331439      global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 1,697,335\n",
      "Trainable params: 1,675,383\n",
      "Non-trainable params: 21,952\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "203129/203129 [==============================] - 108106s 532ms/step - loss: 1.7805 - acc: 0.5186 - top_k_categorical_accuracy: 0.8326 - val_loss: 2.3521 - val_acc: 0.4689 - val_top_k_categorical_accuracy: 0.7700\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.46887, saving model to mobilenet_v2_1.0_pruning_grad_45percent_ft.h5\n",
      "Epoch 2/3\n",
      "203129/203129 [==============================] - 104215s 513ms/step - loss: 1.7287 - acc: 0.5298 - top_k_categorical_accuracy: 0.8412 - val_loss: 2.3271 - val_acc: 0.4725 - val_top_k_categorical_accuracy: 0.7750\n",
      "\n",
      "Epoch 00002: val_acc improved from 0.46887 to 0.47252, saving model to mobilenet_v2_1.0_pruning_grad_45percent_ft.h5\n",
      "Epoch 3/3\n",
      "203129/203129 [==============================] - 104737s 516ms/step - loss: 1.7103 - acc: 0.5339 - top_k_categorical_accuracy: 0.8442 - val_loss: 2.3202 - val_acc: 0.4739 - val_top_k_categorical_accuracy: 0.7780\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.47252 to 0.47391, saving model to mobilenet_v2_1.0_pruning_grad_45percent_ft.h5\n"
     ]
    }
   ],
   "source": [
    "#reduced_model.compile(optimizer=SGD(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy',top_k_categorical_accuracy])\n",
    "reduced_model.summary()\n",
    "mc = ModelCheckpoint(checkpoint_name+'_ft.h5', monitor='val_acc', verbose=1, save_best_only=True)\n",
    "es=EarlyStopping(monitor='val_acc',patience=2)\n",
    "#print(reduced_model.evaluate_generator(val_generator,steps=nb_validation_samples // BATCH_SIZE))\n",
    "hist=reduced_model.fit_generator(train_generator, steps_per_epoch=nb_train_samples//BATCH_SIZE, epochs=3, verbose=1, \n",
    "                    callbacks=[mc,es], validation_data=val_generator, validation_steps=nb_validation_samples // BATCH_SIZE,class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airfield 100 0.96\n",
      "airplane_cabin 100 0.93\n",
      "airport_terminal 100 0.9\n",
      "alcove 100 0.83\n",
      "alley 100 0.89\n",
      "amphitheater 100 0.79\n",
      "amusement_arcade 100 0.82\n",
      "amusement_park 100 0.8\n",
      "anechoic_chamber 100 0.73\n",
      "apartment_building_outdoor 100 0.72\n",
      "aquarium 100 0.91\n",
      "aqueduct 100 0.85\n",
      "arcade 100 0.88\n",
      "arch 100 0.78\n",
      "archaelogical_excavation 100 0.91\n",
      "archive 100 0.78\n",
      "arena_hockey 100 1.0\n",
      "arena_performance 100 0.96\n",
      "arena_rodeo 100 0.98\n",
      "army_base 100 0.93\n",
      "art_gallery 100 0.85\n",
      "art_school 100 0.85\n",
      "art_studio 100 0.76\n",
      "artists_loft 100 0.74\n",
      "assembly_line 100 0.57\n",
      "athletic_field_indoor 100 0.47\n",
      "athletic_field_outdoor 100 0.94\n",
      "atrium_public 100 0.89\n",
      "attic 100 0.92\n",
      "auditorium 100 0.9\n",
      "auto_factory 100 0.82\n",
      "auto_showroom 100 0.98\n",
      "badlands 100 0.82\n",
      "badminton_court_indoor 100 0.76\n",
      "baggage_claim 100 0.85\n",
      "bakery_shop 100 0.87\n",
      "balcony_exterior 100 0.73\n",
      "balcony_interior 100 0.82\n",
      "ball_pit 100 0.89\n",
      "ballroom 100 0.88\n",
      "bamboo_forest 100 0.95\n",
      "bank_vault 100 0.67\n",
      "banquet_hall 100 0.93\n",
      "bar 100 0.79\n",
      "barn 100 0.88\n",
      "barndoor 100 0.87\n",
      "baseball_field 100 0.97\n",
      "basement 100 0.68\n",
      "basketball_court_indoor 100 0.96\n",
      "basketball_court_outdoor 100 0.7\n",
      "bathroom 100 0.9\n",
      "batters_box 100 0.83\n",
      "bazaar_indoor 100 0.69\n",
      "bazaar_outdoor 100 0.86\n",
      "beach 100 0.92\n",
      "beach_house 100 0.85\n",
      "beauty_salon 100 0.62\n",
      "bedchamber 100 0.81\n",
      "bedroom 100 0.95\n",
      "beer_garden 100 0.85\n",
      "beer_hall 100 0.86\n",
      "berth 100 0.91\n",
      "biology_laboratory 100 0.64\n",
      "boardwalk 100 0.78\n",
      "boat_deck 100 0.8\n",
      "boathouse 100 0.81\n",
      "bookstore 100 0.89\n",
      "booth_indoor 100 0.91\n",
      "botanical_garden 100 0.69\n",
      "bow_window_indoor 100 0.91\n",
      "bow_window_outdoor 100 0.11\n",
      "bowling_alley 100 0.88\n",
      "boxing_ring 100 0.95\n",
      "brewery_indoor 100 0.0\n",
      "bridge 100 0.75\n",
      "building_facade 100 0.57\n",
      "bullring 100 0.88\n",
      "burial_chamber 100 0.91\n",
      "bus_interior 100 0.93\n",
      "bus_station_indoor 100 0.91\n",
      "butchers_shop 100 0.78\n",
      "butte 100 0.74\n",
      "cabin_outdoor 100 0.88\n",
      "cafeteria 100 0.24\n",
      "campsite 100 0.92\n",
      "campus 100 0.64\n",
      "canal_natural 100 0.87\n",
      "canal_urban 100 0.89\n",
      "candy_store 100 0.72\n",
      "canyon 100 0.82\n",
      "car_interior 100 0.98\n",
      "carrousel 100 0.87\n",
      "casino_indoor 100 0.72\n",
      "castle 100 0.83\n",
      "catacomb 100 0.96\n",
      "cemetery 100 0.92\n",
      "chalet 100 0.73\n",
      "cheese_factory 100 0.61\n",
      "chemistry_lab 100 0.64\n",
      "chicken_coop_outdoor 100 0.37\n",
      "childs_room 100 0.91\n",
      "church_indoor 100 0.96\n",
      "church_outdoor 100 0.83\n",
      "classroom 100 0.84\n",
      "clean_room 100 0.68\n",
      "cliff 100 0.78\n",
      "closet 100 0.89\n",
      "clothing_store 100 0.84\n",
      "coast 100 0.81\n",
      "cockpit 100 0.99\n",
      "coffee_shop 100 0.66\n",
      "computer_room 100 0.76\n",
      "conference_center 100 0.89\n",
      "conference_room 100 0.87\n",
      "construction_site 100 0.76\n",
      "corn_field 100 0.93\n",
      "corral 100 0.95\n",
      "corridor 100 0.95\n",
      "cottage 100 0.74\n",
      "courthouse 100 0.77\n",
      "courtroom 100 0.76\n",
      "courtyard 100 0.66\n",
      "covered_bridge_exterior 100 0.48\n",
      "creek 100 0.82\n",
      "crevasse 100 0.8\n",
      "crosswalk 100 0.88\n",
      "cybercafe 100 0.27\n",
      "dam 100 0.81\n",
      "delicatessen 100 0.78\n",
      "dentists_office 100 0.7\n",
      "department_store 100 0.86\n",
      "desert_road 100 0.92\n",
      "desert_sand 100 0.88\n",
      "desert_vegetation 100 0.94\n",
      "diner_outdoor 100 0.83\n",
      "dinette_vehicle 100 0.38\n",
      "dining_car 100 0.67\n",
      "dining_hall 100 0.83\n",
      "dining_room 100 0.84\n",
      "discotheque 100 0.93\n",
      "doorway_outdoor 100 0.83\n",
      "dorm_room 100 0.83\n",
      "downtown 100 0.87\n",
      "dressing_room 100 0.69\n",
      "driveway 100 0.84\n",
      "driving_range_outdoor 100 0.0\n",
      "drugstore 100 0.64\n",
      "editing_room 100 0.45\n",
      "electrical_substation 100 0.76\n",
      "elevator_door 100 0.76\n",
      "elevator_interior 100 0.78\n",
      "elevator_lobby 100 0.8\n",
      "elevator_shaft 100 0.84\n",
      "embassy 100 0.87\n",
      "engine_room 100 0.86\n",
      "entrance_hall 100 0.9\n",
      "escalator_indoor 100 0.84\n",
      "excavation 100 0.91\n",
      "fabric_store 100 0.8\n",
      "factory_indoor 100 0.04\n",
      "farm 100 0.76\n",
      "fastfood_restaurant 100 0.7\n",
      "field_cultivated 100 0.83\n",
      "field_road 100 0.87\n",
      "field_wild 100 0.77\n",
      "fire_escape 100 0.89\n",
      "fire_station 100 0.81\n",
      "firing_range_indoor 100 0.52\n",
      "fishpond 100 0.85\n",
      "fitting_room_interior 100 0.0\n",
      "flea_market_indoor 100 0.77\n",
      "florist_shop_indoor 100 0.97\n",
      "florist_shop_outdoor 100 0.31\n",
      "food_court 100 0.72\n",
      "football_field 100 0.93\n",
      "forest_broadleaf 100 0.83\n",
      "forest_needleleaf 100 0.05\n",
      "forest_path 100 0.87\n",
      "forest_road 100 0.9\n",
      "formal_garden 100 0.78\n",
      "fountain 100 0.86\n",
      "funeral_home 100 0.27\n",
      "galley 100 0.85\n",
      "garage_indoor 100 0.8\n",
      "garage_outdoor 100 0.96\n",
      "gas_station 100 0.86\n",
      "gazebo_exterior 100 0.78\n",
      "general_store_indoor 100 0.63\n",
      "general_store_outdoor 100 0.83\n",
      "gift_shop 100 0.63\n",
      "glacier 100 0.89\n",
      "golf_course 100 0.9\n",
      "great_hall 100 0.34\n",
      "greenhouse_indoor 100 0.83\n",
      "greenhouse_outdoor 100 0.8\n",
      "grotto 100 0.95\n",
      "gymnasium_indoor 100 0.83\n",
      "hangar_indoor 100 0.92\n",
      "hangar_outdoor 100 0.7\n",
      "harbor 100 0.87\n",
      "hardware_store 100 0.56\n",
      "hat_shop 100 0.48\n",
      "hayfield 100 0.75\n",
      "heliport 100 0.91\n",
      "highway 100 0.88\n",
      "home_office 100 0.86\n",
      "home_theater 100 0.8\n",
      "hospital 100 0.53\n",
      "hospital_room 100 0.81\n",
      "hot_spring 100 0.77\n",
      "hot_tub_indoor 100 0.5\n",
      "hot_tub_outdoor 100 0.87\n",
      "hotel_outdoor 100 0.73\n",
      "hotel_room 100 0.93\n",
      "house 100 0.81\n",
      "hunting_lodge_outdoor 100 0.87\n",
      "ice_cream_parlor 100 0.66\n",
      "ice_floe 100 0.8\n",
      "ice_shelf 100 0.67\n",
      "ice_skating_rink_indoor 100 0.9\n",
      "ice_skating_rink_outdoor 100 0.92\n",
      "iceberg 100 0.94\n",
      "igloo 100 0.87\n",
      "industrial_area 100 0.82\n",
      "inn_outdoor 100 0.75\n",
      "islet 100 0.89\n",
      "jacuzzi_indoor 100 0.83\n",
      "jail_cell 100 0.84\n",
      "jail_indoor 100 0.22\n",
      "japanese_garden 100 0.75\n",
      "jewelry_shop 100 0.75\n",
      "junkyard 100 0.92\n",
      "kasbah 100 0.83\n",
      "kennel_indoor 100 0.44\n",
      "kennel_outdoor 100 0.82\n",
      "kindergarden_classroom 100 0.93\n",
      "kitchen 100 0.94\n",
      "labyrinth_outdoor 100 0.61\n",
      "lagoon 100 0.85\n",
      "lake_natural 100 0.72\n",
      "landfill 100 0.89\n",
      "landing_deck 100 0.89\n",
      "laundromat 100 0.91\n",
      "lawn 100 0.86\n",
      "lecture_room 100 0.86\n",
      "legislative_chamber 100 0.88\n",
      "library_indoor 100 0.9\n",
      "library_outdoor 100 0.78\n",
      "lido_deck_outdoor 100 0.77\n",
      "lighthouse 100 0.92\n",
      "limousine_interior 100 0.89\n",
      "liquor_store_outdoor 100 0.0\n",
      "living_room 100 0.88\n",
      "loading_dock 100 0.87\n",
      "lobby 100 0.82\n",
      "lock_chamber 100 0.8\n",
      "locker_room 100 0.82\n",
      "loft 100 0.33\n",
      "mansion 100 0.6\n",
      "manufactured_home 100 0.94\n",
      "market_indoor 100 0.56\n",
      "market_outdoor 100 0.83\n",
      "marsh 100 0.78\n",
      "martial_arts_gym 100 0.97\n",
      "mausoleum 100 0.77\n",
      "medina 100 0.81\n",
      "mezzanine 100 0.68\n",
      "moat_water 100 0.71\n",
      "mosque_outdoor 100 0.9\n",
      "motel 100 0.72\n",
      "mountain 100 0.84\n",
      "mountain_path 100 0.67\n",
      "mountain_snowy 100 0.89\n",
      "movie_theater_indoor 100 0.85\n",
      "museum_indoor 100 0.78\n",
      "museum_outdoor 100 0.65\n",
      "music_store 100 0.81\n",
      "music_studio 100 0.88\n",
      "natural_history_museum 100 0.84\n",
      "nuclear_power_plant_outdoor 100 0.65\n",
      "nursery 100 0.84\n",
      "nursing_home 100 0.83\n",
      "oast_house 100 0.82\n",
      "observatory_outdoor 100 0.46\n",
      "ocean 100 0.83\n",
      "office 100 0.84\n",
      "office_building 100 0.8\n",
      "office_cubicles 100 0.69\n",
      "oil_refinery_outdoor 100 0.37\n",
      "oilrig 100 0.91\n",
      "operating_room 100 0.92\n",
      "optician 100 0.5\n",
      "orchard 100 0.81\n",
      "orchestra_pit 100 0.97\n",
      "outhouse_outdoor 100 0.0\n",
      "pagoda 100 0.95\n",
      "palace 100 0.73\n",
      "pantry 100 0.8\n",
      "park 100 0.67\n",
      "parking_garage_indoor 100 0.82\n",
      "parking_garage_outdoor 100 0.68\n",
      "parking_lot 100 0.86\n",
      "pasture 100 0.87\n",
      "patio 100 0.85\n",
      "pavilion 100 0.73\n",
      "pet_shop 100 0.54\n",
      "pharmacy 100 0.65\n",
      "phone_booth 100 0.93\n",
      "physics_laboratory 100 0.73\n",
      "picnic_area 100 0.86\n",
      "pier 100 0.86\n",
      "pizzeria 100 0.76\n",
      "playground 100 0.94\n",
      "playroom 100 0.88\n",
      "plaza 100 0.6\n",
      "podium_indoor 100 0.18\n",
      "pond 100 0.77\n",
      "poolroom_home 100 0.38\n",
      "porch 100 0.87\n",
      "portrait_studio 100 0.45\n",
      "power_plant_outdoor 100 0.18\n",
      "promenade 100 0.85\n",
      "promenade_deck 100 0.69\n",
      "pub_indoor 100 0.91\n",
      "racecourse 100 0.9\n",
      "raceway 100 0.95\n",
      "raft 100 0.9\n",
      "railroad_track 100 0.89\n",
      "rainforest 100 0.87\n",
      "ranch_house 100 0.21\n",
      "reception 100 0.78\n",
      "recreation_room 100 0.59\n",
      "repair_shop 100 0.61\n",
      "residential_neighborhood 100 0.81\n",
      "rest_area 100 0.03\n",
      "restaurant 100 0.77\n",
      "restaurant_kitchen 100 0.91\n",
      "restaurant_patio 100 0.88\n",
      "rice_paddy 100 0.94\n",
      "river 100 0.59\n",
      "rock_arch 100 0.93\n",
      "roof_garden 100 0.88\n",
      "rope_bridge 100 0.79\n",
      "ruin 100 0.86\n",
      "runway 100 0.93\n",
      "sandbox 100 0.89\n",
      "sauna 100 0.82\n",
      "schoolhouse 100 0.7\n",
      "science_museum 100 0.58\n",
      "server_room 100 0.75\n",
      "shed 100 0.85\n",
      "shoe_shop 100 0.72\n",
      "shopfront 100 0.88\n",
      "shopping_mall_indoor 100 0.65\n",
      "shower 100 0.9\n",
      "shower_room 100 0.54\n",
      "ski_resort 100 0.93\n",
      "ski_slope 100 0.94\n",
      "sky 100 0.74\n",
      "skyscraper 100 0.9\n",
      "slum 100 0.86\n",
      "snowfield 100 0.93\n",
      "soccer_field 100 0.93\n",
      "squash_court 100 0.89\n",
      "stable 100 0.82\n",
      "stadium_baseball 100 0.98\n",
      "stadium_football 100 0.99\n",
      "stadium_soccer 100 0.91\n",
      "stage_indoor 100 0.83\n",
      "stage_outdoor 100 0.93\n",
      "staircase 100 0.86\n",
      "storage_room 100 0.72\n",
      "street 100 0.9\n",
      "subway_interior 100 0.81\n",
      "subway_station_platform 100 0.83\n",
      "supermarket 100 0.88\n",
      "sushi_bar 100 0.6\n",
      "swamp 100 0.88\n",
      "swimming_hole 100 0.9\n",
      "swimming_pool_indoor 100 0.93\n",
      "swimming_pool_outdoor 100 0.97\n",
      "synagogue_outdoor 100 0.81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "teashop 100 0.26\n",
      "television_room 100 0.85\n",
      "television_studio 100 0.73\n",
      "temple_asia 100 0.86\n",
      "tennis_court_indoor 100 0.92\n",
      "tennis_court_outdoor 100 0.89\n",
      "theater_indoor_seats 100 0.09\n",
      "thriftshop 100 0.19\n",
      "throne_room 100 0.85\n",
      "ticket_booth 100 0.67\n",
      "toll_plaza 100 0.73\n",
      "topiary_garden 100 0.85\n",
      "tower 100 0.81\n",
      "toyshop 100 0.8\n",
      "train_interior 100 0.96\n",
      "train_station_platform 100 0.94\n",
      "tree_farm 100 0.7\n",
      "tree_house 100 0.75\n",
      "trench 100 0.88\n",
      "tundra 100 0.86\n",
      "underwater_ocean_deep 100 0.98\n",
      "utility_room 100 0.78\n",
      "valley 100 0.64\n",
      "vegetable_garden 100 0.82\n",
      "veterinarians_office 100 0.87\n",
      "viaduct 100 0.81\n",
      "videostore 100 0.81\n",
      "village 100 0.86\n",
      "vineyard 100 0.91\n",
      "volcano 100 0.88\n",
      "volleyball_court_indoor 100 0.92\n",
      "volleyball_court_outdoor 100 0.88\n",
      "waiting_room 100 0.86\n",
      "walk_in_freezer 100 0.34\n",
      "warehouse_indoor 100 0.69\n",
      "water_park 100 0.89\n",
      "water_tower 100 0.83\n",
      "waterfall 100 0.96\n",
      "watering_hole 100 0.79\n",
      "wave 100 0.94\n",
      "wet_bar 100 0.86\n",
      "wheat_field 100 0.89\n",
      "wind_farm 100 0.98\n",
      "windmill 100 0.96\n",
      "wine_cellar_barrel_storage 100 0.83\n",
      "wine_cellar_bottle_storage 100 0.72\n",
      "yard 100 0.6\n",
      "youth_hostel 100 0.8\n",
      "zen_garden 100 0.67\n",
      "avg topK accuracy: 0.7777030162413002\n"
     ]
    }
   ],
   "source": [
    "#reduced_model = load_model(checkpoint_name + '.h5')\n",
    "reduced_model.load_weights(checkpoint_name+'_ft.h5')\n",
    "#reduced_model.summary()\n",
    "#print(reduced_model.evaluate_generator(val_generator,steps=nb_validation_samples // BATCH_SIZE))\n",
    "avg_topK_accuracy=0\n",
    "for label in img_dirs:\n",
    "    img_dir=os.path.join(VAL_DATA_DIR,label)\n",
    "    img_files = sorted(os.listdir(img_dir))\n",
    "    num_correct_topK=0\n",
    "    for f in img_files:\n",
    "        img=cv2.imread(os.path.join(img_dir,f))\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        img=cv2.resize(img,INPUT_SIZE)\n",
    "        inp = preprocessing_function(np.expand_dims(img, axis=0).astype(np.float32)) #\n",
    "        preds=reduced_model.predict(inp)[0]\n",
    "        indices=preds.argsort()[::-1]\n",
    "        predictions=[idx_to_class[ind] for ind in indices]\n",
    "        #print(predictions[:5],preds[:5])\n",
    "        if label in predictions[:5]:\n",
    "            num_correct_topK+=1\n",
    "    topK_accuracy=num_correct_topK/len(img_files)\n",
    "    avg_topK_accuracy+=topK_accuracy\n",
    "    print(label,len(img_files),topK_accuracy)\n",
    "\n",
    "avg_topK_accuracy/=len(img_dirs)\n",
    "print('avg topK accuracy:',avg_topK_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    #reduced_model.compile(optimizer=SGD(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy',top_k_categorical_accuracy])\n",
    "    #reduced_model.save(checkpoint_name + '_model_ft.h5')\n",
    "    save_model(reduced_model,checkpoint_name + '_model_ft.h5')\n",
    "    #K.clear_session()\n",
    "    #tf.reset_default_graph()\n",
    "    #reduced_model = load_model(checkpoint_name + '_model_ft.h5')\n",
    "else:\n",
    "    K.clear_session()\n",
    "    tf.reset_default_graph()\n",
    "    reduced_model = load_model(checkpoint_name + '.h5')\n",
    "    reduced_model.load_weights(checkpoint_name+'_ft.h5')\n",
    "    reduced_model.save(checkpoint_name + '_model_ft.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/engine/saving.py:270: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "  warnings.warn('No training configuration found in save file: '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Conv1 (Conv2D)                  (None, 112, 112, 24) 648         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_Conv1 (BatchNormalization)   (None, 112, 112, 24) 96          Conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Conv1_relu (ReLU)               (None, 112, 112, 24) 0           bn_Conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise (Depthw (None, 112, 112, 24) 216         Conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_BN (Bat (None, 112, 112, 24) 96          expanded_conv_depthwise[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_depthwise_relu (R (None, 112, 112, 24) 0           expanded_conv_depthwise_BN[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project (Conv2D)  (None, 112, 112, 16) 384         expanded_conv_depthwise_relu[0][0\n",
      "__________________________________________________________________________________________________\n",
      "expanded_conv_project_BN (Batch (None, 112, 112, 16) 64          expanded_conv_project[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand (Conv2D)         (None, 112, 112, 64) 1024        expanded_conv_project_BN[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_BN (BatchNormali (None, 112, 112, 64) 256         block_1_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_1_expand_relu (ReLU)      (None, 112, 112, 64) 0           block_1_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise (DepthwiseCon (None, 56, 56, 64)   576         block_1_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_BN (BatchNorm (None, 56, 56, 64)   256         block_1_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_1_depthwise_relu (ReLU)   (None, 56, 56, 64)   0           block_1_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project (Conv2D)        (None, 56, 56, 24)   1536        block_1_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_1_project_BN (BatchNormal (None, 56, 56, 24)   96          block_1_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand (Conv2D)         (None, 56, 56, 96)   2304        block_1_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_BN (BatchNormali (None, 56, 56, 96)   384         block_2_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_2_expand_relu (ReLU)      (None, 56, 56, 96)   0           block_2_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise (DepthwiseCon (None, 56, 56, 96)   864         block_2_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_BN (BatchNorm (None, 56, 56, 96)   384         block_2_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_2_depthwise_relu (ReLU)   (None, 56, 56, 96)   0           block_2_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project (Conv2D)        (None, 56, 56, 24)   2304        block_2_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_2_project_BN (BatchNormal (None, 56, 56, 24)   96          block_2_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_2_add (Add)               (None, 56, 56, 24)   0           block_1_project_BN[0][0]         \n",
      "                                                                 block_2_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand (Conv2D)         (None, 56, 56, 96)   2304        block_2_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_BN (BatchNormali (None, 56, 56, 96)   384         block_3_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_3_expand_relu (ReLU)      (None, 56, 56, 96)   0           block_3_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise (DepthwiseCon (None, 28, 28, 96)   864         block_3_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_BN (BatchNorm (None, 28, 28, 96)   384         block_3_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_3_depthwise_relu (ReLU)   (None, 28, 28, 96)   0           block_3_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project (Conv2D)        (None, 28, 28, 32)   3072        block_3_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_3_project_BN (BatchNormal (None, 28, 28, 32)   128         block_3_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand (Conv2D)         (None, 28, 28, 120)  3840        block_3_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_BN (BatchNormali (None, 28, 28, 120)  480         block_4_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_4_expand_relu (ReLU)      (None, 28, 28, 120)  0           block_4_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise (DepthwiseCon (None, 28, 28, 120)  1080        block_4_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_BN (BatchNorm (None, 28, 28, 120)  480         block_4_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_4_depthwise_relu (ReLU)   (None, 28, 28, 120)  0           block_4_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project (Conv2D)        (None, 28, 28, 32)   3840        block_4_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_4_project_BN (BatchNormal (None, 28, 28, 32)   128         block_4_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_4_add (Add)               (None, 28, 28, 32)   0           block_3_project_BN[0][0]         \n",
      "                                                                 block_4_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand (Conv2D)         (None, 28, 28, 120)  3840        block_4_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_BN (BatchNormali (None, 28, 28, 120)  480         block_5_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_5_expand_relu (ReLU)      (None, 28, 28, 120)  0           block_5_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise (DepthwiseCon (None, 28, 28, 120)  1080        block_5_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_BN (BatchNorm (None, 28, 28, 120)  480         block_5_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_5_depthwise_relu (ReLU)   (None, 28, 28, 120)  0           block_5_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project (Conv2D)        (None, 28, 28, 32)   3840        block_5_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_5_project_BN (BatchNormal (None, 28, 28, 32)   128         block_5_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_5_add (Add)               (None, 28, 28, 32)   0           block_4_add[0][0]                \n",
      "                                                                 block_5_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand (Conv2D)         (None, 28, 28, 120)  3840        block_5_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_BN (BatchNormali (None, 28, 28, 120)  480         block_6_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_6_expand_relu (ReLU)      (None, 28, 28, 120)  0           block_6_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise (DepthwiseCon (None, 14, 14, 120)  1080        block_6_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_BN (BatchNorm (None, 14, 14, 120)  480         block_6_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_6_depthwise_relu (ReLU)   (None, 14, 14, 120)  0           block_6_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project (Conv2D)        (None, 14, 14, 64)   7680        block_6_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_6_project_BN (BatchNormal (None, 14, 14, 64)   256         block_6_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand (Conv2D)         (None, 14, 14, 232)  14848       block_6_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_BN (BatchNormali (None, 14, 14, 232)  928         block_7_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_7_expand_relu (ReLU)      (None, 14, 14, 232)  0           block_7_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise (DepthwiseCon (None, 14, 14, 232)  2088        block_7_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_BN (BatchNorm (None, 14, 14, 232)  928         block_7_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_7_depthwise_relu (ReLU)   (None, 14, 14, 232)  0           block_7_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project (Conv2D)        (None, 14, 14, 64)   14848       block_7_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_7_project_BN (BatchNormal (None, 14, 14, 64)   256         block_7_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_7_add (Add)               (None, 14, 14, 64)   0           block_6_project_BN[0][0]         \n",
      "                                                                 block_7_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand (Conv2D)         (None, 14, 14, 232)  14848       block_7_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_BN (BatchNormali (None, 14, 14, 232)  928         block_8_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_8_expand_relu (ReLU)      (None, 14, 14, 232)  0           block_8_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise (DepthwiseCon (None, 14, 14, 232)  2088        block_8_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_BN (BatchNorm (None, 14, 14, 232)  928         block_8_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_8_depthwise_relu (ReLU)   (None, 14, 14, 232)  0           block_8_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project (Conv2D)        (None, 14, 14, 64)   14848       block_8_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_8_project_BN (BatchNormal (None, 14, 14, 64)   256         block_8_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_8_add (Add)               (None, 14, 14, 64)   0           block_7_add[0][0]                \n",
      "                                                                 block_8_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand (Conv2D)         (None, 14, 14, 232)  14848       block_8_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_BN (BatchNormali (None, 14, 14, 232)  928         block_9_expand[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "block_9_expand_relu (ReLU)      (None, 14, 14, 232)  0           block_9_expand_BN[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise (DepthwiseCon (None, 14, 14, 232)  2088        block_9_expand_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_BN (BatchNorm (None, 14, 14, 232)  928         block_9_depthwise[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block_9_depthwise_relu (ReLU)   (None, 14, 14, 232)  0           block_9_depthwise_BN[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project (Conv2D)        (None, 14, 14, 64)   14848       block_9_depthwise_relu[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "block_9_project_BN (BatchNormal (None, 14, 14, 64)   256         block_9_project[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_9_add (Add)               (None, 14, 14, 64)   0           block_8_add[0][0]                \n",
      "                                                                 block_9_project_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand (Conv2D)        (None, 14, 14, 232)  14848       block_9_add[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_BN (BatchNormal (None, 14, 14, 232)  928         block_10_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_10_expand_relu (ReLU)     (None, 14, 14, 232)  0           block_10_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise (DepthwiseCo (None, 14, 14, 232)  2088        block_10_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_BN (BatchNor (None, 14, 14, 232)  928         block_10_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_10_depthwise_relu (ReLU)  (None, 14, 14, 232)  0           block_10_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project (Conv2D)       (None, 14, 14, 96)   22272       block_10_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_10_project_BN (BatchNorma (None, 14, 14, 96)   384         block_10_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand (Conv2D)        (None, 14, 14, 352)  33792       block_10_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_BN (BatchNormal (None, 14, 14, 352)  1408        block_11_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_11_expand_relu (ReLU)     (None, 14, 14, 352)  0           block_11_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise (DepthwiseCo (None, 14, 14, 352)  3168        block_11_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_BN (BatchNor (None, 14, 14, 352)  1408        block_11_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_11_depthwise_relu (ReLU)  (None, 14, 14, 352)  0           block_11_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project (Conv2D)       (None, 14, 14, 96)   33792       block_11_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_11_project_BN (BatchNorma (None, 14, 14, 96)   384         block_11_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_11_add (Add)              (None, 14, 14, 96)   0           block_10_project_BN[0][0]        \n",
      "                                                                 block_11_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand (Conv2D)        (None, 14, 14, 352)  33792       block_11_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_BN (BatchNormal (None, 14, 14, 352)  1408        block_12_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_12_expand_relu (ReLU)     (None, 14, 14, 352)  0           block_12_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise (DepthwiseCo (None, 14, 14, 352)  3168        block_12_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_BN (BatchNor (None, 14, 14, 352)  1408        block_12_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_12_depthwise_relu (ReLU)  (None, 14, 14, 352)  0           block_12_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project (Conv2D)       (None, 14, 14, 96)   33792       block_12_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_12_project_BN (BatchNorma (None, 14, 14, 96)   384         block_12_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_12_add (Add)              (None, 14, 14, 96)   0           block_11_add[0][0]               \n",
      "                                                                 block_12_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand (Conv2D)        (None, 14, 14, 352)  33792       block_12_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_BN (BatchNormal (None, 14, 14, 352)  1408        block_13_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_13_expand_relu (ReLU)     (None, 14, 14, 352)  0           block_13_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise (DepthwiseCo (None, 7, 7, 352)    3168        block_13_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_BN (BatchNor (None, 7, 7, 352)    1408        block_13_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_13_depthwise_relu (ReLU)  (None, 7, 7, 352)    0           block_13_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project (Conv2D)       (None, 7, 7, 160)    56320       block_13_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_13_project_BN (BatchNorma (None, 7, 7, 160)    640         block_13_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand (Conv2D)        (None, 7, 7, 576)    92160       block_13_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_BN (BatchNormal (None, 7, 7, 576)    2304        block_14_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_14_expand_relu (ReLU)     (None, 7, 7, 576)    0           block_14_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_14_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_14_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_14_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_14_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project (Conv2D)       (None, 7, 7, 160)    92160       block_14_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_14_project_BN (BatchNorma (None, 7, 7, 160)    640         block_14_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_14_add (Add)              (None, 7, 7, 160)    0           block_13_project_BN[0][0]        \n",
      "                                                                 block_14_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand (Conv2D)        (None, 7, 7, 576)    92160       block_14_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_BN (BatchNormal (None, 7, 7, 576)    2304        block_15_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_15_expand_relu (ReLU)     (None, 7, 7, 576)    0           block_15_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_15_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_15_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_15_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_15_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project (Conv2D)       (None, 7, 7, 160)    92160       block_15_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_15_project_BN (BatchNorma (None, 7, 7, 160)    640         block_15_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block_15_add (Add)              (None, 7, 7, 160)    0           block_14_add[0][0]               \n",
      "                                                                 block_15_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand (Conv2D)        (None, 7, 7, 576)    92160       block_15_add[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_BN (BatchNormal (None, 7, 7, 576)    2304        block_16_expand[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block_16_expand_relu (ReLU)     (None, 7, 7, 576)    0           block_16_expand_BN[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise (DepthwiseCo (None, 7, 7, 576)    5184        block_16_expand_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_BN (BatchNor (None, 7, 7, 576)    2304        block_16_depthwise[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block_16_depthwise_relu (ReLU)  (None, 7, 7, 576)    0           block_16_depthwise_BN[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project (Conv2D)       (None, 7, 7, 320)    184320      block_16_depthwise_relu[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "block_16_project_BN (BatchNorma (None, 7, 7, 320)    1280        block_16_project[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1 (Conv2D)                 (None, 7, 7, 768)    245760      block_16_project_BN[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "Conv_1_bn (BatchNormalization)  (None, 7, 7, 768)    3072        Conv_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "out_relu (ReLU)                 (None, 7, 7, 768)    0           Conv_1_bn[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 768)          0           out_relu[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 431)          331439      global_average_pooling2d_1[0][0] \n",
      "==================================================================================================\n",
      "Total params: 1,697,335\n",
      "Trainable params: 1,675,383\n",
      "Non-trainable params: 21,952\n",
      "__________________________________________________________________________________________________\n",
      "['dense_1/Softmax']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 431)\n",
      "elapsed: 0.008690898418426513\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "tf.reset_default_graph()\n",
    "#K.set_floatx('float32')\n",
    "#K.set_epsilon(1e-8)\n",
    "reduced_model = load_model(checkpoint_name + '_model_ft.h5')\n",
    "\n",
    "reduced_model.summary()\n",
    "\n",
    "output_names=[reduced_model.output.op.name]\n",
    "print (output_names)\n",
    "x=np.random.uniform(-1,1,(1,224,224,3))\n",
    "preds = reduced_model.predict(x)\n",
    "print(preds.shape)\n",
    "\n",
    "start_time=time.time()\n",
    "TESTS=100\n",
    "for i in range(TESTS):\n",
    "    preds = reduced_model.predict(x)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print('elapsed:', elapsed_time/TESTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_1/Softmax:0\", shape=(?, 431), dtype=float32)\n",
      "Tensor(\"input_1:0\", shape=(?, 224, 224, 3), dtype=float32) 224 224\n",
      "1335\n",
      "(431,)\n",
      "elapsed: 0.004271173477172851\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np \n",
    "import time\n",
    "K.clear_session()\n",
    "tf.reset_default_graph()\n",
    "\n",
    "#f=tf.gfile.GFile('places_mobilenet2_alpha=1.4_augm_ft_sgd.pb', 'rb')\n",
    "f=tf.gfile.GFile('mobilenet_pruning_30percent_model_ft.pb', 'rb')\n",
    "#f=tf.gfile.GFile(checkpoint_name+'.pb', 'rb')\n",
    "graph_def = tf.GraphDef()\n",
    "graph_def.ParseFromString(f.read())\n",
    "f.close()\n",
    "with tf.Graph().as_default() as graph:\n",
    "    tf.import_graph_def(graph_def, name='')\n",
    "\n",
    "sess=tf.Session(graph=graph)\n",
    "\n",
    "output=graph.get_tensor_by_name('dense_1/Softmax:0')\n",
    "print(output)\n",
    "input=graph.get_tensor_by_name('input_1:0')\n",
    "_,w,h,_=input.shape\n",
    "print(input,w,h)\n",
    "x=[n.name for n in graph_def.node]\n",
    "print(len(x))\n",
    "\n",
    "x=np.random.uniform(-1,1,(1,w,h,3))\n",
    "preds = sess.run(output, feed_dict={input: x})[0]\n",
    "print(preds.shape)\n",
    "\n",
    "start_time=time.time()\n",
    "TESTS=100\n",
    "for i in range(TESTS):\n",
    "    preds = sess.run(output, feed_dict={input: x})[0]\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "print('elapsed:', elapsed_time/TESTS)\n",
    "\n",
    "\n",
    "sess.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
